{
  "id": "lecture_03",
  "title": "Storage Management (Part 2)",
  "text": "This lecture continues the discussion of storage management by examining different data storage approaches used by database management systems, focusing on how tuples are stored, updated, and optimized for different workloads. The lecture begins with a detailed explanation of tuple-oriented storage operations. When inserting a new tuple, the DBMS consults the page directory to locate a page with available space, retrieves the page from disk if it is not already in memory, and uses the slot array to find a location where the tuple can be stored. When updating an existing tuple, the DBMS uses the record identifier to locate the page and slot. If the updated data fits in the existing space, it overwrites the tuple in place; otherwise, the DBMS marks the original tuple as deleted and inserts a new version in a different page.\n\nSeveral problems with in-place tuple updates are discussed. Fragmentation occurs when pages are not fully utilized due to deletions and variable-length attributes, leading to wasted space. Updating a single tuple requires reading and writing an entire page, resulting in unnecessary disk I/O. Random disk I/O can become a significant bottleneck when updates involve tuples spread across multiple pages. These issues motivate alternative storage designs, especially in systems that do not allow in-place overwrites and instead only append new data, such as object stores and distributed file systems like HDFS and Google Colossus.\n\nLog-structured storage is introduced as an alternative storage approach. Instead of updating tuples in place, the DBMS records all changes as sequential log entries representing tuple insertions and deletions. Each log entry contains the tuple’s unique identifier and either the full tuple contents or a deletion marker. This approach was originally proposed as Log-Structured Merge Trees (LSM trees) in the mid-1990s. Updates are first applied to an in-memory data structure known as a MemTable, and when it fills up, its contents are written sequentially to disk as immutable sorted string tables (SSTables).\n\nIn log-structured storage systems, new updates are appended to disk without checking or modifying older records. As a result, multiple versions of the same key may exist across SSTables. To address this, the DBMS periodically performs compaction, which merges multiple SSTables, removes obsolete versions, and retains only the most recent value for each key. Compaction reduces wasted space and improves read performance but introduces additional write amplification and computational overhead. Despite these downsides, log-structured storage managers are widely used today due to their high write throughput, with systems such as RocksDB and LevelDB being prominent examples.\n\nThe lecture then introduces index-organized storage, which addresses limitations of traditional two-table storage layouts that rely on separate indexes to locate tuples. In index-organized storage, the DBMS stores table tuples directly as values within an index data structure, typically a B+ tree. Tuples are physically ordered by key, and leaf nodes contain the actual tuple data using a slotted-page layout. This approach allows efficient point lookups and range scans. Unlike LSM-based systems, B+ trees pay maintenance costs during updates, while LSM trees defer these costs to background compaction.\n\nThe lecture revisits tuple storage fundamentals, emphasizing that a tuple is a sequence of bytes prefixed with a header containing metadata. The DBMS uses catalog information to interpret these bytes according to the table schema. Proper word alignment of attributes within tuples is critical to allow efficient CPU access. To achieve alignment, DBMSs may insert padding between attributes or reorder attributes in the physical layout. These techniques ensure that attributes begin at word boundaries, improving performance at the cost of additional space overhead.\n\nDifferent storage models are then introduced, describing how DBMSs physically organize tuples on disk and in memory. The N-ary Storage Model (NSM), also known as row-oriented storage, stores all attributes of a tuple contiguously within a page. This model is well-suited for OLTP workloads that involve frequent inserts, updates, and point queries accessing entire tuples. NSM provides good write performance but performs poorly for analytical queries that scan large tables and access only a subset of attributes, resulting in wasted I/O and poor cache locality.\n\nThe Decomposition Storage Model (DSM), also known as column-oriented storage, stores each attribute of a table contiguously in separate blocks. This design is ideal for OLAP workloads that perform large scans over selected columns. DSM improves cache locality, enables better compression, and reduces unnecessary I/O. However, it introduces overhead for point queries and updates because the DBMS must reconstruct tuples by combining attributes from multiple locations. Variable-length attributes are typically handled using dictionary compression to convert them into fixed-length representations.\n\nThe lecture observes that while OLAP queries rarely access a single column in isolation, columnar storage remains beneficial. To combine the advantages of row and column storage, the Partition Attributes Across (PAX) model is introduced as a hybrid approach. PAX horizontally partitions data into row groups and vertically partitions attributes within each group into column chunks. This design improves cache locality while retaining many benefits of columnar processing. Modern storage formats such as Parquet, ORC, and Apache Arrow are examples of systems that adopt PAX-like layouts.\n\nThe lecture then discusses database compression as a critical optimization for reducing I/O and memory usage. Compression aims to produce fixed-length representations, postpone decompression as long as possible during query execution (late materialization), and remain lossless. Compression can be applied at different granularities, including block-level, tuple-level, attribute-level, and column-level compression, depending on the storage model and workload.\n\nNaïve compression schemes apply general-purpose compression algorithms to database pages but require decompression before data can be accessed or modified, limiting their usefulness. More advanced columnar compression techniques are introduced, including run-length encoding, bit-packing, bitmap encoding, delta encoding, and dictionary encoding. These schemes exploit data distribution and ordering to reduce storage size while allowing queries to operate directly on compressed data.\n\nRun-length encoding compresses consecutive runs of identical values into compact triplets, while bit-packing reduces the number of bits used to store integer values when their range is small. Bitmap encoding represents attribute values as bit vectors and is effective for low-cardinality attributes. Delta encoding stores differences between consecutive values and is especially useful for time-series or ordered data. Dictionary encoding replaces frequent values with compact codes and maintains a mapping to original values, often using order-preserving dictionaries to support range queries efficiently.\n\nThe lecture concludes by emphasizing that choosing the appropriate storage model depends on the target workload. Row-oriented storage is best suited for OLTP workloads, column-oriented storage is ideal for OLAP workloads, and hybrid approaches such as PAX provide a balance between the two. Compression techniques can further enhance performance and storage efficiency, with dictionary encoding highlighted as one of the most practical and widely used schemes."
}
