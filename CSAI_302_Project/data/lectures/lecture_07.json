{
  "id": "lecture_07",
  "title": "Transaction Processing and Schedules",
  "text": "This lecture introduces transaction processing as a fundamental component of database management systems, focusing on transactions, schedules, serializability, and recoverability. A transaction is defined as a logical unit of database processing that must be executed independently of other transactions and follows the all-or-nothing principle. Transactions may consist of a single data retrieval operation or a sequence of data manipulation operations that must be executed together. Transaction management systems are essential for applications with large databases and many concurrent users, such as banking systems, airline reservations, online retail platforms, and stock trading systems, where high availability and fast response times are required.\n\nA fund transfer example is used to motivate the need for transaction correctness. Transferring money from one account to another involves reading account balances, updating values, and writing them back to the database. Failures such as system crashes or hardware errors during execution may lead to inconsistent database states if updates are partially applied. This motivates the atomicity requirement, which ensures that either all operations of a transaction are reflected in the database or none are. Once a transaction completes successfully and the user is notified, its updates must persist even in the presence of failures, satisfying the durability requirement. Transactions must also preserve database consistency, meaning that integrity constraints hold before and after execution, even though the database may be temporarily inconsistent during execution. Isolation ensures that concurrent transactions do not interfere with one another and that intermediate results of one transaction are not visible to others.\n\nThe lecture contrasts single-user and multi-user database systems. Single-user DBMSs allow only one user at a time, while multi-user DBMSs allow concurrent access by many users or processes. Both require transaction management mechanisms, including concurrency control to maintain transaction independence and recovery mechanisms to ensure atomic execution in the presence of failures. The role of transaction management within the DBMS architecture is discussed, showing how it interacts with query processing, concurrency control, recovery subsystems, and the storage manager.\n\nA transaction is formally described as a program that forms a logical unit of database processing, with its own memory and computation. It includes one or more read and write operations on shared database items, as well as local computations. Transaction boundaries are marked by begin and end statements. If an error occurs during execution, the transaction must roll back, undoing all its effects. Transactions may be read-only or read-write, and a single application program may execute multiple transactions.\n\nThe primary transaction operations are read(X) and write(X). The read operation copies a database item from disk or cache into a local variable, while the write operation updates the database item using the value stored in the local variable. Local computations, such as arithmetic updates, are performed on local variables and do not affect the database until a write operation is executed. Examples are provided to illustrate transaction execution and the importance of explicitly writing updated values back to the database.\n\nThe lecture categorizes different types of failures that may occur during transaction execution. These include system crashes caused by hardware, software, or network errors; transaction failures due to logical errors, constraint violations, or user interruptions; local transaction errors such as missing data or programmed exceptions; concurrency control enforcement actions such as deadlock resolution or serializability violations; disk failures involving read or write errors; and physical failures such as power outages or catastrophic events.\n\nTransaction states are introduced to describe the lifecycle of a transaction. A transaction begins in the active state while executing its operations. After executing its final statement, it enters the partially committed state. If an error is detected, it moves to the failed state and is subsequently aborted, at which point the database is restored to its state prior to the transactionâ€™s execution. After a successful commit, the transaction enters the committed state, after which its effects are permanent. Aborted transactions may either be restarted or terminated, depending on the cause of failure.\n\nThe ACID properties are presented as the desirable correctness guarantees for transactions. Atomicity ensures that a transaction executes entirely or not at all and is enforced by the recovery subsystem. Consistency ensures that the database remains consistent before and after transaction execution and is also supported by recovery mechanisms. Isolation ensures that transactions do not interfere with each other and is enforced by concurrency control mechanisms. Durability guarantees that the effects of committed transactions persist despite failures and is ensured by the recovery subsystem.\n\nAn example involving two transactions operating on bank accounts illustrates the effects of concurrent execution. One transaction transfers money between accounts, while another applies interest. Although serial execution of these transactions preserves correctness, certain interleavings can lead to incorrect results and financial loss. This demonstrates that not all concurrent schedules are acceptable, motivating the need for formal correctness criteria.\n\nA schedule, also called a history or execution plan, is defined as a total ordering of the operations of a set of transactions, where operations from different transactions may interleave but the order of operations within each transaction is preserved. A schedule is complete if all transactions either commit or abort. Examples of serial and non-serial schedules are presented, showing that some non-serial schedules are equivalent to serial ones, while others are not.\n\nSerializability is introduced as the main correctness criterion for concurrent transaction execution. A schedule is serializable if it is equivalent to some serial schedule. Serial execution always preserves consistency, and serializable schedules provide the benefits of concurrency without sacrificing correctness. Two primary notions of serializability are discussed: conflict serializability and view serializability.\n\nConflicting operations are defined as operations from different transactions that access the same data item and where at least one operation is a write. Read-read operations do not conflict, while read-write, write-read, and write-write operations do. Conflict equivalence between schedules requires that the relative order of all conflicting operations is the same. A schedule is conflict serializable if it is conflict equivalent to a serial schedule. Conflict serializability can be tested using a precedence graph, where transactions are nodes and directed edges represent conflict dependencies. A schedule is conflict serializable if and only if its precedence graph is acyclic, and a serial order can be obtained via topological sorting.\n\nView serializability is defined as a more general form of serializability based on the values read and written by transactions. Two schedules are view equivalent if each transaction reads the same initial values, reads values produced by the same transactions, and performs the final write on each data item in both schedules. Every conflict-serializable schedule is view-serializable, but not all view-serializable schedules are conflict-serializable. Testing for view serializability is computationally expensive and is an NP-complete problem, making it impractical for general use in DBMSs.\n\nThe lecture explains that DBMSs enforce concurrency control protocols to guarantee serializability in practice, as it is difficult to test serializability after execution. These protocols ensure correctness before transactions complete, despite variations in system load, transaction arrival times, and process scheduling.\n\nRecoverability is introduced as a property related to durability and failure handling. A schedule is recoverable if whenever a transaction reads data written by another transaction, the writing transaction commits before the reading transaction commits. Non-recoverable schedules may expose users to inconsistent data if a transaction aborts after another has already committed based on its results.\n\nCascading rollbacks occur when the failure of one transaction forces multiple other transactions to abort because they have read uncommitted data. Cascadeless schedules prevent cascading rollbacks by ensuring that transactions only read data written by committed transactions. However, recovery may still be complex. Strict schedules impose a stronger condition by disallowing both reads and writes of a data item until the previous write has either committed or aborted. Strict schedules simplify recovery and are preferred in practical DBMS implementations.\n\nThe lecture concludes with a recovery hierarchy, noting that every strict schedule is cascadeless, every cascadeless schedule is recoverable, and recoverable schedules are preferable to non-recoverable ones. Ensuring serializability and recoverability is essential for building reliable, correct, and efficient transaction processing systems."
}
