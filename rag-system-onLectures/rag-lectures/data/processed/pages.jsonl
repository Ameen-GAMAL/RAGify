{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 1, "text_raw": "       CSAI 302\n\nAdvanced Database\n\n     Systems\n           Lec 01\nAdvanced DBMS and Database\n    System Architectures", "char_count": 111, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 2, "text_raw": "               Outline\n\nDatabase system essentials\nDBMS Architecture Fundamentals\nEvolution of Database System Architectures\nData Models\nOLTP vs. OLAP Workload Characteristics\nCourse Details", "char_count": 181, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 3, "text_raw": "Database system\n   essentials", "char_count": 29, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 4, "text_raw": "   Database System Architecture\n\nThe overall design and structure of a database system that\n  outlines how data is stored, managed, and accessed.\n  defines the components of the system\n   how they interact, and how data flows between them.\nA well-defined architecture ensures Data:\n  Integrity\n  Efficiency\n  Security\n   Scalability.", "char_count": 339, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 5, "text_raw": " Database Architecture Types\n\n\n               Tiered\n            Architectures\n\n\n\n1-Tier           2-Tier           3-Tier", "char_count": 121, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 6, "text_raw": "    Database Architecture Types\n\n\n\n                                     Physical\n                                 Architectures\n\n\n\n                                               Distributed  Centralized          Client/Server                                Parallel Systems                                          Systems\n\n\n\n                                          Data is stored                     Multiple clients                          Uses multiple All data is on a                             across multiple                      connect to a                             processors andsingle computer.                            physical devices                       central server.                                      disks.                                            or locations.", "char_count": 791, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 7, "text_raw": "            Schema\n\nThe blueprint for how data is organized in a\n database\ndefining elements like\n  tables, fields, data types, and their relationships\nbut not the actual data itself.\nThis defines the structure of data for a data\n model.", "char_count": 230, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 8, "text_raw": "     Three-Schema Architecture\n\n          External Schema      Conceptual Schema       Internal Schema\n           View Level             Logical Level            Physical Level\n\n\n         Customized data       Logical structure of       Physical storage\n              views               the database              structures\n\n\n\n\n\n                                                                                                                                                      •   B-tree indexes for\n                                                                                                      frequent lookups\n                   patient           patient                         •  Tables                                                 •  Hash partitioning for\n                 medical      demographic                    •  Relationships                                 parallel processing             systemHospital                records and      information                     •   Integrity constraints                              •  Columnar storage for\n                treatment     and insurance                                                                analytical queries.          management\n                   history            details.", "char_count": 1262, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 9, "text_raw": "            DBMS\n\nA software that allows applications to store and\n analyze information in a database.\nA general-purpose DBMS is designed to allow the\n  definition, creation, querying, update, and\n   administration\n   of databases\n  in accordance with\n   some data model.", "char_count": 265, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 10, "text_raw": " DBMS Core\nComponents", "char_count": 20, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 11, "text_raw": "      DBMS Key Components\n\n\nDatabase Engine       Database Schema       Query Processor\n                                        • The blueprint or logical        • Interprets and executes• Handles data\n                                 structure of the database.       user queries. processing\n                                                                                 • Translates them into\n• Enables efficient access                                                                 actions for the database.\n and manipulation.\n\n\n           Storage Manager      Transaction Manager\n                                                             • Ensures the integrity and                  • Manages the physical\n                                             consistency of data by                storage of data on\n                                                               • Managing transactions                various media\n                                                               • Enforcing rules like                  • Handles data access.                                        ACID properties.", "char_count": 1109, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 12, "text_raw": "     DBMS Key Components\n\n            DBMS Key Components\n\n\n\n     Database        Database        Query          Storage       Transaction\n      Engine        Schema        Processor      Manager       Manager\n\n\n\n                    The blueprint or                                                    Interprets user                        ConcurrencyData processing           logical structure                              Buffer Manager                                                         queries.                                Control                           of the database.\n\n\n                                                                               File OrganizationData access and                                   Builds Execution                          Recovery                                                             and Access manipulation.                                            plans.                         Management                                                             Methods\n\n\n\n                                                                      Index        ACID properties\n                                                        Management      Implementation", "char_count": 1206, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 13, "text_raw": "      Query Processing Engine\nTransforms high-level SQL statements into\n efficient execution plans through several\n critical phases.\n\n            Parser,     Abstract SQL                       Query     Query  Execution    Query           Lexical      syntax Query                        Optimizer     Plan    Engine    Execution          Analysis      tree\n                                                                                  (I/O,                                                Validate                                                                                                                                                                                            (physical                                                                  CPU,                                                                      costMinimize                                      planImplement                  SQL\n                                                                                            query                                                                                                                   memory)                                                              query                                    syntax                                                                                                                                                                                                                 operators)", "char_count": 1465, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 14, "text_raw": "  Evolution of\nDatabase System\n  Architectures", "char_count": 44, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 15, "text_raw": "        Historical Progression\n\nThe evolution of database architectures reflects\n the changing demands of data processing, from\n simple record-keeping to complex analytical\n workloads handling massive datasets.\nArchitectural evolution Drivers\n  Scalability Requirements\n  Data Complexity\n  Performance Expectations\n  Reliability Demands", "char_count": 334, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 16, "text_raw": "  File-Based Systems (1960s-1970s)\n\nEarly computing relied on flat file systems\nEach application maintained its own data files.\nIntegrated Data Store\n  Network data model.\n  Tuple-at-a-time queries.\n  Transaction-oriented\n  Dedicated working storage area for each record type\nThis approach suffered from data redundancy,\n inconsistency, and lack of standardized access methods.", "char_count": 383, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 17, "text_raw": "  Hierarchical and Network Models (70s-80s)\n\nIBM's Information Management System (IMS) introduced\n hierarchical structures resembling tree organizations,\nThe Conference on Data Systems Languages (CODASYL)\n developed network models allowing more complex\n relationships.\nThese systems provided better data organization but\n required programmers to navigate complex pointer\n structures manually.\n  Hierarchical data model.\n  Programmer-defined physical storage format.\n  Tuple-at-a-time queries.", "char_count": 496, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 18, "text_raw": "      Relational Model (80s-90s)\n\nRelational model introduced mathematical\n foundations based on set theory and first-order\n predicate logic.\nAllowed users to focus on what data they wanted rather\n than how to retrieve it\nleading to the development of SQL and modern RDBMS\n systems like Oracle, DB2, and SQL Server.\nDatabase abstraction to avoid this maintenance:\n  Store database in simple data structures.\n  Access data through high-level language.\n   Physical storage left up to implementation.", "char_count": 498, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 19, "text_raw": "  Object-Oriented-Systems (2000s)\n\nAs applications became more complex, the need to\n store complex data types led to object-oriented\n databases and object-relational extensions.\nPostgreSQL exemplifies this evolution, supporting\n both traditional relational operations and complex\n data types like arrays, JSON, and user-defined types.", "char_count": 334, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 20, "text_raw": "      2000s – Internet boom\n\nAll the big players were heavyweight and\n expensive.\nOpen-source databases were missing\n important features.\nMany companies wrote their own custom\n middleware to scale out database across\n single-node DBMS instances.", "char_count": 242, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 21, "text_raw": "     2000s – Data warehouses\nRise of the special purpose OLAP\n DBMSs.\n  Distributed / Shared-Nothing\n  Relational / SQL\n  Usually closed-source.\nSignificant performance benefits\n from using columnar data\n storage model.", "char_count": 219, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 22, "text_raw": "      2000s – NoSQL Systems\n\nFocus on high-availability &\n high-scalability:\n  Schema-less (i.e., “Schema Last”)\n  Non-relational data models\n   (document, key/value, etc)\n No ACID transactions\n Custom APIs instead of SQL\n  Usually open-source", "char_count": 243, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 23, "text_raw": "          2010s – NewSQL\nProvide same performance for OLTP\n workloads as NoSQL DBMSs without giving\n up ACID:\n  Relational / SQL\n  Distributed\n  Usually closed-source", "char_count": 160, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 24, "text_raw": "       2010s – Hybrid systems\nHybrid Transactional-Analytical Processing.\nExecute fast OLTP like a NewSQL system while\n also executing complex OLAP queries like a data\n warehouse system.\n  Distributed / Shared-Nothing\n  Relational / SQL\n  Mixed open/closed-source.", "char_count": 262, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 25, "text_raw": "       2010s – Cloud systems\nFirst database-as-a-service (DBaaS) offerings\n were \"containerized\" versions of existing\n DBMSs.\nThere are new DBMSs that are designed from\n scratch explicitly for running in a cloud\n environment.", "char_count": 220, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 26, "text_raw": "    2010s – Shared-disk engines\nInstead of writing a custom storage\n manager, the DBMS relies on third-party\n distributed storage (object stores) .\n  Scale execution layer independently of\n    storage.\n  Favors log-structured approaches.\nThis is what most people think of when\n they talk about a data lake.", "char_count": 306, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 27, "text_raw": "     2010s – Stream processing\n\nExecute continuous queries on streams of tuples.\nExtend processing semantics to include notion of\n windows.\nOften used in combination of batch-oriented\n systems in a lambda architecture deployment.", "char_count": 227, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 28, "text_raw": "       2010s – Graph systems\n\nSystems for storing and querying graph data.\nTheir main advantage over other data models\n is to provide a graph-centric query API\n  Recent research demonstrated that is unclear\n   whether there is any benefit to using a graph-\n   centric execution engine and storage manager.", "char_count": 301, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 29, "text_raw": "     2010s – Timeseries systems\n\nSpecialized systems that are designed to\n store timeseries / event data.\nThe design of these systems make deep\n assumptions about the distribution of data\n and workload query patterns.", "char_count": 214, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 30, "text_raw": "     2020s-LAKEHOUSE SYSTEMS\n\nMiddleware for data lakes that adds support\n for better schema control / versioning with\n transactional CRUD operations.\n  Store changes in row-oriented log-structured\n    files with indexes.\n  Periodically compact recently added data into\n   read-only columnar files.", "char_count": 296, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 31, "text_raw": "   Data Models\n  A collection of concepts for\ndescribing the data in database.", "char_count": 75, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 32, "text_raw": "   Common Data Models\n\n Relational        Key/Value         Graph\n • (Most DBMSs)                • (NoSQL)                    • (NoSQL)\n\n\n\n Document /     Wide-Column /    Array / Matrix /\nXML / Object     Column-family        Vector\n    • (NoSQL)                    • (NoSQL)             • (Machine Learning)\n\n\n                   Hierarchical /\n               Network / Multi-\n                     Value\n                                • (Obsolete/ Rare)", "char_count": 452, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 33, "text_raw": "Relational\n  Model", "char_count": 18, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 34, "text_raw": "           Relational Model\n\nThe relational model defines a database\n abstraction based on relations to avoid\n maintenance overhead.\nIt has three key ideas:\n  Store database in simple data structures (relations)\n  Physical storage left up to the DBMS implementation\n  Access data through a high-level (declarative)\n   language, where the DBMS figures out best execution\n   strategy", "char_count": 375, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 35, "text_raw": "     Relational Model concepts\n\n Structure       Integrity    Manipulation\n\n\n\n  The definition of\n  relations and their           Ensure the database’s\ncontents independent             contents satisfy\n   of their physical               certain constraints.\n                                               An interface for   representation.\n                                                                accessing and\n                                                             modifying a\n                                                                database’s contents\n                         An example of a                                                                                  (e.g. SQL, Dataframes)Each relation has a set                                 constraint would be  of attributes. Each                                    that the age of aattribute has a domain                              person cannot be a       of values.                                 negative number.", "char_count": 999, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 36, "text_raw": "     Relational Model definitions\n\n\nRelation\nTuple\nPrimary key\nForeign key\nConstraint", "char_count": 85, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 37, "text_raw": "Document\n  Model", "char_count": 16, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 38, "text_raw": "       Document Data Model\n\nA collection of record documents containing a hierarchy of\n named field/value pairs.\n  A field’s value can be either a scalar type, an array of values, or\n   another document.\n  Modern implementations use JSON.\n     Older systems use XML or custom object representations.\nAvoid “relational-object impedance mismatch” by tightly\n coupling objects and database.", "char_count": 385, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 39, "text_raw": "    Relational vs. Document\n\n SUPPLIER                    SUPPLIER\n (sno, sname, scity)                           (sno, sname, scity, sstate, parts[])\n\n\n\n  SUPPLY\n(sno, pno, qty, price)\n\n\n\n   PART                      PART\n   (pno, pname)                                 (pno, pname, qty, price)", "char_count": 291, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 40, "text_raw": "             JSON file\n\n{\n                                                           {\n    \"Suppliers\": [\n                                                              \"sno\": 53,\n        {\n                                                              \"sname\": \"Samy\",\n            \"sno\": 17,\n                                                              \"scity\": \"6th Oct.\",\n            \"sname\": \"Adel\",\n                                                              \"parts\": [\n            \"scity\": \"Mansoura\",\n                                                                   {\n            \"parts\": [\n                                                                      \"pno\": 154,\n                {\n                                                                      \"pname\": \"wallet\",\n                    \"pno\": 124,\n                                                                      \"qty\": 5,\n                    \"pname\": \"chair\",\n                                                                      \"price\":2000\n                    \"qty\": 45,\n                                                                  },\n                    \"price\":1000\n                                                                   {\n                },\n                                                                      \"pno\": 162,\n                {\n                                                                      \"pname\": \"sunglasses\",\n                    \"pno\": 135,\n                                                                      \"qty\": 12,\n                    \"pname\": \"table\",\n                                                                      \"price\":1500\n                    \"qty\": 32,\n                                                                   }\n                    \"price\":3000\n                                                               ]\n                }\n                                                           }\n            ]\n                                                      ]\n        },\n                                                  }", "char_count": 2067, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 41, "text_raw": "           JSON table\nSuppliers         sno             17                  53\n\n        sname       Adel            Samy\n\n           scity     Mansoura            6th Oct.\n          parts              pno     124  135 pno     154     162\n\n            pname chair table pname wallet sunglasses\n\n                 qty     45   32  qty      5       12\n\n                price  1000 3000 price  2000   1500", "char_count": 389, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 42, "text_raw": "            XML file\n\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>            <Suppliers>\n<root>                                             <sno>53</sno>\n    <Suppliers>                                                  <sname>Samy</sname>\n        <sno>17</sno>                                                  <scity>6th Oct.</scity>\n        <sname>Adel</sname>                                                   <parts>        <scity>Mansoura</scity>\n                                                      <pno>154</pno>        <parts>\n                                                      <pname>wallet</pname>            <pno>124</pno>\n            <pname>chair</pname>                          <qty>5</qty>\n            <qty>45</qty>                                <price>2000</price>\n            <price>1000</price>                       </parts>\n        </parts>                                    <parts>\n        <parts>                                                      <pno>162</pno>\n            <pno>135</pno>                                                      <pname>sunglasses</pname>\n            <pname>table</pname>\n                                                      <qty>12</qty>            <qty>32</qty>\n                                                      <price>1500</price>            <price>3000</price>\n                                                  </parts>        </parts>\n    </Suppliers>                                </Suppliers>\n                                           </root>", "char_count": 1498, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 43, "text_raw": "Vector data\n  Model", "char_count": 19, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 44, "text_raw": "         Vector data model\nOne-dimensional arrays used for nearest-neighbor search\n (exact or approximate).\n  Used for semantic search on embeddings generated by ML-\n    trained transformer models (think ChatGPT).\n  Native integration with modern ML tools and APIs (e.g.,\n   LangChain, OpenAI).\nAt their core, these systems use specialized indexes to\n perform NN searches quickly.", "char_count": 375, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 45, "text_raw": "Content-Based Retrieval Workflow Using\n       Vector Space Embeddings", "char_count": 69, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 46, "text_raw": " OLTP vs. OLAP\n  Workload\nCharacteristics", "char_count": 40, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 47, "text_raw": "Online Transaction\nProcessing (OLTP)", "char_count": 36, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 48, "text_raw": "              OLTP\n\n\nOLTP systems handle operational business processes:\n\n    requiring fast, consistent transaction processing\n\n   with high concurrency levels.\n\nA class of systems designed for managing real-time, day-to-day business transactions.\n\nExamples\n\n  ATM transactions\n\n    online banking\n\n    credit card processing\n\n   e-commerce purchases.\n\nThese systems are characterized by\n\n   high volume\n\n   short transactions\n\n   need for quick response times.", "char_count": 461, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 49, "text_raw": "  Characteristics and Requirements\nOLTP workloads involve\n  short-duration transactions\n  accessing small amounts of current data.\nResponse times must be predictable and fast, usually\n under 100 milliseconds.\nConsider an e-commerce checkout process\n  Multiple users simultaneously place orders, update\n    inventory, and process payments.\n  Each transaction involves few records but requires\n   immediate consistency to prevent overselling products.", "char_count": 454, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 50, "text_raw": "       Data Access Patterns\n\nUse indexed access to retrieve specific records or small record sets.\nQueries involve\n   primary key lookups\n   simple range scans.\nUpdate operations modify\n   individual records\n   small groups of related records.\nThe workload mix typically includes\n  70-80% read operations\n  20-30% write operations\n       distributed across many different tables and records.", "char_count": 395, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 51, "text_raw": "       System Optimizations\n\nRow-oriented storage optimizes OLTP performance by\n storing complete records together, minimizing I/O for\n transactions accessing multiple attributes of the same\n entity.\nB+ tree indexes provide efficient access paths for both\n equality and range queries.\nConnection pooling and prepared statements reduce\n overhead for repetitive operations.\nPartitioning strategies often use range or hash partitioning\n based on transaction date or customer ID to distribute load\n evenly.", "char_count": 499, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 52, "text_raw": " Online Analytical\nProcessing (OLAP)", "char_count": 35, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 53, "text_raw": "             OLAP\n\nOLAP systems support\n  complex analytical queries and business\n   intelligence applications\n  requiring sophisticated data aggregation and\n   analysis capabilities.\nOLAP systems enable users to analyze large\n datasets from multiple perspectives.", "char_count": 255, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 54, "text_raw": "          OLAP Example\n\nAnalyzing sales data for a retail company using an\n OLAP cube.\n  The cube could organize sales by\n    product, time, and location,\n  allowing users to drill down into specific\n    regions, products, or time periods\n  to identify\n    trends, such as which products are most popular\n     in a particular city during a specific month.", "char_count": 352, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 55, "text_raw": "  Characteristics and Requirements\n\nOLAP workloads involve long-running queries that\n scan large portions of historical data to compute\n aggregations, trends, and statistical summaries.\nResponse times range from seconds to minutes, but\n query complexity and data volume are substantially\n higher than OLTP systems.\nConsider a retail analytics query calculating seasonal\n sales trends across multiple product categories,\n geographical regions, and customer segments over\n several years.", "char_count": 486, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 56, "text_raw": "       Data Access Patterns\n\nOLAP queries typically involve full table scans or\n large range scans, often accessing millions or billions\n of records.\nAggregation operations like SUM, COUNT, and AVG\n are common, frequently combined with GROUP BY\n clauses creating multi-dimensional summaries.\nJoins often involve large fact tables with smaller\n dimension tables in star or snowflake schema\n configurations.", "char_count": 401, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 57, "text_raw": "       System Optimizations\n\nColumnar storage dramatically improves OLAP\n performance by storing each column separately, enabling\n efficient compression and reducing I/O for queries\n accessing few columns.\nBitmap indexes support complex Boolean queries\n common in analytical workloads.\nMaterialized views pre-compute common aggregations,\n trading storage space for query performance.\nParallel processing distributes query execution across\n multiple processors or machines.", "char_count": 469, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 58, "text_raw": "Hybrid Approaches", "char_count": 17, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 59, "text_raw": "         Hybrid Approaches\n\nHTAP (Hybrid Transactional/Analytical Processing)\n  Modern systems increasingly support mixed workloads combining\n   OLTP and OLAP requirements.\n  SAP HANA exemplifies this approach using in-memory storage and\n    columnar organization to support both transaction processing and real-\n    time analytics on the same data.\nData Replication Strategies\n  Many organizations maintain separate OLTP and OLAP systems\n    connected through data replication mechanisms.\n  Change Data Capture (CDC) identifies and propagates OLTP system\n    changes to analytical systems with minimal impact on operational\n    performance.", "char_count": 638, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 60, "text_raw": "   System\nOptimizations", "char_count": 20, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 61, "text_raw": "    Physical Design Optimizations\n\n\n\nIndex Selection and Design\n\nPartitioning Strategies", "char_count": 86, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 62, "text_raw": "   Query Optimization Techniques\n\n\n\nCost-Based Optimization\n\nAdvanced Optimization Techniques", "char_count": 92, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 63, "text_raw": "   Memory and Caching Strategies\n\n\n\nBuffer Pool Management\n\nQuery Result Caching", "char_count": 79, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 64, "text_raw": "Course\nDetails", "char_count": 14, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 65, "text_raw": "           Course plan\n\nW        LECTURE                         LAB                            Coursework\n  Advanced DBMS and Database\n1                                                        ▪  Environment setup\n  System Architectures\n                                                                      Assignment 1\n                                                           ▪  Implementing a buffer pool manager.\n                                                                                                                                                     ▪   Storage Manager and Buffer\n2 Storage Management                  ▪  Benchmarking different buffer pool strategies\n                                                                                Pool Implementation with\n                                under various workloads\n                                                                                        Different Replacement Policies\n  Storage Models - Row-Oriented ▪  Implement storage engines.\n3\n  and Columnar Systems                ▪   Convert row-store to columnar\n                                                                      Assignment 2\n   Indexing Structures and              ▪   Build a B+ tree index;\n4                                                                                                                                                  ▪   Indexing structures (b+ trees\n  Implementation                           ▪  Implement extendible hashing.\n                                                                          and lsm trees)\n                                                           ▪   Build inventory-auditing triggers.\n  Advanced Programming and       ▪  Atomic SPs with error handling\n5                                                                                   Quiz 1\n  Query Processing                         ▪  Implementing join algorithms and vectorized\n                                   execution operators\n                                                                      Assignment 3\n                                                           ▪  Implementing a cost-based query optimizer.\n6 Query Optimization                                                                                                              ▪  Query Processing and\n                                                           ▪  Tune query plans.\n                                                                                    Optimization\n                                                           ▪  Deadlock simulation; lock contention analysis.\n   Transaction Processing and\n7                                                        ▪   Analyzing isolation level bugs in production\n  Concurrency Control\n                                 systems\n8                                        Mid Term Exam", "char_count": 2868, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 66, "text_raw": "            Course plan\n\nW        LECTURE                   LAB                     Coursework\n                                                        Assignment 4\n  Crash Recovery                                ▪  Implementing WAL and                 ▪  Transaction Processing with 9                                  recovery procedure              Concurrency Control and\n                                                               Recovery\n                                                                    ▪  Implement cross-shard ACID\n   Parallel and Distributed           transactions10  Database Architectures                 ▪  Distributed transaction\n                                   coordination\n                                                                    ▪  Use MongoDB's query language  NoSQL Databases and Big Data                              Assignment 511                                    to explore document-based  Storage Systems                                                                                                     ▪  Implement NoSQL queries                                     databases.\n                                                                    ▪  Implement core components of12 Advanced NoSQL Models.                                       different NoSQL models\n  Caching Strategies, ORM              ▪  Session data caching          Assignment 6\n13 Integration, and Modern               ▪  API caching                                         ▪  Build a Simple Web-site\n  Database Trends                              ▪  E-commerce platforms             Integrating an ORM Framework\n                                                                    ▪  Implement column-level14 Database Security                                    encryption; audit log triggers\n15 Course Wrap up            Assignments Presentation as a Whole Project", "char_count": 1884, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 67, "text_raw": "       Assessment Strategy\n      Assessment Method       Degrees\nQuizzes (best 2 of 3) (week 5, 10, 14)    10\nMidterm Exam (week 8)            20\nLecture participation               8\nLab participation                      7\nTerm Project                          15\nFinal Exam                      40\n              Total               100", "char_count": 331, "is_empty": false}
{"lecture_id": "ADB_Lec01", "source_file": "ADB_Lec01.pdf", "page_num": 68, "text_raw": "", "char_count": 0, "is_empty": true}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 1, "text_raw": "       CSAI 302\n\nAdvanced Database\n\n     Systems\n\n           Lec 02\n    Storage Management", "char_count": 83, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 2, "text_raw": "         Storage hierarchy\n                                                       Faster              CPU        CPU Registers\n                                                    Smaller\n     Volatile                 CPU Caches L1           Expensive\n                                      L2 , L3\n Random Access\n              Memory\n                        DRAM Byte-Addressable\n\n                 Disk  Non-Volatile                  SSD\n\nSequential Access\n                         HDD                                                 Slower\nBlock-Addressable\n                                                    Larger\n                      Tertiary storage (Network Storage)   Cheaper", "char_count": 674, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 3, "text_raw": " Disk-based\nArchitecture", "char_count": 23, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 4, "text_raw": "      Disk-based Architecture\n\nThe DBMS assumes that the primary storage\n location of the database is on non-volatile disk.\nThe DBMS's components manage the movement\n of data between non-volatile and volatile storage.\nLowest layer of DBMS\n  Physical details hidden from higher levels of system\nPurpose\n Map pages to locations on disk\n  Load pages from disk to memory\n  Save pages back to disk & ensuring write", "char_count": 411, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 5, "text_raw": "           Terminologies\n\n\n\nBlock\n  unit of transfer for disk read/write\nPage\n a block-sized chunk of RAM", "char_count": 98, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 6, "text_raw": "       Files of Pages of Records\n\nEach table is stored in one or more OS files\nEach file contains many pages\nEach page contains many records\nPages are understood by multiple layers\n  Managed on disk by the disk space manager:\n    pages read from/written to physical disk/files\n  Managed in memory by the buffer manager:\n    higher levels of DBMS only operate in memory", "char_count": 369, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 7, "text_raw": "    Representing Data Elements\n\n              Data                       Record    Collection            Element\n\n  DBMS      Attribute      Tuple      Relation\n\nFile System      Field      Record         File", "char_count": 205, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 8, "text_raw": "       System design goals\n\nAllow the DBMS to manage databases that\n exceed the amount of memory available.\nReading/writing to disk is expensive\n  It must be managed carefully to avoid large\n    stalls and performance degradation.\nRandom access on disk is usually much\n slower than sequential access\n  the DBMS needs to maximize sequential access.", "char_count": 345, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 9, "text_raw": "         Disk-oriented DBMS\n\n                                   Get Page #2          Execution Engine\n\n                                                                         Interpret                                             Pointer to\n                                                         Page #2                            Directory    Header                  Pool                          Page #2\n              2                                     Update Page #2                           BufferMemory\n\n                  File   Directory    Header        Header        Header        Header        Header                                                Pages              1   2   3   4   5\n         DB\n  Disk", "char_count": 709, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 10, "text_raw": "    Database Storage Questions\n\n\nHow the DBMS represents the database in\n files on disk?\n\n\nHow the DBMS manages its memory and\n moves data back-and-forth from disk?", "char_count": 162, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 11, "text_raw": "               File storage\n\nThe DBMS stores a database as one or more\n files on disk typically in a proprietary format.\n The OS does not know anything about the\n   contents of these files.\nEarly systems in the 1980s used custom\n filesystems on raw block storage.\n Some enterprise DBMSs still support this.\n Most newer DBMSs do not do this.", "char_count": 330, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 12, "text_raw": "         Storage manager\n\nResponsible for maintaining a database's\n files.\nOrganizes the files as a collection of pages.\n  Tracks data read/written to pages.\n  Tracks the available space.\nA DBMS typically does not maintain multiple\n copies of a page on disk.", "char_count": 254, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 13, "text_raw": "          Database pages\n\nA page is a fixed-size block of data.\n  It can contain tuples, meta-data, indexes, log\n   records…\n  Most systems do not mix page types.\n Some systems require a page to be self-contained.\nEach page is given a unique identifier (page ID).\n A page ID could be unique per DBMS instance, per\n   database, or per table.\n  The DBMS uses an indirection layer to map page IDs\n   to physical locations.", "char_count": 416, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 14, "text_raw": "          Database pages\n\n                          Default DB Page SizesThere are three different notions\n of \"pages\" in a DBMS:\n  Hardware Page (usually 4KB)\n  OS Page (usually 4KB, x64 2MB/1GB)\n                     4KB  Database Page (512B-32KB)\nA hardware page is the largest\n block of data that the storage device                     8KB\n can guarantee failsafe writes.\nDBMSs that specialize in read-only\n                       16KB workloads have larger page sizes.", "char_count": 471, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 15, "text_raw": "     Page storage architecture\n\nDifferent DBMSs manage pages in files on disk in\n different ways.\n Heap File Organization\n  Tree File Organization\n  Sequential / Sorted File Organization (ISAM)\n  Hashing File Organization\nAt this point in the hierarchy, we do not need to\n know anything about what is inside of the pages.", "char_count": 322, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 16, "text_raw": "        DB File Structures\n\nUnordered heap files\n   Records placed arbitrarily across pages\n  As file shrinks/grows, pages (de)allocated\n   Suitable when typical access is a full scan of all records\nClustered heap files\n  Group data into blocks to enable fast lookup and efficient modifications\nSorted files\n   Pages and records are in strict sorted order\n   Best for retrieval in order, or when a range of records is needed\nIndex files\n  B+ trees, linear hashing, extensible hashing, ……\n  May contain records or point to records in other files", "char_count": 548, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 17, "text_raw": "  Heap File\nOrganization", "char_count": 22, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 18, "text_raw": "            Heap file\n\nA heap file is an unordered collection of pages\n with tuples that are stored in random order.\nNeed additional meta-data to track location\n of files and free space availability.\nHeap files has one special header page\n Two pointers for free space and data\nLocation of the heap file and the header page\n are saved in DB catalog", "char_count": 340, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 19, "text_raw": "            Heap file\n\n\n\n                        Offset = Page# ×PageSize\n\n                                         File\n                    Page   Page   Page   Page   Page\nGet Page #2                   …                      00     01     02     03     04                                                                                  Database", "char_count": 335, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 20, "text_raw": "      Heap file: Page directory\n\nThe DBMS maintains special pages that tracks the\n location of data pages in the database files.\n One entry per database object.\n  Must make sure that the directory pages are in\n   sync with the data pages.\nDBMS also keeps meta-data about pages' contents:\n  Amount of free space per page.\n  List of free / empty pages.\n  Page type (data vs. meta-data).", "char_count": 385, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 21, "text_raw": "          Page directory\n\n\n\n                                       File Location ⇒Page# ×PageSize\n\n\n                                                                    File  Page  Page  Page  Page  Page             File  Page  Page  Page  Page  Page\n                                          00    01    02    03    04 …          20     21     22    23    24 …\n                                  DB                               DB\n  Get        Page\nPage #23     Directory\n                                                                    File  Page  Page  Page  Page  Page             File  Page  Page  Page  Page  Page\n                                                     10      11      12     13     14 …          40     41    42    43    44 …\n                                  DB                               DB", "char_count": 808, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 22, "text_raw": "  Heap file: Page directory\n\n                    File1            File2\n                                         Page0                     Page0\nDirectory\n\n                                   Data Table X            Data\n\n Index Y\n                                            Page1                       Page1\n Table Z\n                                   Data                  Data    ⋮\n\n                                            ⋮                        ⋮", "char_count": 453, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 23, "text_raw": " Unordered Heap Files With Page Directories\n\nPage directories, with multiple header pages, each\n encoding\n A pointer to page\n # free bytes on the page\nHeader pages are accessed often,\n so likely deployed in cache\nFinding a page to fit a record can be done efficiently\n  One header page load reveals free space of MANY\n\n\n                                                                                                                                   23   pages", "char_count": 466, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 24, "text_raw": "Page Layout", "char_count": 11, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 25, "text_raw": "           Page header\n\nEvery page contains a header of meta-data about the page's contents.\n  Page Size\n                                       Page\n  Checksum\n  DBMS Version                             Header\n   Transaction Visibility\n   Compression / Encoding Meta-data\n                                 Data  Schema Information\n   Data Summary / Sketches\nSome systems require pages to be self-contained (e.g., Oracle).\n   Data and its associated Metadata should reside together on the same physical\n     storage unit.", "char_count": 518, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 26, "text_raw": "           Page layout\n\nFor any page storage architecture, we now\n need to decide how to organize the data inside\n of the page.\n assuming that we are only storing tuples in\n  a row-oriented storage model.\n   Tuple-        Log-         Index-\n  oriented     structured    organized\n  Storage       Storage       Storage", "char_count": 309, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 27, "text_raw": "       Tuple-oriented storage\n\nHow to store tuples in a page?\n Keep track of the number of tuples in a\n  page and then just append a new tuple to\n\n\n\n\n\n                              →\n                              → the end.\n  What happens if we delete a tuple?\n  What happens if we have a variable-\n    length attribute?", "char_count": 317, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 28, "text_raw": "          Tuples in a page\n\n Page       Page       Page       Page\n\nTuples# = 0       Tuples# = 3        Tuples# = 2       Tuples# = 3\n\n                  Tuple #1          Tuple #1          Tuple #1\n\n               Store                  Delete                    Insert\n                  Tuple #2                           Tuple #4              Tuples                  Tuples                  Tuples\n\n                  Tuple #3          Tuple #3          Tuple #3", "char_count": 454, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 29, "text_raw": "      Variable-length attribute\n\nThe most common layout scheme is called\n slotted pages.\nThe slot array maps \"slots“ to the tuples'\n starting position offsets.\nThe header keeps track of:\n The # of used slots\n The offset of the starting location of the last\n   slot used.", "char_count": 269, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 30, "text_raw": "        Slotted pages\n                                    Slot Array\n\n                       1    2    3    4    5    6    7\nHeader\n\n\n\n\n       Tuple #4             Tuple #3\n\n  Tuple #2             Tuple #1\n\n\n     Fixed- and Var-length Tuple Data", "char_count": 237, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 31, "text_raw": "             Delete tuple\n\n\n        Slot Array             Slot Array            Slot Array\n                  1  2  3  4  5  6  7                            1  2  3  4  5  6  7                         1  2  3  4  5  6  7\nHeader              Header             Header\n\n\n\n\n   Tuple #4 Tuple #3        Tuple #4                         Tuple #4\n\n Tuple #2  Tuple #1       Tuple #2  Tuple #1      Tuple #2  Tuple #1", "char_count": 397, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 32, "text_raw": "            Record IDs\n\nThe DBMS assigns each logical tuple a unique\n record identifier that represents its physical\n location in the database.\n  File Id, Page Id, Slot #\n  Most DBMSs do not store ids in tuple.\n  SQLite uses ROWID as the true primary key and\n   stores them as a hidden attribute.\nApplications should never rely on these IDs to\n mean anything.", "char_count": 352, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 33, "text_raw": "           Record IDs\n\n\n\n\n\n CTID      ROWID     %%physloc%%     ROWID\n(6-bytes)       (8-bytes)          (8-bytes)          (10-bytes)", "char_count": 123, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 34, "text_raw": "Tuple Layout", "char_count": 12, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 35, "text_raw": "            Tuple layout\n                               Tuple\n                          Header    Attribute Data\n\nA tuple is essentially a sequence of bytes.\n  These bytes do not have to be contiguous.\nIt is the job of the DBMS to interpret those bytes into\n attribute types and values.\nEach tuple is prefixed with a header that contains meta-\n data about it.\n   Visibility info (concurrency control)\n  Bit Map for NULL values.", "char_count": 421, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 36, "text_raw": "             Tuple data\nAttributes are typically stored                                                  Tuple\n in the order that you specify\n                                   Header  a   b   c  d   e\n them when you create the\n table.                                          CREATE TABLE foo (\n                                              INT PRIMARY KEY,This is done for software           a\n                                            b INT NOT NULL,\n engineering reasons (i.e.,           c INT,\n                                            d DOUBLE, simplicity).\n                                            e FLOAT\n                                          );However, it might be more\n efficient to lay them out\n differently.", "char_count": 720, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 37, "text_raw": "      Denormalized tuple data\n\nDBMS can physically\n denormalize (e.g., \"pre-join\")\n                                             CREATE TABLE foo ( related tuples and store them\n                                             a INT PRIMARY KEY,\n together in the same page.                                             b INT NOT NULL,\n  Potentially reduces the          );\n  amount of I/O for common\n                                          CREATE TABLE bar (\n   workload patterns.                                           c INT PRIMARY KEY,\n                                           a INT REFERENCES foo (a), Can make updates more\n                                           );   expensive.", "char_count": 684, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 38, "text_raw": "      Denormalized tuple data\n\n    foo\n                            SELECT * FROM foo JOIN bar\nHeader  a   b\n                            ON foo.a = bar.a;\n\n    bar\nHeader  c   a\n                                  fooHeader  c   a\n                      Header   a   b   c   c   c  . . .Header  c   a\n\n                                         foo        bar", "char_count": 347, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 39, "text_raw": "      Denormalized tuple data\n\n\nNot a new idea.\n IBM System R did this in\n   the 1970s.\n  Several NoSQL DBMSs do\n   this without calling it\n   physical denormalization.", "char_count": 165, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 40, "text_raw": "Other Memory\n    Pools", "char_count": 22, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 41, "text_raw": "        Other memory pools\n\nThe DBMS needs memory for things other than\n just tuples and indexes.\nThese other memory pools may not always\n backed by disk, depends on implementation.\n  Sorting + Join Buffers\n  Query Caches\n  Maintenance Buffers\n  Log Buffers\n  Dictionary Caches", "char_count": 276, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 42, "text_raw": "      Buffer pool organization\n\nMemory region organized as an                Buffer\n array of fixed-size pages.                       Pool\n\n                                                                         frame1page1An array entry is called a frame.\n                                                                     frame2page3\nWhen the DBMS requests a                             frame3\n                                                                     frame4 page, an exact copy is placed into\n one of these frames.\n\n                                              page1  page2  page3  page4Dirty pages are buffered and not\n written to disk immediately                                      On-Disk File\n  Write-Back Cache", "char_count": 734, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 43, "text_raw": "       Buffer pool meta-data\n\nThe page table keeps track of                                           Page       Buffer\n pages                                                 Table         Pool\n\n                                                                                 page1           frame1page1that are currently in memory.                    meta-data\n                                                                              page3\n                                                                                                    meta-data          frame2page3  Usually a fixed-size hash table\n                                                                      frame3page2   protected with latches to ensure              page2\n                                                                                                    meta-data         frame4   thread-safe access.\nAdditional meta-data per page:\n\n                                              page1  page2  page3  page4  Dirty Flag\n  Pin/Reference Counter                  On-DiskFile\n  Access Tracking Information", "char_count": 1092, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 44, "text_raw": "    Page table vs. Page directory\n\nPage directory         Page table\n\nThe mapping from   The mapping from\n page ids to page       page ids to a copy of\n locations in the        the page in buffer\n database files.         pool frames.\n  All changes must be    This is an in-memory\n   recorded on disk to       data structure that\n   allow the DBMS to        does not need to be\n   find on restart.            stored on disk.", "char_count": 423, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 45, "text_raw": "    When a Page is Requested …\n\n1.  If requested page is NOT in the buffer pool:\n    1. Choose an un-pinned (pin count = 0) frame for replacement\n   2. If frame is dirty, write current page to disk, mark as “clean”\n   3. Read requested page into frame\n2. Pin the page and return its address\nIf requests can be predicted (e.g., sequential scans), pages\n can be prefetched\n  Several pages at a time\nWhen the buffer pool is full …\n  Need to evict an existing page\n  Need a page replacement policy", "char_count": 494, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 46, "text_raw": "   Buffer\nReplacement", "char_count": 18, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 47, "text_raw": "    Buffer Replacement Policies\n\nWhen the DBMS needs to free up a frame to\n make room for a new page, it must decide\n which page to evict from the buffer pool.\nGoals:\n  Correctness\n  Accuracy\n  Speed\n  Meta-data overhead", "char_count": 222, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 48, "text_raw": "       LEAST-RECENTLY USED\nMaintain a single timestamp of when\n each page was last accessed.\nWhen the DBMS needs to evict a page,       page0\n select the one with the oldest\n timestamp.                   Q1        page1\n  Keep the pages in sorted order to reduce      page2\n   the search time on eviction.\n                                                       page3\n\n                                                       page4                 page1page0     page0page1     page2\n\n                   Newest ← Oldest                     page5\n               LRU List", "char_count": 562, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 49, "text_raw": "      LRU Replacement Policy\n\n\nLeast Recently Used (LRU)\n   Pinned frame: not available to replace\n   Track time for each frame last unpinned (end of use)\n   Replace the frame which was least recently used\n\n      Need to “find min” on the last used attributed (priority queue)\n   Very common policy: intuitive and simple\n\n      Good for repeated access to popular pages (temporal locality)\nSequential Scan + LRU\n   Lead to sequential flooding\n\n     0% hit rate in cache\n   Repeated sequential scan is very common in DB workload\n\n       Nested-loop join", "char_count": 558, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 50, "text_raw": "        Better Policies: LRU-K\n\nTrack the history of last K references to each page as timestamps\n and compute the interval between subsequent accesses.\n  Can distinguish between reference types\nUse this history to estimate the next time that page is going to be\n accessed.\n  Replace the page with the oldest \"K-th\" access.\n  Balances recency vs. frequency of access.\n  Maintain an ephemeral in-memory cache for recently evicted pages to\n    prevent them from always being evicted.", "char_count": 479, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 51, "text_raw": "          Example: LRU-3\n\n\nPage A\n  Access at T=10 , T=40 , T=80\n\nPage B\n  Access at T=5 , T=30 , T=90", "char_count": 96, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 52, "text_raw": "     MySQL approximate LRU-K\n\n\nSingle LRU linked list but with two entry\n points (\"old\" vs \"young\").\n New pages are always inserted to the head\n   of the old list.\n  If pages in the old list is accessed again,\n   then insert into the head of the young list.", "char_count": 256, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 53, "text_raw": "    MySQL approximate LRU-K\n\n                                          Disk Pages\n\n                                                        page0\n\n                                        Q1                                                        page1\n HEAD   YoungList            HEAD  OldList\n                                                        page2\npage4   page5   page9   page3   page6   page2   page8\n                                                        page3\n\n                                                        page4\n              Newest ←Oldest\n                                                        page5", "char_count": 620, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 54, "text_raw": "    MySQL approximate LRU-K\n\n                                          Disk Pages\n\n                                                        page0\n\n                                        Q1                                                        page1\n HEAD   YoungList            HEAD  OldList\n                                                        page2\npage4   page5   page9   page3   page1   page6   page2\n                                                        page3\n\n                                                        page4\n              Newest ←Oldest\n                                                        page5", "char_count": 620, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 55, "text_raw": "    MySQL approximate LRU-K\n\n                                          Disk Pages\n\n                                                        page0\n\n                                        Q2                                                        page1\n HEAD   YoungList            HEAD  OldList\n                                                        page2\npage4   page5   page9   page3   page1   page6   page2\n                                                        page3\n\n                                                        page4\n              Newest ←Oldest\n                                                        page5", "char_count": 620, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 56, "text_raw": "    MySQL approximate LRU-K\n\n                                          Disk Pages\n\n                                                        page0\n\n                                        Q2                                                        page1\n HEAD   YoungList            HEAD  OldList\n                                                        page2\npage1   page4   page5   page9   page3   page6   page2\n                                                        page3\n\n                                                        page4\n              Newest ←Oldest\n                                                        page5", "char_count": 620, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 57, "text_raw": "     Better policies: Localization\n\nThe DBMS chooses which pages to evict on a per\n query basis.\nThis minimizes the pollution of the buffer pool\n from each query.\n  Keep track of the pages that a query has accessed.\nExample\n  Postgres assigns a limited number of buffer pool\n   pages to a query and uses it as a circular ring buffer.", "char_count": 333, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 58, "text_raw": "    Better policies: Priority hints\n\n\nThe DBMS knows about the context of each\n page during query execution.\n\nIt can provide hints to the buffer pool on\n whether a page is important or not.", "char_count": 187, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 59, "text_raw": "             Dirty Pages\n\nFast Path\n  If a page in the buffer pool is not dirty, then the\n  DBMS can simply \"drop\" it.\nSlow Path\n  If a page is dirty, then the DBMS must write back\n   to disk to ensure that its changes are persisted.\nTrade-off between fast evictions versus dirty\n writing pages that will not be read again in the\n future.", "char_count": 330, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 60, "text_raw": "        Background writing\n\nThe DBMS can periodically walk through the\n page table and write dirty pages to disk.\nWhen a dirty page is safely written, the\n DBMS can either evict the page or just unset\n the dirty flag.\nNeed to be careful that the system doesn't\n write dirty pages before their log records are\n written.", "char_count": 313, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 61, "text_raw": " Buffer Pool\nOptimizations\n             Multiple Buffer Pools\n                 Pre-Fetching\n               Scan Sharing\n               Buffer Pool Bypass", "char_count": 152, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 62, "text_raw": "         Multiple buffer pools\nThe DBMS does not always have a single\n buffer pool for the entire system.\n  Multiple buffer pool instances\n  Per-database buffer pool\n  Per-page type buffer pool\nPartitioning memory across multiple pools\n helps reduce latch contention and improve\n locality.\n  Avoids contention on LRU tracking\n   meta-data.", "char_count": 336, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 63, "text_raw": "         Multiple buffer pools\n\nObject Id                              GET RECORD #123                                Q1\n  Embed an object\n                                                                  HASH(123) % n                                   <ObjectId, PageId, SlotNum>    identifier in record\n   ids and then\n   maintain a mapping\n   from objects to\n   specific buffer pools.\nHashing\n  Hash the page id to\n   select which buffer\n   pool to access.              Buffer Pool #1  Buffer Pool #2", "char_count": 498, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 64, "text_raw": "            Pre-fetching\n\n\nThe DBMS can also prefetch pages based on a\n query plan.\n  Examples: Sequential vs. Index Scans\nSome DBMS prefetch to fill in empty frames\n upon start-up.", "char_count": 172, "is_empty": false}
{"lecture_id": "ADB_Lec02", "source_file": "ADB_Lec02.pdf", "page_num": 65, "text_raw": "", "char_count": 0, "is_empty": true}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 1, "text_raw": "       CSAI 302\n\nAdvanced Database\n\n     Systems\n\n           Lec 03\n   Storage Management [2]", "char_count": 86, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 2, "text_raw": "       Tuple-oriented storage\n\nInsert a new tuple:\n  Check page directory to find a page with a free slot.\n     Retrieve the page from disk (if not in memory).\n  Check slot array to find empty space in page that will fit.\nUpdate an existing tuple using its record id:\n  Check page directory to find location of page.\n     Retrieve the page from disk (if not in memory).\n  Find offset in page using slot array.\n     If new data fits, overwrite existing data.\n     Otherwise, mark existing tuple as deleted and insert new version\n       in a different page.", "char_count": 558, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 3, "text_raw": "            Problems\n\nFragmentation\n  Pages are not fully utilized (unusable space, empty slots).\nUseless Disk I/O\n  DBMS must fetch entire page to update one tuple.\nRandom Disk I/O\n  Worse case scenario when updating multiple tuples is that\n   each tuple is on a separate page.\nWhat if the DBMS cannot overwrite data in pages and could\n only create new pages?\n  Examples: Some object stores, HDFS, Google Colossus", "char_count": 410, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 4, "text_raw": "Log-structured\n   Storage", "char_count": 25, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 5, "text_raw": "       Log-structured Storage\n\nInstead of storing tuples in pages and updating them in-\n place, the DBMS maintains a log that records changes to\n tuples.\n  Each log entry represents a tuple PUT/ DELETE\n   operation.\n  Originally proposed as log-structure merge trees\n   (LSM Trees) in 1996.\nThe DBMS applies changes to an in-memory data\n structure (MemTable) and then writes out the changes\n sequentially to disk (SSTable).", "char_count": 420, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 6, "text_raw": "       Log-structured storage\n\n\n        PUTPUTPUTPUT (key101,a1)(key103,c1)(key101,a2)(key102,b1)\n\n                                     MemTable\nMemory\n\n                                     Key\n                                   PUT (key101,a2)\n                                                  (Low                        SSTable\n                                   PUT (key102,b1)\n            →\n                                   PUT (key103,c1)  Disk                                                              High)", "char_count": 512, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 7, "text_raw": "       Log-structured storage\n\nKey-value storage that appends log records\n on disk to represent changes to tuples (PUT,\n DELETE).                                    SSTable\n  Each log record must contain the tuple’s          Key    DEL (key100)\n   unique identifier.\n                                                                     PUT (key101,a2)                                                                                                                (Low\n  Put records contain the tuple contents.                            →                                                                     PUT (key102,b1)\n  Deletes marks the tuple as deleted.\n                                                                     PUT (key103,c1)                                                                                                                                            High)\nAs the application makes changes to the\n database, the DBMS appends log records to\n the end of the file without checking previous\n log records.", "char_count": 1032, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 8, "text_raw": "     Log-structured compaction\nPeriodically compact SSTAbles to reduce wasted space and speed\n up reads.\n  Only keep the \"latest\" values for each key using a sort- merge\n    algorithm.\n                                         SSTable       SSTable         SSTable\n\n                                                               DEL (key100)         DEL (key100)             PUT (key101,a2)\n                                                               PUT (key101,a3)         PUT (key101,a3)          PUT (key102,b1)\n                                                               PUT (key102,b2)         PUT (key102,b2)          DEL (key103)\n                                                               PUT (key103,c1)         PUT (key103,c1)          PUT (key104,d2)\n                                                               PUT (key104,d2)\n         Newest → Oldest", "char_count": 871, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 9, "text_raw": "             Discussion\n\nLog-structured storage managers are more common\n today than in previous decades.\n  This is partly due to the proliferation of RocksDB.\n\n\n\n\nWhat are some downsides of this approach?\n  Write-Amplification.\n  Compaction is expensive.", "char_count": 247, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 10, "text_raw": "Index-organized\n    Storage", "char_count": 27, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 11, "text_raw": "           Observation\n\nThe two-table storage approach relies on\n indexes to find individual tuples.\n\n Such indexes are necessary because the tables\n   are inherently unsorted.\n\nBut what if the DBMS could keep tuples\n sorted automatically using an index?", "char_count": 246, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 12, "text_raw": "      Index-organized Storage\n\nDBMS stores a table's tuples as the\n value of an index data structure.\n  Still use a page layout that looks like a\n   slotted page.\n  Tuples are typically sorted in page\n   based on key.\nB+Tree pays maintenance costs\n upfront, whereas LSMs pay for it later.", "char_count": 286, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 13, "text_raw": "      Index-organized Storage\n\n\n\nInner\nNodes\n\n\n\n\n                                                                key→  key→  key→\n                                     Header   offset  offset  offsetLeaf\nNodes\n\n\n                                                                      Tuple #3 Tuple #2 Tuple #6", "char_count": 301, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 14, "text_raw": "           Tuple storage\nA tuple is essentially a sequence of bytes prefixed\n with a header that contains meta-data about it.\nIt is the job of the DBMS to interpret those bytes\n into attribute types and values.\nThe DBMS's catalogs contain the schema\n information about tables that the system uses to\n figure out the tuple's layout.\n  CREATE TABLE foo (\n     id INT PRIMARY KEY,             unsigned char[]\n     value BIGINT\n                         header       id             value    );", "char_count": 480, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 15, "text_raw": "        Word-aligned tuples\n\n All attributes in a tuple must be word aligned\n  to enable the CPU to access it without any\n unexpected behavior or additional work.\n\n\n    CREATE TABLE foo (\n32-bits id INT PRIMARY KEY,           unsigned char[]\n      cdate TIMESTAMP,64-bits\n                                         id      cdate     c   zipc\n      color CHAR(2),16-bits\n      zipcode INT32-bits                                    64-bit Word 64-bit Word 64-bit Word 64-bit Word\n    );", "char_count": 475, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 16, "text_raw": "      Word-alignment: Padding\nAdd empty bits after attributes to ensure that\n tuple is word aligned.\nEssentially round up the storage size of types\n to the next largest word size.\n\n   CREATE TABLE foo (\n32-bits id INT PRIMARY KEY,\n                                                                00000000                                        0000\n                                                                00000000                                        000064-bits cdate TIMESTAMP,\n                                                                00000000                                        0000                                     id           Cdate     c   zipc\n 16-bits color CHAR(2),                            00000000                                        0000\n32-bits zipcode INT              64-bitWord   64-bitWord   64-bitWord   64-bitWord\n   );", "char_count": 862, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 17, "text_raw": "    Word-alignment: Reordering\n\nSwitch the order of attributes in the tuples'\n physical layout to make sure they are aligned.\n May still have to use padding to fill remaining space.\n\n\n   CREATE TABLE foo (\n32-bits id INT PRIMARY KEY,                                      id      cdate     c   zipc\n64-bits cdate TIMESTAMP,\n16-bits color CHAR(2),\n32-bits zipcode INT                                                                  000000000000000000000000\n                                      id    zipc     cdate     c   000000000000\n   );                                                                                     000000000000\n\n                                 64-bitWord   64-bitWord   64-bitWord   64-bitWord", "char_count": 720, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 18, "text_raw": "Storage models", "char_count": 14, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 19, "text_raw": "          Storage models\nA DBMS's storage model specifies how it physically\n organizes tuples on disk and in memory.\n  N-ary Storage Model (NSM)\n  Decomposition Storage Model (DSM)\n  Hybrid Storage Model (PAX)\nCan have different performance characteristics\n based on the target workload (OLTP vs. OLAP).\nInfluences the design choices of the rest of the\n DBMS.", "char_count": 355, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 20, "text_raw": "N-ary Storage\n Model (NSM)", "char_count": 26, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 21, "text_raw": "     N-ary Storage Model (NSM)\n\nThe DBMS stores (almost) all attributes for a\n single tuple contiguously in a single page.\n Also commonly known as a row store\nIdeal for OLTP workloads where queries are\n more likely to access individual entities and\n execute write-heavy workloads.\nNSM database page sizes are typically some\n constant multiple of 4 KB hardware pages.", "char_count": 365, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 22, "text_raw": "     NSM: Physical Organization\n\n\nA disk-oriented NSM system stores a tuple's\n fixed-length and variable-length attributes\n contiguously in a single slotted page.\n\nThe tuple's record id (page#, slot#) is how\n the DBMS uniquely identifies a physical tuple.", "char_count": 252, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 23, "text_raw": "    NSM: Physical Organization\n\n\n\n\n       Col A   Col B    Col C\nRow#0   a0      b0       c0\n                                       header\nRow#1   a1      b1       c1\n\nRow#2   a2      b2       c2                                                           Page\nRow#3   a3      b3       c3                 header  a5   b5    c5   header  a4\nRow#4   a4      b4       c4                 b4    c4   header  a3   b3    c3\nRow#5   a5      b5       c5                 header  a2   b2    c2   header  a1                                                                                                                       Database\n                                        b1    c1   header  a0   b0    c0", "char_count": 689, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 24, "text_raw": "        NSM: OLTP example\n\n   SELECT * FROM useracct\n   WHERE userName = ?\n                                               Index   AND userPass = ?\n\n   INSERT INTO useracct\n    VALUES (?,?,…?)\n                        NSM Disk Page\n\n                                                     header  userID userName userPass hostname lastLogin\n\n                                                     header  userID userName userPass hostname lastLogin\n\n                                                     header  userID userName userPass hostname lastLogin                 File\n                                                     headerheader  userID-   userName-     userPass-    hostname-      lastLogin-Disk                          Database", "char_count": 728, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 25, "text_raw": "       NSM: OLAP example\n\n      SELECT COUNT(U.lastLogin),\n            EXTRACT(month FROM U.lastLogin) AS month\n        FROM useracct AS U\n        WHERE U.hostname LIKE '%.gov'\n        GROUP BY EXTRACT(month FROM U.lastLogin)\n\n                        NSM Disk Page\n\n                                                     header  userID userName userPass hostname lastLogin\n\n                                                     header  userID userName userPass hostname lastLogin\n\n                                                     header  userID userName userPass hostname lastLogin                 File\n                                                     header  userID userName userPass hostname lastLoginDisk                          Database\n\n                                     Useless Data!", "char_count": 791, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 26, "text_raw": "          NSM: summary\nAdvantages\n  Fast inserts, updates, and deletes.\n  Good for queries that need the entire tuple (OLTP).\n  Can use index-oriented physical storage for\n   clustering.\nDisadvantages\n  Not good for scanning large portions of the table\n   and/or a subset of the attributes.\n  Terrible memory locality in access patterns.\n  Not ideal for compression because of multiple value\n   domains within a single page.", "char_count": 422, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 27, "text_raw": "Decomposition\nStorage Model\n    (DSM)", "char_count": 37, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 28, "text_raw": " Decomposition Storage Model (DSM)\n\nStore a single attribute for all tuples\n contiguously in a block of data.\n Also known as a \"column store\"\nIdeal for OLAP workloads where read-only\n queries perform large scans over a subset of\n the table’s attributes.\nDBMS is responsible for combining/splitting\n a tuple's attributes when reading/writing.", "char_count": 344, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 29, "text_raw": "     DSM: Physical Organization\n\nStore attributes and meta-data (e.g., nulls) in\n separate arrays of fixed- length values.\n Most systems identify unique physical\n   tuples using offsets into these arrays.\n Need to handle variable-length values.\nMaintain separate pages per attribute with a\n dedicated header area for meta-data about\n entire column.", "char_count": 347, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 30, "text_raw": "    DSM: Physical Organization\n\n                               #1    header         Null bitmap\n                                                              Page  a0   a1   a2   a3   a4   a5\n       Col A   Col B    Col C\nRow#0   a0      b0       c0\n                               #2    header         Null bitmap\nRow#1   a1      b1       c1\n                                         b0   b1   b2   b3   b4   b5\nRow#2   a2      b2       c2                                                              Page\nRow#3   a3      b3       c3\n\nRow#4   a4      b4       c4\n                                          header         Null bitmap\nRow#5   a5      b5       c5            #3                                          c0     c1     c2     c3     c4\n                                          c5                                                              Page", "char_count": 851, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 31, "text_raw": "        DSM: OLAP example\n\n    SELECT COUNT(U.lastLogin),\n         EXTRACT(month FROM U.lastLogin) AS month\n    FROM useracct AS U\n    WHERE U.hostname LIKE '%.gov'\n    GROUP BY EXTRACT(month FROM U.lastLogin)\n\n\n                         DSM Disk Page\n\n                                                                 hostname hostname hostname                                    header\n                     userID                                 lastLogin                                                hostname hostname hostname hostname hostname\n\n                                                hostname hostname hostname hostname hostname\n\n                                                hostname hostname hostname hostname hostnameDisk           File                 userName                               Database             userPass", "char_count": 831, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 32, "text_raw": "        DSM: OLAP example\n\n    SELECT COUNT(U.lastLogin),\n         EXTRACT(month FROM U.lastLogin) AS month\n    FROM useracct AS U\n    WHERE U.hostname LIKE '%.gov'\n    GROUP BY EXTRACT(month FROM U.lastLogin)\n\n\n                         DSM Disk Page\n\n                                                                                      lastlogin   lastlogin   lastlogin                                    header\n                     userID                                 lastLogin                                                               lastlogin   lastlogin   lastlogin   lastlogin   lastlogin\n\n                                                               lastlogin   lastlogin   lastlogin   lastlogin   lastlogin\n\n                                                               lastlogin   lastlogin   lastlogin   lastlogin   lastloginDisk           File                 userName                               Database             userPass", "char_count": 943, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 33, "text_raw": "     DSM: Variable-length Data\n\nPadding variable-length fields to ensure they\n are fixed-length is wasteful, especially for\n large attributes.\nA better approach is to use dictionary\n compression to convert repetitive variable-\n length data into fixed- length values (typically\n 32-bit integers).", "char_count": 292, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 34, "text_raw": "          DSM: Summary\n\nAdvantages\n  Reduces the amount wasted I/O per query because\n   the DBMS only reads the data that it needs.\n  Faster query processing because of increased locality\n   and cached data reuse.\n  Better data compression.\nDisadvantages\n  Slow for point queries, inserts, updates, and deletes\n   because of tuple splitting/stitching/reorganization.", "char_count": 362, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 35, "text_raw": "          OBSERVATION\n\nOLAP queries almost never access a single column in\n a table by itself.\n  At some point during query execution, the DBMS\n   must get other columns and stitch the original tuple\n   back together.\nBut we still need to store data in a columnar format to\n get the storage + execution benefits.\nWe need columnar scheme that still stores attributes\n separately but keeps the data for each tuple physically\n close to each other.", "char_count": 438, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 36, "text_raw": "    Partition\nAttributes Across\n     (PAX)", "char_count": 38, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 37, "text_raw": "       PAX Storage Model\n\nPartition Attributes Across (PAX) is a hybrid\n storage model that vertically partitions\n attributes within a database page.\n  Examples: Parquet, ORC, and Arrow.\nThe goal is to get the benefit of faster\n processing on columnar storage while\n retaining the spatial locality benefits of row\n storage.", "char_count": 319, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 38, "text_raw": "     PAX: Physical Organization\n\nHorizontally partition data into row groups.\nThen vertically partition their attributes into\n column chunks.\nGlobal meta-data directory contains offsets\n to the file's row groups.\n  This is stored in the footer if the file is\n  immutable (Parquet, Orc).\nEach row group contains its own meta-data\n header about its contents.", "char_count": 356, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 39, "text_raw": "     PAX: Physical Organization\n\n\n       Col A   Col B    Col C\nRow#0   a0      b0       c0\n\nRow#1   a1      b1       c1                           Row Group Meta-data                                    ColumnRow#2   a2      b2       c2           Chunk               Group                                             a0   a1   a2     b0   b1   b2\n\nRow#3   a3      b3       c3                                                                  Row   c0     c1     c2\nRow#4   a4      b4       c4\n                                                 Row Group Meta-dataRow#5   a5      b5       c5                                                                                                              Group                                             a3   a4   a5     b3   b4   b5                                                              File\n                                                                  Row   c3     c4     c5\n                                              PAX\n                                                   File Meta-data", "char_count": 1041, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 40, "text_raw": "           Observation\n\nI/O is the main bottleneck if the DBMS fetches\n data from disk during query execution.\nThe DBMS can compress pages to increase the\n utility of the data moved per I/O operation.\nKey trade-off is speed vs. compression ratio\n  Compressing the database reduces DRAM\n   requirements.\n  It may decrease CPU costs during query execution.", "char_count": 348, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 41, "text_raw": "  Database\nCompression", "char_count": 20, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 42, "text_raw": "       Database Compression\nGoal #1: Must produce fixed-length values.\n  Only exception is var-length data stored in separate\n   pool.\nGoal #2: Postpone decompression for as long as\n possible during query execution.\n  Also known as late materialization.\nGoal #3: Must be a lossless scheme.\n  People (typically) don't like losing data.\n  Any lossy compression must be performed by\n   application.", "char_count": 395, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 43, "text_raw": "      Compression Granularity\nBlock-level\n  Compress a block of tuples for the same table.\nTuple-level\n  Compress the contents of the entire tuple (NSM-only).\nAttribute-level\n  Compress a single attribute within one tuple (overflow).\n  Can target multiple attributes for the same tuple.\nColumn-level\n  Compress multiple values for one or more attributes\n   stored for multiple tuples (DSM-only).", "char_count": 398, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 44, "text_raw": "        NAÏVE Compression\nCompress data using a general-purpose\n algorithm.\nScope of compression is only based on the\n data provided as input.\n LZO (1996), LZ4 (2011), Snappy (2011), Oracle OZIP\n   (2014), Zstd (2015)\nConsiderations\n  Computational overhead\n  Compress vs. decompress speed.", "char_count": 288, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 45, "text_raw": "   MYSQL Innodb Compression\n\n\n         Buffer Pool         Database File\n\n            mod log               mod logWriteRead                                                    [1,2,4,8] KB           Compressed Page0            Compressed Page0\n\n                                mod log\nRead                               Compressed Page1          Uncompressed\n                   16 KB\n              Page0                 mod log\n                                      Compressed Page2", "char_count": 479, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 46, "text_raw": "        NAÏVE Compression\n\n\nThe DBMS must decompress data first before\n it can be read and (potentially) modified.\n This limits the \"scope\" of the compression\n  scheme.\nThese schemes also do not consider the high-\n level meaning or semantics of the data.", "char_count": 249, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 47, "text_raw": "           Observation\n\nIdeally, we want the DBMS to operate on\n compressed data without decompressing it\n first.\n                       Database\n                         Magic!\n    SELECT * FROM users               SELECT * FROM users\n    WHERE name = 'Andy'            WHERE name = XX\n\n\n\n              NAME      SALARY                             NAME     SALARY\n              Andy       99999                           XX       AA\n            Jignesh     88888                           YY       BB", "char_count": 491, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 48, "text_raw": "      Compression Granularity\nBlock-level\n  Compress a block of tuples for the same table.\nTuple-level\n  Compress the contents of the entire tuple (NSM-only).\nAttribute-level\n  Compress a single attribute within one tuple (overflow).\n  Can target multiple attributes for the same tuple.\nColumn-level\n  Compress multiple values for one or more attributes\n   stored for multiple tuples (DSM-only).", "char_count": 398, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 49, "text_raw": " Columnar\nCompression", "char_count": 20, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 50, "text_raw": "      Columnar Compression\n\nRun-length Encoding\nBit-Packing Encoding\nBitmap Encoding\nDelta / Frame-of-Reference Encoding\nIncremental Encoding\nDictionary Encoding", "char_count": 161, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 51, "text_raw": "        Run-length encoding\n\nCompress runs of the same value in a single\n column into triplets:\n The value of the attribute.\n The start position in the column segment.\n The # of elements in the run.\nRequires the columns to be sorted\n intelligently to maximize compression\n opportunities.", "char_count": 284, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 52, "text_raw": "        Run-length Encoding\n\n\n                             Compressed        Original\n                                 Data           Data\n\n\n                                                id   isDead                                                                                id    isDead\n                                                 1   (Y,0,3)                                                                                1       Y\n                                                 2   (N,3,1)\nSELECT isDead, COUNT(*)                                         2       Y\n                                                 3   (Y,4,1)                                                                                3       Y\nFROM users                                                 4   (N,5,1)                                                                                4       N\nGROUP BY isDead                         6   (Y,6,2)                                                                                6       Y\n\n                                                                                7       N                                                 7  RLETriplet\n                                                 8   - Value                                                                                8       Y\n                                                                    - Offset                                                 9                                                                                9       Y                                                                    - Length", "char_count": 1615, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 53, "text_raw": "  Run-length Encoding\n\n\nSorted Data              Compressed Data\n\n id      isDead                           id       isDead\n 1         Y                                           1       (Y,0,6)\n 2         Y                                           2       (N,7,2)\n 3         Y                                           3\n 6         Y                                           6\n 8         Y                                           8\n 9         Y                                           9\n 4         N                                           4\n 7         N                                           7", "char_count": 605, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 54, "text_raw": "               Bit Packing\n\n\n                                                                      Original\n                                                             DataIf the values for an integer attribute is\n smaller than the range of its given           int32                                                                      13\n data type size, then reduce the number      191\n                                                                      56 of bits to represent each value.\n                                                                      92\n                                                                      81\n                                                                      120\nUse bit-shifting tricks to operate on          231\n                                                                      172 multiple values in a single word.", "char_count": 860, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 55, "text_raw": "              Bit Packing\n\nOriginal                                            Original\n Data                                        Data\n int32                                             int32\n   13      00000000 00000000 00000000 00001101               13      00001101\n  191     00000000 00000000 00000000 10111111              191      10111111\n   56      00000000 00000000 00000000 00111000               56      00111000\n   92      00000000 00000000 00000000 01011100               92      01011100\n   81      00000000 00000000 00000000 01010001               81      01010001\n  120     00000000 00000000 00000000 01111000              120      01111000\n  231     00000000 00000000 00000000 11100111              231      11100111\n  172     00000000 00000000 00000000 10101100              172      10101100\n\n                                       Compressed:                 Original:\n         8 × 32-bits = 256 bits          8 × 8-bits = 64 bits", "char_count": 940, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 56, "text_raw": "     Patching / mostly Encoding\n\n\n\nA variation of bit packing for when an\n attribute's values are \"mostly\" less than the\n largest size, store them with smaller data type.\n The remaining values that cannot be\n   compressed are stored in their raw form.", "char_count": 248, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 57, "text_raw": "   Patching / mostly Encoding\n\n  Original                Compressed Data\n   Data\n   int32                 mostly8\n                                          offset    value\n     13                     13\n                                     3     99999999\n    191                    191\n 999999999                 XXX\n     92                     92\n     81                     81\n                        Compressed:    120                    120\n    231                    231    (8 × 8-bits) +16-bits + 32-bits\n    172                    172   = 112 bits\nOriginal:\n8 × 32-bits = 256 bits", "char_count": 584, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 58, "text_raw": "         Bitmap Encoding\n\nStore a separate bitmap for each unique\n value for an attribute where an offset in the\n vector corresponds to a tuple.\n The ith position in the Bitmap corresponds to the\n    ith tuple in the table.\n  Typically segmented into chunks to avoid\n   allocating large blocks of contiguous memory.\nOnly practical if the value cardinality is low.\nSome DBMSs provide bitmap indexes.", "char_count": 394, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 59, "text_raw": "         Bitmap encoding\n\n                            CompressedOriginal Data\n                                                           isDead                             Data                                             2 × 8-bits      id  isDead\n                                          id      Y   N                                             = 16-bits      1     Y\n                                           1       1   0\n      2     Y\n                                           2       1   0\n      3     Y\n                                           3       1   0\n      4     N                                   8 × 2-bits                                           4       0   1\n      6     Y                                   = 16-bits                                           6       1   0\n      7     N\n                                           7       0   1\n      8     Y\n                                           8       1   0\n      9     Y\n                                           9       1   0\n  Original:                               Compressed:\n   8 × 8-bits = 64 bits                                     16-bits +16-bits = 32-bits", "char_count": 1143, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 60, "text_raw": "     Bitmap encoding: Example\n\nAssume we have 10 million tuples.                                CREATE TABLE customer (\n 43,000 zip codes in the US.                                                  id INT PRIMARY KEY,\n  10000000  32-bits = 40 MB       name VARCHAR(32),             ×\n                                           email VARCHAR(64),  10000000  43000 = 53.75 GB             ×                                          address VARCHAR(64),\nEvery time the application inserts a    zip_code INT\n new tuple, the DBMS must extend        );\n 43,000 different bitmaps.\nThere are compressed data\n structures for sparse data sets:\n  Roaring Bitmaps", "char_count": 651, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 61, "text_raw": "           Delta Encoding\n\nRecording the difference between values that\n follow each other in the same column.\n\n\n\n\n\n                                                                                                      →\n  Store base value in-line or in a separate look-up\n   table.\n Combine with RLE to get even better\n   compression ratios.\nFrame-of-Reference Variant: Use global min\n value.", "char_count": 385, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 62, "text_raw": "           Delta Encoding\n\n\n        Original           Compressed          Compressed\n        Data                Data                Data\n      time64  temp           time64  temp                                                            temp\n      12:00  99.5            12:00   99.5                                                            99.5                                                    time64\n      12:01  99.4             +1    -0.1                                                            -0.1                                                     12:00\n      12:02  99.5             +1    +0.1                                                            +0.1                                                    (+1,4)\n      12:03  99.6             +1    +0.1                                                            +0.1\n      12:04  99.4             +1    -0.2                                                            -0.2\n\n5 × 64bits         64bits + (4 × 16bits)     64bits + (2 × 16bits)\n= 320 bits                = 128 bits             = 96 bits", "char_count": 1060, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 63, "text_raw": "       Dictionary Compression\nReplace frequent values with smaller fixed-length\n codes and then maintain a mapping (dictionary) from\n the codes to the original values\n  Typically, one code per attribute value.\n  Most widely used native compression scheme in DBMSs.\nThe ideal dictionary scheme supports fast encoding\n and decoding for both point and range queries.\n  Encode/Locate: For a given uncompressed value,\n   convert it into its compressed form.\n  Decode/Extract: For a given compressed value, convert\n     it back into its original form.", "char_count": 544, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 64, "text_raw": "    Dictionary: Order-preserving\n\nThe encoded values need to support the\n same collation as the original values.\n\n   SELECT * FROM users               SELECT * FROM users\n   WHERE name LIKE 'And%'          WHERE name BETWEEN 10 AND 20\n\n       Original Data              Compressed Data\n\n              name                         name      value    code\n             Andrea                         10      Andrea    10\n           Mr.Pickles                       40       Andy     20\n              Andy                          20     Jignesh    30                                                                                                                                                Sorted\n                                           30            Jignesh                              Mr.Pickles  40                  Dictionary\n           Mr.Pickles                       40", "char_count": 879, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 65, "text_raw": "     Order-preserving encoding\n\nSELECT name FROM users                     Still must perform\n                                   scan on column WHERE name LIKE 'And%'\n\nSELECT DISTINCT name FROM users        Only need to\n                                     access dictionary WHERE name LIKE 'And%'\n\n      Original Data              Compressed Data\n\n             name                         name      value    code\n            Andrea                         10      Andrea    10\n          Mr.Pickles                       40       Andy     20\n             Andy                          20     Jignesh    30                                                                                                                                               Sorted\n                                           30            Jignesh                              Mr.Pickles  40                  Dictionary\n          Mr.Pickles                       40", "char_count": 933, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 66, "text_raw": "             Conclusion\n\nIt is important to choose the right storage model\n for the target workload:\n OLTP → Row Store\n OLAP → Column Store\nDBMSs can combine different approaches for\n even better compression.\nDictionary encoding is probably the most useful\n scheme because it does not require pre-sorting.", "char_count": 297, "is_empty": false}
{"lecture_id": "ADB_Lec03", "source_file": "ADB_Lec03.pdf", "page_num": 67, "text_raw": "", "char_count": 0, "is_empty": true}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 1, "text_raw": "       CSAI 302\n\nAdvanced Database\n\n     Systems\n           Lec 04\n   Indexing Structures and\n      Implementation", "char_count": 107, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 2, "text_raw": "               Index\n\nA data structure that improves the speed of\n data retrieval operations on a database table.\nBuilt on one or more columns of a table and\n store a sorted copy of the indexed data along\n with pointers to the corresponding rows in the\n main table.\n  Example: B+Tree", "char_count": 271, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 3, "text_raw": "         Types of indexes\n\nSparse                    Dense\n\n                  One entry per recordOne entry per data block\nRequires data to be      Data do not have to be\n sorted                   sorted\nIdentifies the first                  Can tell if a given\n record of the block                        record exists without\n  Faster access            accessing the file", "char_count": 371, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 4, "text_raw": "   Indexes based on primary keys\n\nEach key value corresponds to a specific\n record\nTwo cases to consider:\n  Table is sorted on its primary key\n   Can use a sparse index\n  Table is either non-sorted or sorted on another\n   field\n   Must use a dense index", "char_count": 256, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 5, "text_raw": "      Sparse Index\n\n\n\n\n\n                               .Alan              Ahmed                  …   …\n                               .Dana                Amita                  …   …\n                               .Gina                Brenda                  …   …\n                       Carlos                  …   …\n\n                   Dana                  …   …\n                     Dino                  …   …\n                     Emily                  …   …\n                     Frank                  …   …", "char_count": 509, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 6, "text_raw": "      Dense Index\n\n\n\nAhmed            Ahmed                  …   …\nAmita                Frank                  …   …\nBrenda               Brenda                  …   …\nCarlos              Dana                  …   …\nDana\nDino                 Emily                  …   …\nEmily                Dino                  …   …\nFrank                  Carlos                  …   …\n                    Amita                  …   …", "char_count": 415, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 7, "text_raw": "    Indexes based on other fields\n\nEach key value may correspond to more than\n one record\n  clustering index\nTwo cases to consider:\n  Table is sorted on the field\n   Can use a sparse index\n  Table is either non-sorted or sorted on another\n   field\n   Must use a dense index", "char_count": 276, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 8, "text_raw": " Sparse clustering index\n\n\n\n\n\n                               .Austin            Ahmed                           Austin…\n                               .Dallas                Frank                           Austin…\n                               .Laredo               Brenda                           Austin…\n                   Dana    Dallas                      …\n                     Emily   Dallas                      …\n                     Dino    Dallas                      …\n                       Carlos                           Laredo…\n                    Amita                           Laredo…", "char_count": 605, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 9, "text_raw": "  Dense clustering index\n\n\n\nAustin                 Ahmed                           Austin…Austin                    Amita                           Laredo…Austin                    Brenda                           Austin…\nDallas                       Carlos                           Laredo…Dallas\n                   Dana    DallasDallas                   …\n                     Dino    DallasLaredo                  …\n                     Emily   DallasLaredo                  …\n                     Frank                           Austin…", "char_count": 538, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 10, "text_raw": "   Another realization\n\n\n\nAustin             Ahmed                           Austin…\n                               .Dallas                Amita                           Laredo…\n                               .Laredo                     Brenda                           Austin…\n                       Carlos                           Laredo…\n                    Dana    Dallas                      … We save space                     Dino    Dallas                      …  and add one extra\n                      Emily   Dallas                      …  level of indirection\n                     Frank                           Austin…", "char_count": 631, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 11, "text_raw": "B-trees and B+\n    trees", "char_count": 24, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 12, "text_raw": "             Motivation\n\nTo have dynamic indexing structures that can\n evolve when records are added and deleted\n  Static indexes are completely rebuilt\nOptimized for searches on block devices\nBoth B trees and B+ trees are not binary\n  Objective is to increase branching factor to\n   reduce the number of device accesses", "char_count": 312, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 13, "text_raw": "           B-Tree family\n\nB-Tree (1970)\nB+Tree (1973)\nB* Tree (1977)\nBlinkTree (1981)\nB𝛆-Tree (2003)\nBw-Tree (2013)", "char_count": 110, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 14, "text_raw": "    Binary vs. higher-order tree\n\n                     Higher-order trees:\nBinary trees:                         Designed for searching\n  Designed for in-          data on block devices\n  memory searches                       Try to minimize the\n  Try to minimize the     number of device\n                              accesses  number of memory\n   accesses                   Searching within a\n                                   block is cheap!", "char_count": 448, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 15, "text_raw": "            B trees\n\n\nGeneralization of binary search trees\n  Not binary trees\n The B stands for Bayer (or Boeing)\nDesigned for searching data stored on block-\n oriented devices", "char_count": 169, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 16, "text_raw": "       A very small B tree\n\n\n\n\n\nBottom nodes are leaf nodes: all their\n pointers are NULL", "char_count": 83, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 17, "text_raw": "    Searching the tree\n\n\n\n\n\n                             keys > 16keys < 7\n\n\n\n               7 < keys < 16", "char_count": 102, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 18, "text_raw": "          Balancing B trees\n\n\n\n\nObjective is to ensure that all terminals\n nodes be at the same depth", "char_count": 92, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 19, "text_raw": "  Insertions\n\n\n\n1\n\n\n1   2\n\n1   2   3         2\n\n                1         3", "char_count": 73, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 20, "text_raw": " Insertions\n\n\n        2\n    1        3  4\n\n        2\n    1        3  4   5\n\n        2  4\n1       3       5", "char_count": 105, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 21, "text_raw": "   Insertions\n\n\n\n\n        2  4\n1       3       5  6\n\n\n        2  4\n1       3       5  6   7", "char_count": 88, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 22, "text_raw": "  Insertions\n\n\n        2  4\n1       3      6\n        5       7\n\n         2  4   6\n 1       3\n        5       7", "char_count": 108, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 23, "text_raw": "       Insertions\n\n\n\n\n                2  4   6\n          1       3\n               5       7\n\n              4\n\n      2          6\n\n1       3       5       7", "char_count": 148, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 24, "text_raw": "      Two basic operations\n\nSplit:\n When trying to add to a full node\n                                             5  6    7\n  Split node at central value\n                                             6\n\n                                             5      7\nPromote:\n Must insert root of split node higher up\n May require a new split", "char_count": 332, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 25, "text_raw": "Insertion in B-Trees", "char_count": 20, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 26, "text_raw": "Insertion in B-Trees", "char_count": 20, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 27, "text_raw": "             B+ trees\n\n\n\nVariant of B trees\nTwo types of nodes\n  Internal nodes have no data pointers\n  Leaf nodes have no in-tree pointers", "char_count": 130, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 28, "text_raw": "              B+Tree\n\nA self-balancing, ordered m-way tree\nfor searches, sequential access, insertions, and\n deletions in O(logmn) where m is the tree fanout.\n  It is perfectly balanced (i.e., every leaf node is at the same\n   depth in the tree)\n  Every node other than the root is at least half-full\n    m/2-1 ≤ #keys ≤ m-1\n  Every inner node with k keys has k+1 non-null children.\n  Optimized for reading/writing large data blocks.", "char_count": 426, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 29, "text_raw": "         B+Tree Example\n\n           <node*>|<key>|<node*>|…|<key>|<node*>\n\n                         20     Root Node\n                  <20             ≥20\n\n             10       Sibling Pointers  35     Inner / Non-Leaf Nodes\n\n         <10        ≥10          <35        ≥35\n\n       6          10          20  31      38  44  Leaf Nodes\n\n                Index Key(s) Low → High\n\n<node*>|<key>|<value>|…|<key>|<value>|<node*><key>|<value>|<key>|<value>", "char_count": 442, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 30, "text_raw": "             Nodes\n\nEvery B+Tree node is comprised of an array of\n key/value pairs.\n  The keys are derived from the index's target\n    attribute(s).\n  The values will differ based on whether the node is\n    classified as an inner node or a leaf node.\nThe arrays are (usually) kept in sorted key order.\nStore all NULL keys at either first or last leaf\n nodes.", "char_count": 350, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 31, "text_raw": "", "char_count": 0, "is_empty": true}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 32, "text_raw": "             Searches\ndef tree_search (k, node) :\n     if node is a leaf :\n      return node\n    elif k < k_0 :\n      return tree_search(k, p_0)\n  …\n    elif k_i ≤ k < k_{i+1}\n      return tree_search(k, p_{i+1})\n  …\n    elif k_d ≤ k\n      return tree_search(k, p_{d+1});", "char_count": 258, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 33, "text_raw": "         Insertion in B+ Trees\n\n1. Navigate to the correct leaf node\n2. Insert the new key in sorted order\n3. If overflow occurs:\n  Split the leaf node\n Push the middle key to the parent\n This process may propagate up to the root", "char_count": 226, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 34, "text_raw": "             Insertions\n\ndef insert (entry) :\n   Find target leaf L\n   if L has less than m – 2 entries :\n     add the entry\n     else :\n      Allocate new leaf L'\n     Pick the m/2 highest keys of L and move them to L'\n      Insert highest key of L and corresponding address leaf into the parent\n      node\n      If the parent is full :\n             • Split it and add the middle key to its parent node\n     Repeat until a parent is found that is not full", "char_count": 452, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 35, "text_raw": "          B+TREE – INSERT\n\nFind correct leaf node L.\nInsert data entry into L in sorted order.\nIf L has enough space, done!\nOtherwise, split L keys into L and a new node L2\n Redistribute entries evenly, copy up middle key.\n Insert index entry pointing to L2 into parent of L.\nTo split inner node, redistribute entries evenly, but\npush up middle key.", "char_count": 346, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 36, "text_raw": "   Insertions\n\n\n\n1\n\n\n1   2\n\n1   2   3         2\n\n                1   2     3", "char_count": 73, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 37, "text_raw": "  Insertions\n\n\n        2\n    1  2    3  4\n\n        2\n    1  2     3  4   5\n\n        2  4\n1  2    3  4   5", "char_count": 103, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 38, "text_raw": "   Insertions\n\n\n\n\n        2  4\n1  2    3  4   5  6\n\n\n        2  4\n1  2    3  4   5  6   7", "char_count": 86, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 39, "text_raw": "  Insertions\n\n\n        2  4\n1  2    3  4   6\n        5  6    7\n\n         2  4   6\n 1  2         3  4\n        5  6    7", "char_count": 116, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 40, "text_raw": "     Insertions\n\n\n                2  4   6\n          1       3\n               5       7\n\n              4\n\n      2          6\n\n1       3       5       7", "char_count": 146, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 41, "text_raw": "         Insert\n\n                        9\n\n\n          5                                   16  30\n\n\n 1 3        5 6              9          30 40                                   16  17\n\n\n• Insert a pair with key = 2.\n\n• New pair goes into a full node.", "char_count": 244, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 42, "text_raw": "  Insert Into A Full Node\nInsert new pair so that the keys\n are in ascending order.\n                     1 2 3\n\n • Split into two nodes.\n\n               1       2 3\n\n• Insert smallest key in new node and pointer\n  to this new node into parent.\n\n                        2\n\n                   1       2 3", "char_count": 301, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 43, "text_raw": "          Insert\n\n\n                         9\n\n\n           5    2                                    16  30\n\n                     2  3\n    1         5  6               9          30 40                                    16  17\n\n\n\n\n• Insert an index entry 2 plus a pointer into parent.", "char_count": 274, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 44, "text_raw": "          Insert\n\n\n                         9\n\n\n          2  5                                    16  30\n\n\n   1     2  3    5  6            9          30 40                                    16  17\n\n\n\n• Now, insert a pair with key = 18.", "char_count": 227, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 45, "text_raw": "          Insert\n\n\n                         9\n                                            17\n\n          2  5                                    16  30                                                17  18\n\n\n   1     2  3    5  6            9     16   30 40\n\n\n\n• Now, insert a pair with key = 18.\n• Insert an index entry17 plus a pointer into parent.", "char_count": 339, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 46, "text_raw": "          Insert\n\n                                         17                      9\n\n\n       2  5                        16           30\n\n\n1     2  3    5  6               9     16    17  18  30  40\n\n\n\n  • Now, insert a pair with key = 18.\n  • Insert an index entry17 plus a pointer into parent.", "char_count": 286, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 47, "text_raw": "          Insert\n\n                        9  17\n\n\n          2  5            16          30\n\n\n   1     2  3    5  6   9     16  17  18  30  40\n\n\n\n• Now, insert a pair with key = 7.", "char_count": 169, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 48, "text_raw": "Insertion in B+Trees", "char_count": 20, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 49, "text_raw": "         Deletion in B+Trees\n\nDeletion involves:\n  1. Finding and removing the key from the\n   appropriate leaf node\n  2. Rebalancing the tree to maintain B+ Tree\n   properties:\n    Borrowing keys from siblings or\n   Merging nodes if necessary", "char_count": 239, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 50, "text_raw": "          B+TREE – DELETE\nStart at root, find leaf L where entry belongs.\nRemove the entry.\nIf L is at least half-full, done!  If L has\nonly m/2-1 entries,\n → Try to re-distribute, borrowing from sibling (adjacent node\n     with same parent as L).\n → If re-distribution fails, merge L and sibling.\nIf merge occurred, must delete entry (pointing to L or\nsibling) from parent of L.", "char_count": 374, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 51, "text_raw": "              Deletions\n\n\ndef delete (record) :\n   Locate target leaf and remove the entry\n   If leaf is less than half full:\n     Try to re-distribute, taking from sibling (adjacent node with same\n       parent)\n      If re-distribution fails:\n             • Merge leaf and sibling\n             • Delete entry to one of the two merged leaves\n             • Merge could propagate to root", "char_count": 378, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 52, "text_raw": "         Delete\n\n\n                         9\n\n\n          2  5                                    16  30\n\n\n   1     2  3    5  6            9     17   30 40\n\n\n\n• Delete pair with key = 16.\n• Note: delete pair is always in a leaf.", "char_count": 219, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 53, "text_raw": "         Delete\n\n\n                         9\n\n\n          2  5                                    16  30\n\n\n   1     2  3    5  6            9     17   30 40\n\n\n\n• Delete pair with key = 1.\n\n• Get >= 1 from adjacent sibling and update parent key.", "char_count": 234, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 54, "text_raw": "         Delete\n\n\n                         9\n\n\n          3  5                                    16  30\n\n\n   2       3    5  6            9     17   30 40\n\n\n\n• Delete pair with key = 1.\n\n• Get >= 1 from sibling and update parent key.", "char_count": 224, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 55, "text_raw": "         Delete\n\n\n                         9\n\n\n          3  5                                    16  30\n\n\n   2       3    5  6            9     17   30 40\n\n\n\n• Delete pair with key = 2.\n\n• Merge with sibling, delete in-between key in parent.", "char_count": 232, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 56, "text_raw": "         Delete\n\n\n                         9\n\n\n           5                                    16  30\n\n\n   3                           9     17   30 40               5  6\n\n\n\n• Delete pair with key = 3.\n\n•Get >= 1 from sibling and update parent key.", "char_count": 239, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 57, "text_raw": "         Delete\n\n\n                         9\n\n\n           6                                    16  30\n\n\n   5           6               9     17   30 40\n\n\n\n• Delete pair with key = 9.\n\n• Merge with sibling, delete in-between key in parent.", "char_count": 229, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 58, "text_raw": "        Delete\n\n\n                      9\n\n\n        6                         30\n\n\n                                     30  40                              175           6", "char_count": 162, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 59, "text_raw": "         Delete\n\n\n                         9\n\n\n           6                                    16  30\n\n\n   5           6               9     17   30 40\n\n\n\n• Delete pair with key = 6.\n\n• Merge with sibling, delete in-between key in parent.", "char_count": 229, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 60, "text_raw": "         Delete\n\n\n                         9\n\n\n                                    16  30\n\n\n   5                           9     17   30 40\n\n\n\n• Index node becomes deficient.\n\n•Get >= 1 from sibling, move last one to parent, get\nparent key.", "char_count": 231, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 61, "text_raw": "         Delete\n\n\n                         16\n\n\n            9                                     30\n\n\n   5                                 17   30 40               9\n\n\n\n• Delete 9.\n\n• Merge with sibling, delete in-between key in parent.", "char_count": 228, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 62, "text_raw": "         Delete\n\n\n                         16\n\n\n                                     30\n\n\n   5                                 17   30 40\n\n\n\n•Index node becomes deficient.\n\n• Merge with sibling and in-between key in parent.", "char_count": 214, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 63, "text_raw": "         Delete\n\n\n\n\n\n          16 30\n\n\n           17   30  40   5\n\n\n\n•Index node becomes deficient.\n\n• It’s the root; discard.", "char_count": 117, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 64, "text_raw": "          Leaf node values\n\n1: Record IDs\n  A pointer to the location of the tuple to\n    which the index entry corresponds.\n     Most common implementation.\n2: Tuple Data\n   Index-Organized Storage\n  Primary Key Index\n     Leaf nodes store the contents of the tuple.\n  Secondary Indexes\n     Leaf nodes store tuples' primary key as\n         their values.", "char_count": 354, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 65, "text_raw": "         B-TREE VS. B+TREE\n\n\nThe original B-Tree from 1971 stored keys\n and values in all nodes in the tree.\n More space-efficient, since each key only\n   appears once in the tree.\nA B+Tree only stores values in leaf nodes.\n  Inner nodes only guide the search process.", "char_count": 263, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 66, "text_raw": "B+Tree design\n   choices\n               Node Size\n            Merge Threshold\n             Variable-Length Keys\n              Intra-Node Search", "char_count": 143, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 67, "text_raw": "            Node Size\n\nThe slower the storage device, the larger the\n optimal node size for a B+Tree.\n HDD: ~1MB\n  SSD: ~10KB\n  In-Memory: ~512B\nOptimal sizes can vary depending on the\n workload\n  Leaf Node Scans vs. Root-to-Leaf Traversals", "char_count": 234, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 68, "text_raw": "         Merge Threshold\nSome DBMSs do not always merge nodes when\n they are half full.\n  Average occupancy rate for B+Tree nodes is 69%.\nDelaying a merge operation may reduce the\n amount of reorganization.\nIt may also be better to let underfilled nodes exist\n and then periodically rebuild entire tree.\nThis is why PostgreSQL calls their B+Tree a \"non-\n balanced\" B+Tree (nbtree).", "char_count": 377, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 69, "text_raw": "        Variable-length Keys\nPointers\n  Store the keys as pointers to the tuple’s attribute.\nVariable-Length Nodes\n  The size of each node in the index can vary.\n  Requires careful memory management.\nPadding\n  Always pad the key to be max length of the key type.\nKey Map / Indirection\n  Embed an array of pointers that map to the key +\n   value list within the node.", "char_count": 367, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 70, "text_raw": "         Intra-node Search\nLinear\n  Scan node keys from beginning to end.\n Use SIMD to vectorize comparisons.\n   Find Key=8\n\n\n                      0   0   0   0  1   0   0   0\n\n                      4   5   6   7   8   9  10\n\n\n                      8   8   8   8  8   8   8   8", "char_count": 272, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 71, "text_raw": "         Intra-node Search\nBinary\n Jump to middle key\n  Pivot left/right depending on comparison.\n   Find Key=8\n\n\n\n\n\n                              →\n\n\n\n\n                              →                   4   5   6   7   8   9  10", "char_count": 222, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 72, "text_raw": "         Intra-node Search\nInterpolation\n  Approximate location of desired key based on\n  known distribution of keys.\n\n\n\n\n\n                              →\n   Find Key=8\n\n\n                              →                   4   5   6   7   8   9  10\n\n\n                            𝟖−𝟒\n                  Offset: 𝟏𝟎−𝟒× 𝟕= 𝟒", "char_count": 310, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 73, "text_raw": " Optimizations\n\n  Prefix Compression                  Deduplication\n\nSuffix Truncation                     Pointer Swizzling\n\nBulk Insert                          Buffered Updates", "char_count": 178, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 74, "text_raw": "         Prefix compression\n\nSorted keys in the same leaf\n node are likely to have the      robbed  robbing  robot\n same prefix.\nInstead of storing the entire                                                        Prefix: rob\n                                                   bed  bing  ot key each time, extract\n common prefix and store only\n unique suffix for each key.", "char_count": 365, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 75, "text_raw": "            Deduplication\n\nNon-unique indexes can\n end up storing multiple                                                      K1   V1   K1  V2   K1  V3  K2  V4\n copies of the same key in\n leaf nodes.\nThe leaf node can store the    K1   V1  V2  V3  K2  V4\n key once and then maintain\n a \"posting list\" of tuples with\n that key", "char_count": 317, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 76, "text_raw": "          Suffix truncation\n\n                                                  abcdefghijk  lmnopqrstuvThe keys in the inner\n nodes are only used to\n \"direct traffic\".                              … …       … …\n We don't need the entire\n   key.\n                                             abc lmnStore a minimum prefix\n that is needed to correctly\n route probes into the       … …       … …\n index.", "char_count": 392, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 77, "text_raw": "          Pointer swizzling\nNodes use page ids to                                         FindKey>3 reference other nodes in the\n                                                   6   9 index.                                                     Page #2\nThe DBMS must get the                    Page #3\n memory location from the page                                                             1   3          6   7\n table during traversal.\n                                                             Page #2 →<Page*>If a page is pinned in the buffer                                                             Page #3 →<Page*>\n pool, then we can store raw\n\n                                                                                                                      Header        Header        Header pointers instead of page ids.                                                                          Pool\n                                             1   2   3This avoids address lookups\n from the page table.                                               Buffer", "char_count": 1068, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 78, "text_raw": "             Bulk insert\n\nThe fastest way to build a new B+Tree for an\n existing table is to first sort the keys and then\n build the index from the bottom up.\n        Keys: 3, 7, 9, 13, 6, 1\n Sorted Keys: 1, 3, 6, 7, 9, 13\n\n                                          6   9\n\n\n\n                                      1   3          6   7          9  13", "char_count": 336, "is_empty": false}
{"lecture_id": "ADB_Lec04", "source_file": "ADB_Lec04.pdf", "page_num": 79, "text_raw": "", "char_count": 0, "is_empty": true}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 1, "text_raw": "       CSAI 302\n\nAdvanced Database\n\n     Systems\n           Lec 05\n     Query Processing\n     & Optimization [1]", "char_count": 105, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 2, "text_raw": "        QUERY EXECUTION\nA query plan is a DAG of               SELECT R.id, S.cdate\n                                                 FROM R JOIN S operators.\n                                                   ON R.id = S.id\nA pipeline is a sequence of            WHERE S.value > 100\n operators where tuples\n                                                                  Pipeline #2\n continuously flow between them                                     without intermediate storage.                   R.id, S.cdate\nA pipeline breaker is an operator        ⨝R.id=S.id\nthat cannot finish until all its                                                           value>100\n children emit all their tuples.\n                    R   S  Joins (Build Side), Subqueries, Order\n                                                      Pipeline #1   By", "char_count": 835, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 3, "text_raw": "Query Execution", "char_count": 15, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 4, "text_raw": "         Processing Model\n\nA DBMS's processing model defines how the system executes a\n query plan and moves data from one operator to the next.\n   Different trade-offs for workloads (OLTP vs. OLAP).\nEach processing model has two types of execution paths:\n  Control Flow\n    How the DBMS invokes an operator.\n  Data Flow\n    How an operator sends its results.\nThe output of an operator can be either whole tuples (NSM) or\n subsets of columns (DSM).", "char_count": 447, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 5, "text_raw": "     Processing Model\n\n\nIterator Model\n• Most Common\n\n  Vectorized / Batch Model\n   • Common\n\nMaterialization Model\n• Rare", "char_count": 117, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 6, "text_raw": "            Iterator Model\n\nEach query plan operator implements a Next()\n function.\n On each invocation, the operator returns either a single\n   tuple or a EOF marker if there are no more tuples.\n  The operator implements a loop that calls Next() on its\n   children to retrieve their tuples and then process them.\nEach operator implementation also has Open() and\n Close() functions.\nAlso called Volcano or Pipeline Model.", "char_count": 414, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 7, "text_raw": "            Iterator model\n\n                                              SELECT R.id, S.cdate\n                    for t in\n          Next()                                   FROM R JOIN S                      child.Next():\n                      emit(projection(t))                      ON R.id = S.id\n                                               WHERE S.value > 100                  for t1 in left.Next():         Next()\n                     buildHashTable(t1)\n                  for t2 in right.Next():\n                    if probe(t2): emit(t1⨝t2)                                                                                    R.id, S.cdate\n\n                                 for t in child.Next():\n                     Next()                                   if evalPred(t): emit(t)                                            ⨝R.id=S.id\n\n\n        for t in R:                     for t in S:                                                   value>100Next()                     Next()          emit(t)                         emit(t)\n                       R   S", "char_count": 1060, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 8, "text_raw": "           Iterator model\n\n                                           SELECT R.id, S.cdate\n                 for t in child.Next():                   FROM R JOIN S\n                   emit(projection(t))     1                                               ON R.id = S.id\n                                            WHERE S.value > 100\n    22   forbuildHashTable(t1)t1 in left.Next():\n               for t2 in right.Next():                        R.id, S.cdate                 if probe(t2): emit(t1⨝t2)\n                              for t in child.Next():            ⨝R.id=S.id              Single Tuple                                if evalPred(t): emit(t)  4\n                                                 value>100\n3   foremit(t)t in R:                     foremit(t)t in S:  5                        R    S\n\n                             Control Flow       Data Flow", "char_count": 860, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 9, "text_raw": "            Iterator model\nThe Iterator model is used in almost every\n DBMS.\n  Easy to implement / debug.\n  Output control works easily with this approach.\nAllows for pipelining where the DBMS tries to\n process each tuple through as many operators\n as possible before retrieving the next tuple.", "char_count": 286, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 10, "text_raw": "         Vectorization model\n\nLike the Iterator Model where each operator\n implements a Next() function, but…\nEach operator emits a batch of tuples instead of a\n single tuple.\n  The operator's internal loop processes multiple\n   tuples at a time.\n  The size of the batch can vary based on hardware or\n   query properties.\n  Each batch will contain one or more columns each\n   their own null bitmaps.", "char_count": 395, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 11, "text_raw": "       Vectorization model\n\n              out = [ ]\n              for t in child.Next():  1            SELECT R.id, S.cdate\n                                            FROM R JOIN S                out.add(projection(t))\n                if |out|>n: emit(out)                   ON R.id = S.id\n                                           WHERE S.value > 100           out = [ ]                     2\n           for t1 in left.Next():\n             buildHashTable(t1)\n           for t2 in right.Next():             if probe(t2): out.add(t1⨝t2)                                                               R.id, S.cdate\n             if |out|>n: emit(out)\n\n                         out = [ ]              Tuple Batch               4       ⨝R.id=S.id                         for t in child.Next():\n                           if evalPred(t): out.add(t)\n                           if |out|>n: emit(out)                                               value>100\nout = [ ]                    out = [ ]         3\nfor t in R:                  for t in S:      5  R   S  out.add(t)                   out.add(t)\n  if |out|>n: emit(out)        if |out|>n: emit(out)", "char_count": 1141, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 12, "text_raw": "       Vectorization model\n\n              out = [ ]\n              for t in child.Next():  1            SELECT R.id, S.cdate\n                                            FROM R JOIN S                out.add(projection(t))\n                if |out|>n: emit(out)                   ON R.id = S.id\n                                           WHERE S.value > 100           out = [ ]                     2\n           for t1 in left.Next():\n             buildHashTable(t1)\n           for t2 in right.Next():             if probe(t2): out.add(t1⨝t2)                                                               R.id, S.cdate\n             if |out|>n: emit(out)\n\n                         out = [ ]              Tuple Batch                                         ⨝R.id=S.id                         for t in S:\n                           if evalPred(t): out.add(t)\n                           if |out|>n: emit(out)                                               value>100\nout = [ ]         3       Operator Fusion\nfor t in R:                     R   S  out.add(t)\n  if |out|>n: emit(out)", "char_count": 1066, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 13, "text_raw": "         Vectorization model\nIdeal for OLAP queries because it greatly reduces the\n number of invocations per operator.\nAllows an out-of-order CPU to efficiently execute\n operators over batches of tuples.\n  Operators perform work in tight for-loops over arrays,\n   which compilers know how to optimize / vectorize.\n  No data or control dependencies.\n  Hot instruction cache.", "char_count": 370, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 14, "text_raw": "        Materialization model\n\nEach operator processes its input all at once and\n then emits its output all at once.\n  The operator \"materializes\" its output as a single\n    result.\n  The DBMS can push down hints (e.g., LIMIT) to avoid\n   scanning too many tuples.\n  Can send either a materialized row or a single\n   column.\nThe output can be either whole tuples (NSM) or\n subsets of columns (DSM).", "char_count": 395, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 15, "text_raw": "      Materialization model\n\n\n               out = [ ]                    1            SELECT R.id, S.cdate\n               for t in child.Output():               FROM R JOIN S\n                 out.add(projection(t))\n                                             ON R.id = S.id               return out\n                                           WHERE S.value > 100\n              out = [ ]                     2\n              for t1 in left.Output():\n                buildHashTable(t1)\n              for t2 in right.Output():                                                                              R.id, S.cdate                if probe(t2): out.add(t1⨝t2)\n              return out\n                           4       ⨝R.id=S.id                            out = [ ]\n             ALL Tuples                            for t in child.Output():\n                              if evalPred(t): out.add(t)                            return out                      value>100\n\n    out = [ ]                   out = [ ]3    for t in R:                 for t in S:    5   R   S\n      out.add(t)                  out.add(t)\n    return out                  return out", "char_count": 1152, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 16, "text_raw": "        Materialization model\nBetter for OLTP workloads because queries only\n access a small number of tuples at a time.\n → Lower execution / coordination overhead.\n → Fewer function calls.\nNot ideal for OLAP queries with large intermediate\n results because DBMS must allocate buffers.", "char_count": 281, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 17, "text_raw": "Plan Processing", "char_count": 15, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 18, "text_raw": "      Plan Processing Direction\n\nTop-to-Bottom (Pull)\n  Start with the root and \"pull\" data up from its\n   children.\n  Tuples are always passed between operators using\n   function calls (unless it's a pipeline breaker).\nBottom-to-Top (Push)\n  Start with leaf nodes and \"push\" data to their parents.\n  Can \"fuse\" operators together within a for-loop to\n   minimize intermediate result staging.", "char_count": 392, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 19, "text_raw": "          Access methods\n\nAn access method is the way that the DBMS\n accesses the data stored in a table.\n  Not defined in relational algebra.\nThree basic approaches:\n  Sequential Scan.\n  Index Scan (many variants).\n  Multi-Index Scan.", "char_count": 231, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 20, "text_raw": "         SEQUENTIAL SCAN\nFor each page in the table:\n  Retrieve it from the buffer pool.\n  Iterate over each tuple and check whether to\n   include it.\n                      for page in table.pages:\n                       for t in page.tuples:\n                         if evalPred(t):\n                           // Do Something!\nThe DBMS maintains an internal cursor that\n tracks the last page examined.", "char_count": 397, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 21, "text_raw": "Sequential scan: Optimizations\n\n                    Prefetching /         TaskData Encoding /                 Scan Sharing /     Parallelization / Compression                    Buffer Bypass    Multi-threading\n\n\n                                       Materialized  Clustering /          Late                                  Views / Result    Sorting        Materialization                                    Caching\n\n\n                       Data           Code\n Data Skipping     Parallelization /    Specialization /\n                    Vectorization      Compilation", "char_count": 570, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 22, "text_raw": "           Data skipping\n\nApproximate Queries (Lossy)\n  Execute queries on a sampled subset of the\n   entire table to produce approximate results.\nZone Maps (Lossless)\n  Pre-compute columnar aggregations per\n  page that allow the DBMS to check whether\n   queries need to access it.\n  Trade-off between page size vs. filter efficacy.", "char_count": 326, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 23, "text_raw": "            Zone maps\nPre-computed aggregates for the attribute\n values in a page.\nDBMS checks the zone map first to decide\n whether it wants to access the page.\n\n                               Original Data         Zone Map\n\n                                   val               type   val\n SELECT * FROM table                                   100                  MIN    100\n  WHERE val > 600                                   200                  MAX    400\n                                   300                  AVG    280\n                                   400                  SUM   1400\n                                   400                 COUNT    5", "char_count": 650, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 24, "text_raw": "             Index scan\n\nThe DBMS picks an index to find the tuples that\n the query needs.\nWhich index to use depends on:\n What attributes the index contains\n What attributes the query references\n  The attribute's value domains\n  Predicate composition\n  Whether the index has unique or non-unique keys", "char_count": 295, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 25, "text_raw": "             Index scan\nSuppose that we have a single table with 100\ntuples and two indexes: SELECT * FROM students\n                           WHERE age < 30 Index #1: age\n                             AND dept = 'CS'\n Index #2: dept\n                             AND country = 'US'\n\n          Scenario #1                 Scenario #2\n    There are 99 people        There are 99 people in\n   under the age of 30 but     the CS department but\n    only 2 people in the CS      only 2 people under the\n    department.              age of 30.", "char_count": 525, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 26, "text_raw": "          Multi-index scan\n\nIf there are multiple indexes available for a query, the\n DBMS does not have to pick only one:\n  Compute sets of Record IDs using each matching index.\n  Combine these sets based on the query’s predicates (union vs.\n    intersect).\n  Retrieve the records and apply any remaining predicates.\nExamples:\n  DB2 Multi-Index Scan\n  PostgreSQL Bitmap Scan\n  MySQL Index Merge", "char_count": 393, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 27, "text_raw": "          Multi-index scan\n\nGiven the following query on a\n database with an index #1 on age\n and an index #2 on dept:                                   SELECT * FROM students\n  Retrieve the Record IDs         WHERE age < 30\n    satisfying age<30 using index #1.   AND dept = 'CS'\n                                     AND country = 'US'  Retrieve the Record IDs\n    satisfying dept='CS' using index #2.\n  Take their intersection.\n  Retrieve records and check\n   country='US'.", "char_count": 470, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 28, "text_raw": "          Multi-index scan\n\n                                    SELECT * FROM studentsSet intersection can be done\nefficiently with bitmaps or       WHERE age < 30\n                                      AND dept = 'CS'hash tables.\n                                      AND country = 'US'\n\n\n\n\n                                      dept='CS'             age<30\n\n                                                         record ids                     record ids\n\n                                    fetch records                                         country='US'", "char_count": 551, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 29, "text_raw": "Expression\nevaluation", "char_count": 21, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 30, "text_raw": "       Expression evaluation\nThe DBMS represents a WHERE clause as an\n expression tree.\nThe nodes in the tree represent different\n expression types:\n  Comparisons (=, <, >, !=)\n  Conjunction (AND), Disjunction (OR)\n  Arithmetic Operators (+, -, *, /, %)\n  Constant Values\n  Tuple Attribute References\n  Functions", "char_count": 313, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 31, "text_raw": "Expression evaluation\n\n      SELECT R.id, S.cdate\n       FROM R JOIN S\n          ON R.id = S.id\n       WHERE S.value > 100;\n\n\n\n                              AND\n\n\n\n                     =                         >\n\n\n\n Attribute(R.id)  Attribute(S.id)   Attribute(value)  Constant(100)", "char_count": 283, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 32, "text_raw": "       Expression evaluation\n\nPREPARE xxx AS\n SELECT * FROM S         ExecutionContext\n  WHERE S.val = $1 + 9         Current Tuple       Query Parameters    Table Schema\n                                                (123, 1000)         (int:991)           S→(int:id, int:val)\nEXECUTE xxx(991)\n\n                                =\n\n\n             Attribute(S.val)           +\n\n\n\n                       Parameter($1)         Constant(9)", "char_count": 427, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 33, "text_raw": "       Expression evaluation\n\n                                                 SELECT * WHERE s.val = 1;\nEvaluating predicates by traversing a\n                                                              = tree is terrible for the CPU.\n  The DBMS traverses the tree and for                                                                          Attribute(s.val)       Constant(1)\n   each node that it visits, it must figure\n    out what the operator needs to do.\n\n                                                            bool check(val) {A better approach is to evaluate the\n                                                              return (val == 1);\n expression directly.                               }\nAn even better approach is to                                          gcc, Clang, LLVM,\n vectorize it evaluate a batch of tuples\n                                                       Machine Code\n at the same time…", "char_count": 929, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 34, "text_raw": "      EXPRESSION EVALUATION:\n          OPTIMIZATIONS\nConstant Folding:\n→ Identify redundant / unnecessary operations\n that are wasteful.\n→ Compute a sub-expression on a constant\nvalue once and reuse result per tuple.\n\n\n\n\n\n                              →\nCommon Sub-Expr. Elimination: Identify\n\n\n\n\n\n                              → repeated sub-expressions that can be shared\n across expression tree.\nCompute once and then reuse result.", "char_count": 434, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 35, "text_raw": "          Constant Folding\n\n                                             WHERE UPPER(col1) = UPPER('wutang');Identify redundant /\n\n                                                                                                 = unnecessary\n\n                                                                                     UPPER()           UPPER() operations that are\n\n                                                                             Attribute(col1)      Constant('wutang') wasteful.\nCompute a sub-\n                                             WHERE UPPER(col1) = UPPER('wutang');\n\n\n\n\n\n                              → expression on a\n                                                                                                 =\n\n\n\n\n\n                              → constant\n                                                                                     UPPER()      Constant('WUTANG')\nvalue once and reuse                Attribute(col1)\n result per tuple.", "char_count": 977, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 36, "text_raw": "   Common Sub-Expr. Elimination\n\n                                                 WHERE STRPOS('x', col1) < 2\n                                                   OR STRPOS('x', col1) > 8\n\n\n                                                                                                           ORIdentify repeated\n\n                                                                                          Op(<)                            Op(>) sub-expressions\n\n\n                                                                                                       STRPOS()     Constant(2)                 STRPOS()     Constant(8) that can be shared\n\n\n                                                                                          Constant('x')       Attribute(col1)      Constant('x')       Attribute(col1) across expression\n\n\n\n\n\n                              → tree.\n                                                                                                            OR\n\n\n                              →                                                                                     Op(<)           Op(>)Compute once and\n\n\n                                                                                                    STRPOS()      Constant(2)        Constant(8) then reuse result.\n\n\n                                                                                           Constant('x')       Attribute(col1)", "char_count": 1441, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 37, "text_raw": "Query Optimization", "char_count": 18, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 38, "text_raw": "     Optimization architecture\n\n\n\n        Application\n                                                                      Cost\n                                                                   Model\n                         System                             SchemaInfo\n                            Catalog\n1 SQL Query                                                                                                Estimates\n                                        Optimizer\n   Parser\n                               Name→Internal ID                               4 Physical\n                                                                                 Plan\n                 Binder\n       2 Abstract                 3 Logical\n            Syntax Tree                      Plan", "char_count": 773, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 39, "text_raw": "       Logical vs. Physical plans\n\nThe optimizer generates a mapping of a\n logical algebra expression to the optimal\n equivalent physical algebra expression.\n\nPhysical operators define a specific\n execution strategy using an access path.\n They can depend on the physical format of the\n   data that they process (i.e., sorting, compression).\n  Not always a 1:1 mapping from logical to physical.", "char_count": 390, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 40, "text_raw": " Annotated RA Tree = The Physical Plan\n\n\n                 Simple projection\n                    Estimates: output cardinality = 20, …                     πename\n\n    NL-IDX using unclusteredindex on EMP.id                                                     To thescheduler\n                    Estimates: output cardinality = 20, …\n                                                                   to run the query                        ⋈EMP.did = DEPT.did\n\n                            EMP AccessPath: FileScan\nAccessPath: UnclusteredB-tree                                 Estimates: output cardinality = 10K\n            Estimates: output cardinality = 1, …                    σdname= ‘Toy’\n\n\n                    DEPT", "char_count": 718, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 41, "text_raw": "      Query optimization (QO)\nIdentify candidate equivalent trees\n (logical).\n  It is an NP-hard problem, so the space\n                                                                                                  p1    is large.                                                            pn\n\n                                                                                                         pi                                                                                               p2For each candidate, find the\n                                                                                             p3 execution plan (physical).\n  Estimate the cost of each plan.\n                                                             Entire search space very\n                                                                  large, as QO is NP-hardChoose the best (physical) plan.                                                                                  (w.r.t. # joins)\nPractically: Choose from a subset\n of all possible plans.", "char_count": 1049, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 42, "text_raw": "      QUERY OPTIMIZATION\n\n\nHeuristics /    Cost-based\n   Rules        Search", "char_count": 70, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 43, "text_raw": "          Heuristics / Rules\n\nRewrite the query to remove (guessed)\n inefficiencies.\nExamples:\n  always do selections first or push down\n   projections as early as possible.\nThese techniques may need to examine\n catalog, but they do not need to examine\n data.", "char_count": 253, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 44, "text_raw": "       Logical plan optimization\n\nTransform a logical plan into an equivalent\n logical plan using pattern matching rules.\nThe goal is to increase the likelihood of\n enumerating the optimal plan in the search.\n Many equivalence rules for relational algebra!\nCannot compare plans because there is no\n cost model but can \"direct\" a transformation to\n a preferred side.", "char_count": 362, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 45, "text_raw": "Heuristic Algebraic\n   Optimization\n    Algorithm", "char_count": 49, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 46, "text_raw": "         Algorithm Outline\n\nUsing rule 1, break up any select operations with\n conjunctive conditions into a cascade of select operations.\nUsing rules 2, 4, 6, and 10 concerning the commutatively\n of select with other operations, move each select\n operation as far down the query tree as is permitted by\n the attributes involved in the select condition.\nUsing rule 9 concerning associatively of binary operations,\n rearrange the leaf nodes of the tree so that the leaf node\n relations with the most restrictive select operations are\n executed first in the query tree representation.", "char_count": 576, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 47, "text_raw": "         Algorithm Outline\n\nUsing Rule 12, combine a Cartesian product\n operation with a subsequent select operation in the\n tree into a join operation.\nUsing rules 3, 4, 7, and 11 concerning the cascading of\n project and the commuting of project with other\n operations, break down and move lists of projection\n attributes down the tree as far as possible by\n creating new project operations as needed.\nIdentify subtrees that represent groups of operations\n that can be executed by a single algorithm.", "char_count": 495, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 48, "text_raw": "            EXAMPLE\n\nHeuristic Optimization of Query Trees:\n  The same query could correspond to many different\n    relational algebra expressions — and hence many different\n   query trees.\n  The task of heuristic optimization of query trees is to find a\n    final query tree that is Efficient to Execute.\nExample:\n  SELECT  LNAME\n FROM   EMPLOYEE, WORKS_ON, PROJECT\n WHERE PNAME = ‘AQUARIUS’ AND PNMUBER=PNO\n  AND ESSN=SSN AND BDATE > ‘1957-12-31’;", "char_count": 444, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 49, "text_raw": "Using Heuristics in Query Optimization\n\n\n                                               Cartesian Product\n                                  →Avoid it!!!\n\n\n\n\n\n                                     Apply Select to reduce\n                                  number of tuples\n\n\n                              Move Project down since\n                                                                it is more selective\n\n\n\n\n\n  Slide 15- 50", "char_count": 429, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 50, "text_raw": "                                        Replace Cart. Product\n                                        followed by Join Condition\n                          → JOIN\n\n\n\n\n\n                                   Move Project\n                                          operations down the\n                                           query tree\n\n\n\n\n\nSlide 15- 51", "char_count": 308, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 51, "text_raw": "      Summary of Heuristics\nThe main heuristic is to apply first the operations that\n reduce the size of intermediate results.\n  Perform select operations as early as possible to reduce\n   the number of tuples\n  Perform project operations as early as possible to reduce\n   the number of attributes.\n  Move select & project operations down the tree\nThe select and join operations that are most\n restrictive should be executed before other similar\n operations.\n  Reorder the leaf nodes of the tree to have most\n    restrictive operations far down", "char_count": 544, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 52, "text_raw": "           Example\n\n\n\n\n\n10/28/2025                                       Introduction to Database Systems                                             53", "char_count": 141, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 53, "text_raw": "  Query optimization example\n\n\n\n\n\n10/28/2025                                       Introduction to Database Systems                                        54", "char_count": 155, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 54, "text_raw": "SELECT S.sid, S.name, S.age\nFROM Sailors S, Boats B, Reservers R\nWHERE S.sid=R.sid AND B.bid=R.bid AND\n B.color=“Red” AND S.age>30", "char_count": 133, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 55, "text_raw": "    Query optimization example\n\n⚫Step 1: translate SQL query to algebra query\n\n\n⚫Step 2: generate initial query tree\n\n⚫Step 3: apply heuristic rules and\nGenerate optimized tree\n\n\n\n\n\n       10/28/2025                                       Introduction to Database Systems                                          56", "char_count": 310, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 56, "text_raw": "  Query optimization example\n\n\n\n\n\n10/28/2025                                       Introduction to Database Systems                                            57", "char_count": 159, "is_empty": false}
{"lecture_id": "ADB_Lec05", "source_file": "ADB_Lec05.pdf", "page_num": 57, "text_raw": "", "char_count": 0, "is_empty": true}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 1, "text_raw": "       CSAI 302\n\nAdvanced Database\n\n     Systems\n           Lec 06\n     Query Processing\n     & Optimization [2]", "char_count": 105, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 2, "text_raw": "         Cost-based Search\n\n\n\nUse a model to estimate the cost of executing\n a plan.\nEnumerate multiple equivalent plans for a\n query and pick the one with the lowest cost.", "char_count": 165, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 3, "text_raw": "   Cost-based query optimization\nStart with cost-based, bottom-up QO\nEnumerate different plans for the query and\n estimate their costs.\nIt chooses the best plan it has seen for the\n query after exhausting all plans or some\n timeout.\n  Single relation.\n  Multiple relations.\n  Nested sub-queries.", "char_count": 298, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 4, "text_raw": "    Single-relation query planning\n\nPick the best access method.\n  Sequential Scan\n  Binary Search\n  Index Scan\nPredicate evaluation ordering.\nSimple heuristics are often good enough for\n this.", "char_count": 195, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 5, "text_raw": "    Multi-relation query planning\nGenerative / Bottom-Up\n  Start with nothing and then iteratively assemble and\n   add building blocks to generate a query plan.\n  Examples: System R, Starburst\nTransformation / Top-Down\n  Start with the outcome that the query wants, and then\n   transform it to equivalent alternative sub-plans to find\n   the optimal plan that gets to that goal.\n  Examples: Volcano, Cascades", "char_count": 410, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 6, "text_raw": "      Bottom-up optimization\n\nUse static rules to perform initial\n optimization.\nThen use dynamic programming to\n determine the best join order for tables using\n a divide-and-conquer search method\nExamples\n IBM System R, DB2, MySQL, Postgres, most\n   open-source DBMSs.", "char_count": 267, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 7, "text_raw": "        System R optimizer\n                                                                   Left-DeepTree\nBreak query into blocks and generate\n logical operators for each block.                    D\n\n                                                    CFor each logical operator, generate a set\n                                                  B                                              A of physical operators that implement it.                                                                             outer   inner\n  All combinations of join algorithms and\n                                                               BushyTree\n   access paths\nThen, iteratively construct a “left-deep”\n join tree that minimizes the estimated\n                                              A  B C  D\n amount of work to execute the plan.", "char_count": 828, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 8, "text_raw": "        System R optimizer\n\nSELECT ARTIST.NAME\n FROM ARTIST, APPEARS, ALBUM       ARTIST: Sequential Scan\n WHERE ARTIST.ID=APPEARS.ARTIST_ID  APPEARS: Sequential Scan\n  AND APPEARS.ALBUM_ID=ALBUM.ID                                    ALBUM: Index Look-up on NAME\n  AND ALBUM.NAME=“Andy's OG Remix”\n ORDER BY ARTIST.ID\n                                           ARTIST ⨝ APPEARS ⨝ ALBUM\n  Step #1: Choose the best access                                           APPEARS ⨝ALBUM  ⨝ARTIST\n  paths to each table                                           ALBUM  ⨝APPEARS ⨝ARTIST\n                                           APPEARS ⨝ ARTIST ⨝ ALBUM\n  Step #2: Enumerate all possible                                           ARTIST  ×  ALBUM ⨝ APPEARS\n   join orderings for tables                                           ALBUM   ×  ARTIST ⨝ APPEARS\n                                                                      ⋮                  ⋮                  ⋮  Step #3: Determine the join\n   ordering with the lowest cost", "char_count": 1007, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 9, "text_raw": "      Top-down optimization\n\nStart with a logical plan of what we want the\n query to be.\nPerform a branch-and-bound search to\n traverse the plan tree by converting logical\n operators into physical operators.\n Keep track of global best plan during search.\n  Treat physical properties of data as first-class\n   entities during planning.\nExamples: MSSQL, Greenplum, CockroachDB", "char_count": 373, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 10, "text_raw": "      Top-down optimization\n\n                                                                 ARTIST ⨝APPEARS ⨝ALBUM\nStart with a logical plan of what                                                                   ORDER-BY(ARTIST.ID)\n we want the query to be.\nInvoke rules to create new                     SORT(A1.ID)                     HASH_JOIN(A1⨝A2,A3)\n nodes and traverse tree.\n                                                                           MERGE_JOIN(A1⨝A2,A3)\n   Logical→Logical:               HASH_JOIN(A1⨝A2,A3)\n   JOIN(A,B) to JOIN(B,A)\n   Logical→Physical:                    ARTIST⨝APPEARS    ALBUM⨝APPEARS     ARTIST⨝ALBUM\n   JOIN(A,B) to\n                                                    HASH_JOIN(A1,A2)                    MERGE_JOIN(A1,A2)\n    HASH_JOIN(A,B)\nCan create \"enforcer\" rules that\n                                                        ARTIST             ALBUM             APPEARS\n require input to have certain\n properties.\n                                                      Logical Op   Physical Op", "char_count": 1051, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 11, "text_raw": "       Hash join vs. Merge join\nFeature            Hash Join                        Merge Join\n\n          Builds a hash table from one table's join  Sorts both tables on the join key and then\n How it        column and then probes the hash table  merges them together by comparing rows in a works\n         with rows from the other table.          single pass.\n\n When   Large, unsorted tables, especially when  Tables that are already sorted on the join key,\n it's best  one fits into memory.                  or when the join is a range join.\n\n                                              Lower, as it primarily requires memory forMemory Can be high, especially if the hash table                                                  sorting (if needed) and the merge process usage   doesn't fit in memory and spills to disk.                                                                 itself.\n\n          Fast for large datasets when the hashPerform                                     Slower if tables need to be sorted first; very fast          table fits in memory; performance  ance                                    and efficient if data is already sorted.         degrades if it has to use disk.\n\n  Join         Primarily used for equi-joins (=).       Can handle both equi-joins and non-equi-joins.  types", "char_count": 1305, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 12, "text_raw": "Merge Join", "char_count": 10, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 13, "text_raw": "        Nested sub-queries\n\nThe DBMS treats nested sub-queries in the\n where clause as functions that take\n parameters and return a single value or set of\n values.\n   1. Rewrite to de-correlate and/or flatten\n   them.\n  2. Decompose nested query and store results\n    in a temporary table.", "char_count": 282, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 14, "text_raw": "Nested sub-queries: Rewrite\n\n      SELECT name FROM sailors AS S\n     WHERE EXISTS (\n       SELECT * FROM reserves AS R\n           WHERE S.sid = R.sid\n          AND R.day = '2024-10-25'\n     )\n\n\n    SELECT name\n      FROM sailors AS S, reserves AS R\n     WHERE S.sid = R.sid\n       AND R.day = '2024-10-25'", "char_count": 306, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 15, "text_raw": "       Decomposing queries\n\n\nFor harder queries, the optimizer breaks up\n queries into blocks and then concentrates on\n one block at a time.\nSub-queries are written to temporary tables\n that are discarded after the query finishes.", "char_count": 225, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 16, "text_raw": "     Decomposing queries\n\n\n\nSELECT S.sid, MIN(R.day)\n FROM sailors S, reserves R, boats B\n WHERE S.sid = R.sid  AND R.bid\n  = B.bid  AND B.color = 'red'\n  AND S.rating = (SELECT MAX(S2.rating)\n                    FROM sailors S2)\n GROUP BY S.sid\nHAVING COUNT(*) > 1\n                                   Nested Block", "char_count": 308, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 17, "text_raw": "      Decomposing queries\n\nInner Block           SELECT MAX(rating) FROM sailors\n\n  SELECT S.sid, MIN(R.day)\n   FROM sailors S, reserves R, boats B\n   WHERE S.sid = R.sid  AND R.bid\n    = B.bid  AND B.color = 'red'\n    AND S.rating =\n\n   GROUP BY S.sid\n  HAVING COUNT(*) > 1\n  Outer Block", "char_count": 282, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 18, "text_raw": "        Expression rewriting\n\nAn optimizer transforms a query’s expressions\n (e.g., WHERE/ON clause predicates) into the\n minimal set of expressions.\nImplemented using if/then/else clauses or a\n pattern-matching rule engine.\n  Search for expressions that match a pattern.\n When a match is found, rewrite the expression.\n  Halt if there are no more rules that match.", "char_count": 362, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 19, "text_raw": "        Expression rewriting\n\nImpossible / Unnecessary Predicates\n\n SELECT * FROM A WHERE 1 = 0;         SELECT * FROM A WHERE false;\n\n SELECT * FROM A WHERE NOW() IS NULL;\n\n SELECT * FROM A WHERE false;\n\nMerging Predicates\n\nSELECT * FROM A\n                                    SELECT * FROM A\n WHERE val BETWEEN 1 AND 100\n                                     WHERE val BETWEEN 1 AND 150;\n    OR val BETWEEN 50 AND 150;", "char_count": 410, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 20, "text_raw": "Cost estimation", "char_count": 15, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 21, "text_raw": "          Cost estimation\n\nThe DBMS uses a cost model to predict the\n behavior of a query plan given a database\n state.\n  This is an internal cost that allows the DBMS to\n  compare one plan with another.\nIt is too expensive to run every possible plan\n to determine this information, so the DBMS\n need a way to derive this information.", "char_count": 327, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 22, "text_raw": "       Cost model components\n\nPhysical Costs\n  Predict CPU cycles, I/O, cache misses, RAM\n   consumption, network messages…\n  Depends heavily on hardware.\nLogical Costs\n  Estimate output size per operator.\n  Independent of the operator algorithm.\n Need estimations for operator result sizes.", "char_count": 291, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 23, "text_raw": "               Statistics\n\nThe DBMS stores internal statistics about tables,\n attributes, and indexes in its internal catalog.\nDifferent systems update them at different times.\nManual invocations:\n  Postgres/SQLite: ANALYZE\n  Oracle/MySQL:  ANALYZE TABLE\n  SQL Server:     UPDATE STATISTICS\n  DB2:          RUNSTATS", "char_count": 307, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 24, "text_raw": "         Selection cardinality\n\nThe selectivity (sel) of a predicate P is the fraction\n of tuples that qualify:                                SELECT * FROM people\n  Equality Predicate: A=constant  WHERE age = 9\n  sel(A=constant) = #occurences / |R|\n Example: sel(age = 9) = 4/45\n\n                                                       SC(age=9)=4\n# of occurrences\n            10\n\n                                                                                            Distinct values\n             0                                                                                    of attribute\n                   1  2  3  4  5  6  7  8  9 10 11 12 13 14 15\n                                 age", "char_count": 693, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 25, "text_raw": "         Selection cardinality\nUniform Data\n The distribution of values is the same.\nIndependent Predicates\n The predicates on attributes are independent\nInclusion Principle\n The domain of join keys overlap such that each\n   key in the inner relation will also exist in the\n   outer table.", "char_count": 286, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 26, "text_raw": "              Statistics\n\n                           • Maintain an occurrence count perHistograms                      value (or range of values) in a column.\n\n\n                           • Probabilistic data structure that gives\n                   an approximate count for a given Sketches\n                        value.\n\n\n                           • DBMS maintains a small subset of each\n                        table that it then uses to evaluate Sampling\n                      expressions to compute selectivity.", "char_count": 503, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 27, "text_raw": "           Histograms\n\nOur formulas are nice, but we assume that data\nvalues are uniformly distributed.\n\n                                  Histogram\n            10 #of occurrences\n\n              5\n\n              0\n                     1  2  3  4  5  6  7  8  9 10 11 12 13 14 15\n\n                                          Distinctvaluesof attribute        15Keys× 32-bits=60bytes", "char_count": 368, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 28, "text_raw": "      Equi-width histogram\nMaintain counts for a group of values instead of\neach unique key. All buckets have the same width\n(i.e., same # of value).\n\n                  Non-Uniform Approximation\n         10\n\n          5\n\n          0\n   Bucket Ranges   1  2  3  4  5  6  7  8  9 10 11 12 13 14 15\n                             Bucket #1      Bucket #2      Bucket #3      Bucket #4      Bucket #5\n                            Count=8       Count=4       Count=15       Count=3       Count=14", "char_count": 482, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 29, "text_raw": "      Equi-width histogram\nMaintain counts for a group of values instead of\neach unique key. All buckets have the same width\n(i.e., same # of value).\n\n                      Equi-Width Histogram\n         15\n         10\n          5\n          0\n                     1-3       4-6       7-9     10-12    13-15    Bucket Ranges\n                             Bucket #1      Bucket #2      Bucket #3      Bucket #4      Bucket #5\n                            Count=8       Count=4       Count=15       Count=3       Count=14", "char_count": 509, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 30, "text_raw": "                                                                                                                   145\n             EQUI-DEPTH HISTOGRAMS\n\n          Varythe width of bucketsso that the total number\n           of occurrencesfor each bucket isroughlythe same.\n\n\n                                Histogram(Quantiles)\n            10\n\n              5\n\n\n\n\n\n15-445/645 (Spring 2025)              0\n                      1  2  3  4  5  6  7  8  9 10 11 12 13 14 15", "char_count": 356, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 31, "text_raw": "  Equi-depth histograms\n\nVarythe width of bucketsso that the total number\nof occurrencesfor each bucket isroughlythe same.\n\n\n                   Histogram(Quantiles)\n  10\n\n    5\n\n    0\n         1  2  3  4  5  6  7  8  9 10 11 12 13 14 15\n\n                        Bucket #1             Bucket #2              Bucket #3           Bucket #4\n                       Count=12             Count=12              Count=9           Count=12", "char_count": 427, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 32, "text_raw": "  Equi-depth histograms\n\nVarythe width of bucketsso that the total number\nof occurrencesfor each bucket isroughlythe same.\n\n\n                   Histogram(Quantiles)\n  15\n  10\n    5\n    0\n             1-5         6-8        9-13       14-15", "char_count": 237, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 33, "text_raw": "             Sketches\n\nProbabilistic data structures that generate\n approximate statistics about a data set.\nCost-model can replace histograms with sketches to\n improve its selectivity estimate accuracy.\nMost common examples:\n  Count-Min Sketch\n    Approximate frequency count of elements in a set.\n  HyperLogLog\n    Approximate the number of distinct elements in a set.", "char_count": 364, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 34, "text_raw": "             Sampling\n\n                                         SELECT AVG(age)\nModern DBMSs also collect samples\n                                           FROM people\n from tables to estimate selectivities.\n                                          WHERE age > 50\nUpdate samples when the underlying\n                                                  id   name      age status\n tables changes significantly.                                                  1001 Obama     63  Rested\n                                                  1002 Swift     34  Paid\n                                                  1003 Tupac     25  Dead\n                Table Sample              1004 Bieber    30  Crunk\n                                                  1005 Andy      43  Illin\n                     1001    Obama  63  Rested\n                                                  1006 TigerKing 61  Jailedsel(age>50) = 1/3                     1003    Tupac  25  Dead\n                                                                           ⋮                     1005    Andy   43  Illin\n                                   1 billion tuples", "char_count": 1119, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 35, "text_raw": "Adaptive Query\n Optimization", "char_count": 28, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 36, "text_raw": "    Adaptive Query Optimization\n\nThe best plan for a query can change as the\n database evolves over time.\n  Physical design changes.\n  Data modifications.\n  Prepared statement parameters.\n  Statistics updates.\nThe query optimizers that we have talked about\n so far all generate a plan for a query before the\n DBMS executes a query.", "char_count": 333, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 37, "text_raw": "         Bad query plans\n\nThe most common problem in a query plan is\n incorrect join orderings.\n  This occurs because of inaccurate cardinality\n   estimations that propagate up the plan.\nIf the DBMS can detect how bad a query plan\n is, then it can decide to adapt the plan rather\n than continuing with the current sub-optimal\n plan.", "char_count": 326, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 38, "text_raw": "     Why good plans go bad?\n\nEstimating the execution behavior of a plan\n to determine its quality relative to other plans.\nThese estimations are based on a static\n summarizations of the contents of the\n database and its operating environment:\n  Statistical Models / Histograms / Sampling\n  Hardware Performance\n  Concurrent Operations", "char_count": 335, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 39, "text_raw": "         Optimization timing\n\nStatic Optimization\n   Select the best plan prior to execution.\n   Plan quality is dependent on cost model accuracy.\n  Can amortize over executions with prepared statements.\nDynamic Optimization\n   Select operator plans on-the-fly as queries execute.\n   Will have re-optimize for multiple executions.\n   Difficult to implement/debug (non-deterministic)\nAdaptive Optimization\n  Compile using a static algorithm.\n   If the estimate errors > threshold, change or re-optimize.", "char_count": 504, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 40, "text_raw": "    Adaptive query optimization\n\nModify the execution behavior of a query by\n generating multiple plans for it:\n  Individual complete plans.\n  Embed multiple sub-plans at materialization points.\nUse information collected during query\n execution to improve the quality of these plans.\n  Can use this data for planning one query or merge\n   the it back into the DBMS's statistics catalog.", "char_count": 387, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 41, "text_raw": "    Adaptive query optimization\n\n\n\nModify Future Invocations\nReplan Current Invocation\nPlan Pivot Points", "char_count": 103, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 42, "text_raw": "     Modify future invocations\n\n\nThe DBMS monitors the behavior of a query\n during execution and uses this information to\n improve subsequent invocations.\n  Plan Correction\n  Feedback Loop", "char_count": 186, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 43, "text_raw": "  Reversion-based plan correction\n\nThe DBMS tracks the history of query\n invocations:\n  Cost Estimations\n  Query Plan\n  Runtime Metrics\nIf the DBMS generates a new plan for a query,\n then check whether that plan performs worse\n than the previous plan.\n  If it regresses, then switch back to the cheaper plans.", "char_count": 313, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 44, "text_raw": "      Replan current invocation\n\n\nIf the DBMS determines that the observed\n execution behavior of a plan is far from its\n estimated behavior, them it can halt execution\n and generate a new plan for the query.\n  Start-Over from Scratch\n Keep Intermediate Results", "char_count": 258, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 45, "text_raw": "          Plan pivot points\n\nThe optimizer embeds alternative sub-plans\n at materialization points in the query plan.\nThe plan includes \"pivot\" points that guides\n the DBMS towards a path in the plan based on\n the observed statistics.\n  Parametric Optimization\n  Proactive Reoptimization", "char_count": 281, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 46, "text_raw": "      Parametric optimization\n\nGenerate multiple sub-      SELECTJOIN *B FROMON A.idA  = B.id\n plans per pipeline in the       JOIN C ON A.id = C.id;\n                                                                                                              Candidate Pipeline #1\n                                                                                                 If |input|>X, choose#1         HASH_JOIN(A⨝B,C) query.\n                                                                                                          Else, choose #2\n\n\n                                                                                                                                            SEQ_SCAN(C)                                                                                                       CHOOSE-PLANAdd a choose-plan\n                                                                                                              Candidate Pipeline #2\n\n                                                                                                       HASH_JOIN(A,B) operator that allows the                                            NL_JOIN(A⨝B,C)\n\n\n                                                                                                 SEQ_SCAN(A)    SEQ_SCAN(B) DBMS to select which plan                                                 IDX_SCAN(C)\n to execute at runtime.", "char_count": 1406, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 47, "text_raw": "      Proactive reoptimization\n\nGenerate multiple sub-\n plans within a single               SELECT * FROM A                                                 JOIN B ON A.id = B.id\n                                                 JOIN C ON A.id = C.id; pipeline.\nUse a switch operator to                                    ComputeBounding Boxes                                                    Optimizer                                                                                                                 GenerateSwitchable Plans choose between different\n\n                                                                                   Reoptimize sub-plans during execution\n                                                            Execution     ExecuteQuery in the pipeline.                                                                                            CollectStatistics                                                         Engine\nComputes bounding boxes                        SwitchPlans\n to indicate the uncertainty of\n estimates used in plan.", "char_count": 1075, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 48, "text_raw": "            Plan stability\n\nHints\n  Allow the DBA to provide hints to the optimizer.\nFixed Optimizer Versions\n  Set the optimizer version number and migrate\n   queries one-by-one to the new optimizer.\nBackwards-Compatible Plans\n  Save query plan from old version and provide it\n   to the new DBMS.", "char_count": 291, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 49, "text_raw": "             Conclusion\n\nQuery optimization is critical for a database\n system.\n  SQL → Logical Plan → Physical Plan\n  Flatten queries before going to the optimization part.\nExpression handling is also important.\n  Estimate costs using models based on\n   summarizations.\nQO enumeration can be bottom-up or top-down.", "char_count": 308, "is_empty": false}
{"lecture_id": "ADB_Lec06", "source_file": "ADB_Lec06.pdf", "page_num": 50, "text_raw": "", "char_count": 0, "is_empty": true}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 1, "text_raw": "       CSAI 302\n\nAdvanced Database\n\n     Systems\n           Lec 07\n Transaction Processing and\n         Schedules", "char_count": 106, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 2, "text_raw": "            Introduction\n\nTransactions (informally):\n  mechanism for managing logical units of data processing:\n    independent on others, all or nothing\n  Examples:\n     a single data retrieval query\n     a sequence of data manipulation queries that should be executed together\nTransaction management (or processing) systems:\n  systems with large databases and many concurrent users require\n    high availability and fast response time\n  Examples:\n      banking, airline booking, online retail, stocks", "char_count": 499, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 3, "text_raw": "      Fund Transfer Example\n\nTransfer $50 from account A to account B:\n  1.   read(A)                            Failures, such as:\n  2.  A := A – 50                                     •  hardware failures\n                                     •  system crashes  3.   write(A)\n  4.  read(B)\n                        Concurrent execution of\n  5.  B := B + 50                          multiple transactions\n  6.   write(B)", "char_count": 420, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 4, "text_raw": "      Fund Transfer Example\n\n                            If the transaction fails afterTransfer $50 from\n                               step 3 and before step 6, account A to account B:                       money will be “lost” leading\n  1.   read(A)               to an inconsistent database\n                                  state  2.  A := A – 50\n                      The system should ensure  3.   write(A)\n                                that updates of a partially\n  4.   read(B)                            executed transaction are\n                             not reflected in the  5.  B := B + 50\n                             database\n  6.   write(B)\n                         Atomicity requirement", "char_count": 710, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 5, "text_raw": "      Fund Transfer Example\n\n                      Once the user has beenTransfer $50 from\n                               notified that the account A to account B:                               transaction has completed\n  1.   read(A)                          The transfer of the $50 has\n                                  taken place  2.  A := A – 50\n                        the updates to the database  3.   write(A)\n                           by the transaction must\n  4.   read(B)                                 persist even if there are\n  5.  B := B + 50            software or hardware\n                                    failures.  6.   write(B)\n                           Durability requirement", "char_count": 706, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 6, "text_raw": "      Fund Transfer Example\n\nTransfer $50 from     Sum of A and B is unchanged by\n account A to account B:    the execution of the transaction\n                        A transaction must see a\n  1.   read(A)                                     consistent database.\n  2.  A := A – 50             During transaction execution\n                                      the database may be\n  3.   write(A)                                      temporarily inconsistent.\n  4.   read(B)            When the transaction\n                                    completes successfully the  5.  B := B + 50                                      database must be consistent\n  6.   write(B)\n                         Consistency requirement", "char_count": 721, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 7, "text_raw": "      Fund Transfer Example\n\n                                if between steps 3 and 6,Transfer $50 from\n                                another transaction T2 is\n account A to account B:                                allowed to access the partially\n                               updated database  1.   read(A)\n                        T2  2.  A := A – 50\n                                   read(A), read(B), print(A+B)\n  3.   write(A)\n                                it will see an inconsistent\n  4.   read(B)               database\n  5.  B := B + 50           (the sum A + B will be less\n                               than it should be).\n  6.   write(B)\n                            Isolation requirement", "char_count": 712, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 8, "text_raw": "      Single-user vs multi-user\n\nSingle-user DBMS:\n   at most one user at a time (usually, personal computer)\nMulti-user DBMS:\n  many users (processes with own computation) with concurrent access to the\n    same data\n       (usually, servers with many CPUs, but may be handled by one CPU with interleaving\n        concurrency)\nBoth need transaction management, with:\n   concurrency control\n       (transactions independent of each other)\n   fail recovery\n      (each transaction executed all or nothing)", "char_count": 507, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 9, "text_raw": "The place of transaction management", "char_count": 35, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 10, "text_raw": "The place of transaction management", "char_count": 35, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 11, "text_raw": "          Transaction idea\nTransaction is a program that forms a logical unit of\n database processing\n  has its own memory and computation ability\n  includes one or more access operations to (shared)\n   database (e.g., retrieval, insertion, deletion)\nboundaries can be specified by begin and end\n statements\n  if something goes wrong on the way, effects roll back\nan application program may have several transactions\n may be read-only or read-write", "char_count": 445, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 12, "text_raw": "    Main transaction operations\n\nread(X)\n  reads an item named X from the global database into a local program\n    variable named X\n      includes finding the address of the block on the disk (or in cache) with X , and\n       copying to a main memory buffer\nwrite(X)\n   writes the value of local program variable named X into the global\n    database item named X\n      includes finding the address of the block on the disk (or in cache) with X , read\n            it to the local memory buffer, modify it, and write it back (to the disk or cache)\nProgram local operations\n   (for example, update X := X + 50)", "char_count": 611, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 13, "text_raw": "       Example transactions\n\nLet X and Y be the numbers of reserved\n  seats in two flights (stored in a database)\nTransaction T1 transfers N reservations\n from X to Y\nTransaction T2 reserves M seats in X\n\n\nImportant:\n   updates are local, the database is not\n    updated until the new value is written\n  some commands are often omitted if\n    they are not relevant (both local and\n    transaction management)", "char_count": 407, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 14, "text_raw": "         Types of failures\n   Computer failure                                       • hardware, software, network errors\n    (system crash)\n\n                                       • division by zero, integrity constraint violation, user  Transaction failure                                  interrupt, etc.\n\nLocal transaction errors   • no data found, programmed exception, etc.\n\n Concurrency control                                       • serializability violation, deadlock resolving, etc.\n     enforcement\n\n      Disk failure            • errors with disk reads or writes\n\n   Physical problems       • power cut, fire, catastrophe, etc.", "char_count": 632, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 15, "text_raw": "         Transaction State\nActive\n   the initial state; the transaction stays in this state while it is executing\nPartially committed\n   after the final statement has been executed.\nFailed\n   after the discovery that normal execution can no longer proceed.\nAborted\n   after the transaction has been rolled back and the database restored to its\n     state prior to the start of the transaction.\n  Two options after it has been aborted:\n      Restart the transaction (only if no internal logical error)\n       Kill the transaction\nCommitted\n   after successful completion.", "char_count": 574, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 16, "text_raw": "Transaction State (Cont.)", "char_count": 25, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 17, "text_raw": "  Desirable\n  properties\nACID principles", "char_count": 38, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 18, "text_raw": "         ACID properties\n\nAtomicity   Consistency    Isolation     Durability\n\n\n                                          Transaction Transaction       The database                          Changes of                                         should not performed in       should always                          committed                                             interfere with its entirety or          remain                                 transactions                                             other   not at all            consistent                          must persist                                            transactions\n\n\n  ensured by         ensured by        ensured by the        ensured by\n  transaction          transaction        concurrency         transaction\n  recovery           recovery            control           recovery\n subsystem         subsystem         subsystem         subsystem", "char_count": 906, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 19, "text_raw": "             Example\n\nConsider two transactions (Xacts):\n                 T1: BEGIN A=A+100, B=B-100 END\n               T2: BEGIN A=1.06*A, B=1.06*B END\n   1st xact transfers $100 from B’s account to A’s\n  2nd credits both accounts with 6% interest.\nAssume at first A and B each have $1000. What are the legal outcomes of\n running T1 and T2?\n  T1 ; T2 (A=1166,B=954)\n  T2 ; T1 (A=1160,B=960)\n  In either case, A+B = $2000 *1.06 = $2120\n  There is no guarantee that T1 will execute before T2 or vice-versa, if both are\n    submitted together.", "char_count": 538, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 20, "text_raw": "         Example (Contd.)\nConsider a possible interleaved schedule:\nT1: A=A+100,           B=B-100\nT2:          A=1.06*A,           B=1.06*B\n  This is OK (same as T1;T2). But what about:\nT1: A=A+100,                    B=B-100\nT2:          A=1.06*A, B=1.06*B\n  Result: A=1166, B=960; A+B = 2126, bank loses $6 !\nThe DBMS’s view of the second schedule:\nT1: R(A), W(A),                                R(B), W(B)\nT2:                R(A), W(A), R(B), W(B)", "char_count": 452, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 21, "text_raw": "Interleaved vs. Parallel processing", "char_count": 35, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 22, "text_raw": "Transactions and\n   schedules", "char_count": 29, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 23, "text_raw": "           Transactions\n\nTransaction is a sequence of operations, an atomic unit of work\nStructure of a committed (successful) transaction:\n     1.   begin  ← marks the beginning of transaction execution\n    2.   one or several read(X), write(X), local operations (e.g., var updates),\n        transaction control operations (e.g., locks), etc.\n    3.   End   ← mark the end of transaction execution\n    4.   one or several operations checking consistency, serializability, etc.\n    5.  commit ← successful completion, changes cannot be undone\nStructure of an aborted (unsuccessful) transaction: same beginning, but\n ends at any point with\n  N.  abort  ← unsuccessful completion, all changes must be undone\nA partial transaction:\n  a beginning of one above (‘waiting’ for next operation)", "char_count": 781, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 24, "text_raw": "             Schedules\n\n\nSchedule (or history, execution plan) S of\ntransactions T1, . . . , Tn: a (total) ordering of the\noperations of T1, . . . , Tn\n\n operations of different transactions can interleave\n\n operations of each Ti are in the same order as in Ti", "char_count": 250, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 25, "text_raw": "             Schedules\nExample:\n  Sa: r1(X ), r2(X ), w1(X ), r1(Y ), w2(X ), w1(Y )\n\n\n\n\n\nExample (complete):\n Sb : r1(X ), w1(X ), r2(X ), w2(X ), r1(Y ), a1, c2", "char_count": 153, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 26, "text_raw": "         Complete Schedule\nall T1, . . . , Tn are committed or aborted\n A transaction that successfully completes its\n   execution will have a commit instructions as the\n   last statement\n   By default, transaction assumed to execute commit\n      instruction as its last step\n A transaction that fails to successfully complete\n    its execution will have an abort instruction as the\n   last statement", "char_count": 395, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 27, "text_raw": "             Example\n\n\nLet\n T1 transfer $50 from A to B,\nand\n T2 transfer 10% of the balance from A\n   to B.", "char_count": 99, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 28, "text_raw": "             Schedule 1\n\n\n\n\nA serial schedule in which\n T1 is followed by T2", "char_count": 64, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 29, "text_raw": "             Schedule 2\n\n\n\nA serial schedule\n where T2 is followed\n by T1", "char_count": 61, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 30, "text_raw": "             Schedule 3\n\n\nThis schedule is not a\n serial schedule, but it is\n equivalent to Schedule 1\n  In Schedules 1, 2 and 3, the\n  sum A + B is preserved.", "char_count": 148, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 31, "text_raw": "             Schedule 4\n\n\n\nThe following concurrent\n schedule does not preserve\n the value of (A + B ).", "char_count": 91, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 32, "text_raw": "Serializability", "char_count": 15, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 33, "text_raw": "             Serializability\n\nEach transaction should preserve database\n consistency.\n  Serial execution of a set of transactions\n   preserves database consistency.\nA (possibly concurrent) schedule is\n serializable if it is equivalent to a serial\n schedule.", "char_count": 247, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 34, "text_raw": "        Serializable schedules\n\n\n\n\n\nC not serializable       D serializable", "char_count": 68, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 35, "text_raw": "       Conflicting Instructions\n\nInstructions li and lj of transactions Ti and Tj\n respectively,\nconflict\n  if and only if there exists some item Q accessed\n   by both li and lj,\n and at least one of these instructions wrote Q.", "char_count": 224, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 36, "text_raw": "       Conflicting Instructions\nli = read(Q), lj = read(Q).       don’t conflict.\nli = read(Q), lj = write(Q).    They conflict\n\n  r1(X), r2(X), w1(X), r1(Y), w2(X), w1(Y)\n\nli = write(Q), lj = read(Q).     They conflict\n\n  r1(X), w1(X), r2(X), w2(X), r1(Y), a1\n\nli = write(Q), lj = write(Q).    They conflict\n  r1(X), w1(X), r2(X), w2(X), r1(Y), a1", "char_count": 348, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 37, "text_raw": "       Conflicting Instructions\n\nA conflict between li and lj forces a (logical)\n temporal order between them.\nIf li and lj are consecutive in a schedule and\n they do not conflict,\n  their results would remain the same even if they\n  had been interchanged in the schedule.", "char_count": 268, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 38, "text_raw": "      Serializability Types\n\n       Different forms of\n    schedule equivalence\n      give the notions of:\n\n\n   Conflict         View\nserializability     serializability", "char_count": 163, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 39, "text_raw": "        Conflict Serializability\n\nIf a schedule S can be transformed into a\n schedule S’ by a series of swaps of non-\n conflicting instructions, we say that S and S’\n are conflict equivalent.\nWe say that a schedule S is conflict\n serializable if it is conflict equivalent to a\n serial schedule", "char_count": 287, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 40, "text_raw": "          Conflict equivalent\n\n\nTwo schedules are conflict equivalent if\n they are schedules of the same transactions\n  if the relative order of every conflict (read-\n   write, write-write) is the same in both\n  schedules", "char_count": 214, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 41, "text_raw": "     Conflict Serializability (Cont.)\nSchedule 3 can be transformed into Schedule 6, a serial schedule\n where T2 follows T1, by series of swaps of non-conflicting\n instructions.\n  Therefore Schedule 3 is conflict serializable.\n\n\n\n\n\n                 Schedule 3                                      Schedule 6", "char_count": 304, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 42, "text_raw": "     Conflict Serializability (Cont.)\nExample of a schedule that is not conflict\n serializable:\n\n\n\n\n\nWe are unable to swap instructions in the above\n schedule to obtain either the serial schedule < T3,\n T4 >, or the serial schedule < T4, T3 >.", "char_count": 240, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 43, "text_raw": "Conflict Serializability (Cont.)\n\n\n\n\n\n    Schedule C is not (conflict-)serializable\n    Schedule D is serializable (equivalent to T1;T2)", "char_count": 136, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 44, "text_raw": "      Testing for Serializability\nConsider some schedule of a set of transactions\n T1, T2, ..., Tn\nPrecedence graph\n  a direct graph where the vertices are the\n   transactions.\nWe draw an arc from Ti to Tj if the two\n transactions conflict, and Ti accessed the data\n item on which the conflict arose earlier.\nWe may label the arc by the item that was\n accessed.", "char_count": 360, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 45, "text_raw": "    Test for Conflict Serializability\n\nA schedule is conflict serializable if and\n only if its precedence graph is acyclic.\nIf precedence graph is acyclic, the\n serializability order can be obtained by a\n topological sorting of the graph.\n  This is a linear order consistent with the\n    partial order of the graph.\n  For example, a serializability order for\n   Schedule A would be\n    T5 → T1 → T3 → T2 → T4\n    Are there others?", "char_count": 431, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 46, "text_raw": "conflict serializable", "char_count": 21, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 47, "text_raw": "Example 1", "char_count": 9, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 48, "text_raw": "Example 2", "char_count": 9, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 49, "text_raw": "Example 3", "char_count": 9, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 50, "text_raw": "        View Serializability\n\nLet S and S’ be two schedules with the same set of transactions.\nS and S’ are view equivalent if the following three conditions are\n met, for each data item Q.\n1.    If in S, transaction Ti reads the initial value of Q,\n    then in S’ transaction Ti must read the initial value of Q.\n2.    If in S transaction Ti executes read(Q), and that value was\n    produced by transaction Tj ,\n    then in S’ transaction Ti must read the value of Q that was\n    produced by the same write(Q) of Tj .\n3.  The transaction that performs the final write(Q) operation in S\n   must also perform the final write(Q) operation in S’.", "char_count": 637, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 51, "text_raw": "         View-serializability\n\nserializability based on view equivalence\nEach conflict-serializable is view-serializable\nEach view-serializable is semantic-\n serializable (so result-serializable)\nDifficult to check view-equivalence (NP-\n complete)", "char_count": 242, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 52, "text_raw": "     View Serializability (Cont.)\n\nA schedule S is view serializable if it is view-\n equivalent to a serial schedule.\nBelow is a schedule which is view-serializable but not\n conflict serializable.", "char_count": 193, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 53, "text_raw": "     Test for View Serializability\n\nThe precedence graph test for conflict serializability\n cannot be used directly to test for view serializability.\n  Extension to test for view serializability has cost exponential in\n    the size of the precedence graph.\nThe problem of checking if a schedule is view-serializable\n falls in the class of NP-complete problems.\n  Thus, existence of an efficient algorithm is extremely unlikely.\nHowever practical algorithms that just check some\n sufficient conditions for view serializability can still be\n used.", "char_count": 545, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 54, "text_raw": " Serializability in concurrency control\n\nEvery serial schedule is serializable, but not other way round\nSerializable schedules give benefit of concurrent execution\nwithout giving up any correctness\nDifficult to test for serializability in practice (even\nconflict-serializability)\n    system load, time of transaction submission, and process priority\n       affect ordering of operations\n     often, we need to ensure serializability before the transactions complete\nDBMSs enforce concurrency control protocols that ensure\nserializability", "char_count": 542, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 55, "text_raw": "           Recoverability\nFor durability, we need to be able to recover\n schedules from transaction and system failures\nSchedules with respect to recoverability, are\n classified into:\n  impossible to recover\n  possible to recover\n  recoverable\n  easy to recover\n  cascadeless, strict", "char_count": 279, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 56, "text_raw": "       Recoverable Schedules\n\nNeed to address the effect of transaction\n failures on concurrently running\n transactions.\nRecoverable schedule\n  if a transaction Tj reads a data item previously\n   written by a transaction Ti ,\n  then the commit operation of Ti appears before\n   the commit operation of Tj.", "char_count": 302, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 57, "text_raw": "       Recoverable Schedules\n\nThe following schedule is not recoverable\nIf T8 should abort, T9 would have read (and possibly shown to\n the user) an inconsistent database state.", "char_count": 171, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 58, "text_raw": "            Examples\nr1(X ), r2(X ), w1(X ), r1(Y ), w2(X ), c2, w1(Y ), c1\n  recoverable\nr1(X ), w1(X ), r2(X ), r1(Y ), w2(X ), w1(Y ), c2, a1\n  non-recoverable\nr1(X ), w1(X ), r2(X ), r1(Y ), w2(X ), w1(Y ), a1, c2\n  still non-recoverable\nr1(X ), w1(X ), r2(X ), r1(Y ), w2(X ), w1(Y ), a1, a2\n  recoverable", "char_count": 306, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 59, "text_raw": "         Cascading Rollbacks\nA single transaction failure leads to a series of transaction\n rollbacks.\n  Can lead to the undoing of a significant amount of work\nConsider the following schedule where none of the transactions\n has yet committed (so the schedule is recoverable)\n  If T10 fails, T11 and T12 must also be rolled back.", "char_count": 324, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 60, "text_raw": "       Cascadeless schedules\n\nRecoverable schedules may need cascading aborts\n (cascading rollbacks) to recover\n  an (non-committed) transaction has to abort since it has\n   read from another failed transaction\n  Example\n  r1(X), w1(X), r2(X), r1(Y), w2(X), w1(Y), a1, a2\nThis may affect many transactions, and rollbacks may\n be expensive\nCascadeless schedule idea: no cascade rollbacks", "char_count": 385, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 61, "text_raw": "       Cascadeless schedules\nEvery transaction in the schedule reads only\n from committed transactions\n  (i.e., for each r(X), X can be previously written by\n   the same transaction, written by another\n  committed transaction or have not been written\n   before)\nExample:\n  r1(X), w1(X), r1(Y), r2(Z), w1(Y), c1, w2(Z), r2(X),\n   w2(X), c2", "char_count": 335, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 62, "text_raw": "            Strict schedules\nCascadeless schedules may still have fairy complicated\nrecovery protocols, because we cannot just restore the values\n of all writes of an aborted transaction\n Example: w1(X ), w2(X ), a1\n  This may all affect many transactions (no cascades though)\nStrict schedule: no transaction can read or write an item X\n until the previous write of X is committed or aborted\nExamples:\n w1(X ), c1, w2(X )\n w1(X ), a1, w2(X )", "char_count": 436, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 63, "text_raw": "        Recovery hierarchy\n\n\n\n\nEvery strict schedule is cascadeless\nEvery cascadeless is recoverable", "char_count": 94, "is_empty": false}
{"lecture_id": "ADB_Lec07", "source_file": "ADB_Lec07.pdf", "page_num": 64, "text_raw": "", "char_count": 0, "is_empty": true}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 1, "text_raw": "       CSAI 302\n\nAdvanced Database\n\n     Systems\n\n           Lec 08\n    Concurrency Control", "char_count": 84, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 2, "text_raw": "            Introduction\n\nA database must provide a mechanism that will\n ensure that all possible schedules are:\n  either conflict or view serializable, and\n  are recoverable and preferably cascadeless\nA policy in which only one transaction can\n execute at a time generates serial schedules, but\n provides a poor degree of concurrency\nTesting a schedule for serializability after it has\n executed is a little too late!", "char_count": 411, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 3, "text_raw": "   Concurrency control problems\n\nDirty write (or lost update)\n\nDirty read (or temporary update)\n\nNon-repeatable read\n\nIncorrect summary (or phantom\n phenomena)", "char_count": 160, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 4, "text_raw": "       Dirty write (lost update)\n\nTwo transactions update (read and write) the same\n item, second update starts before the first is complete\n  (updates are interleaved)\nResult: incorrect value", "char_count": 188, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 5, "text_raw": "    Dirty read (temporary update)\n\nA transaction updates an item,\nnew value is used by another transaction,\nthe first transaction fails and its update is rolled back\nResult: the second transaction relies on an incorrect value", "char_count": 225, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 6, "text_raw": "        Non-repeatable read\n\nOne transaction reads the same item twice\nanother transaction changes its value in between\nResult: the first transaction gets different values of\n the same item", "char_count": 184, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 7, "text_raw": " Incorrect summary (Phantom phenomena)\n\nOne transaction calculates an aggregate summary\nwhile other transactions update some involved items\nResult: the aggregate is inconsistent", "char_count": 179, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 8, "text_raw": "     Why recovery is needed?\n\n(if something goes wrong, effects roll back)\nShould be either\n  Committed:\n    evaluated in full and all effects permanently\n    recorded\n  Aborted:\n   no effect on the database (everything done\n     rolled back)", "char_count": 243, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 9, "text_raw": "          The System Log\n\nSystem log keeps track of transaction operations\n  Sequential, append-only file\n  Not affected by failure\nLog buffer\n  Main memory buffer\n When full, appended to end of log file on disk\nLog file is backed up periodically\nUndo and redo operations based on log possible", "char_count": 291, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 10, "text_raw": "   Commit Point of a Transaction\n\nOccurs when all operations that access the\n database have completed successfully\nTransaction writes a commit record into the\n log\n  If system failure occurs, can search for\n   transactions with recorded start_transaction\n   but no commit record", "char_count": 278, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 11, "text_raw": "Concurrency\n  Control", "char_count": 21, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 12, "text_raw": "     Concurrency Control (Cont.)\nGoal\n  Develop concurrency control protocols that\n   will assure serializability.\nConcurrency-control schemes tradeoff between\n the amount of concurrency they allow and the\n amount of overhead that they incur.\n Some schemes allow only conflict-serializable\n   schedules to be generated, while others allow view-\n   serializable.", "char_count": 360, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 13, "text_raw": " Concurrency Control vs. Serializability Tests\n\nConcurrency-control protocols\n  allow concurrent schedules,\n  ensure that the schedules are conflict/view serializable,\n  and are recoverable and cascadeless.\nConcurrency control protocols do not examine the\n precedence graph as it is being created\n  Instead, a protocol imposes a discipline that avoids non-\n    serializable schedules.\n   Tests for serializability help us understand why a\n        concurrency control protocol is correct.", "char_count": 493, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 14, "text_raw": "    Weak Levels of Consistency\n\nSome applications are willing to live with weak\n levels of consistency, allowing schedules that are\n not serializable\n  E.g., a read-only transaction that wants to get an\n   approximate total balance of all accounts\n  E.g., database statistics computed for query\n   optimization can be approximate.\n  Such transactions need not be serializable with\n   respect to other transactions\nTradeoff accuracy for performance", "char_count": 448, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 15, "text_raw": "            Isolation levels\n\nIt is not always necessary to ensure no problems of all types\n  in some applications we can tolerate some problems\n   for the sake of more concurrency (i.e., efficiency)\nSimple isolation level hierarchy of schedules (and transaction\n management protocols):\n   Level 0: no dirty reads\n   Level 1: no dirty writes\n   Level 2: no dirty reads, no dirty writes\n   Level 3: (true isolation): no dirty reads, no dirty writes, no non-repeatable\n    reads\nA protocol that ensure recoverable and serializable schedules is Level 3", "char_count": 546, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 16, "text_raw": "  Implementation of Isolation Levels\n\nLocking\n   Lock on whole database vs lock on items\n  How long to hold lock?\n   Shared vs exclusive locks\nTimestamps\n   Transaction timestamp assigned e.g. when a transaction begins\n   Data items store two timestamps\n\n      Read timestamp\n\n      Write timestamp\n   Timestamps are used to detect out of order accesses\nMultiple versions of each data item\n   Allow transactions to read from a “snapshot” of the database", "char_count": 463, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 17, "text_raw": "Locking", "char_count": 7, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 18, "text_raw": "               Locks\n\nLock: a variable associated with a data item\n  describes status for operations that can be applied\n  unique Lock(X) for each data item X\nbinary locks:\n  Lock(X) takes values locked or unlocked (or 1 and 0)\nshared/exclusive locks:\n  Lock(X) takes values read-locked, write-locked, or unlocked\nThese variables are managed by concurrency control\n subsystem", "char_count": 368, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 19, "text_raw": "            Binary locks\n\nfor each item X, variable Lock(X) can have on\n  of the two values:\n\n  Lock(X) is locked (or 1) means that X is locked\n     by a transaction and cannot be accessed by\n     any other transaction\n  Lock(X) is unlocked (or 0) means that X is\n      available and can be accessed when requested\n\n schedules start with all unlocked", "char_count": 342, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 20, "text_raw": "     Binary locks in transactions\nUse two operations lock(X) and unlock(X) applying\n these rules:\n  all read(X) and write(X) must be between the two\n  well-formed: no unlocking without locking, etc.\nThese operations are implemented such that\n  when lock(X) is issued\n     if Lock(X) = 1, the transaction is forced to wait for Lock(X) = 0\n       (in the schedule)\n     if Lock(X) = 0, it is set to 1 and the transaction can proceed\n  when unlock(X) is issued, Lock(X) is set to 0", "char_count": 481, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 21, "text_raw": "Ex1: Transactions with binary locks\n\n\n                        T1                                           T2\n                         lock(X );                                                    lock(X );\n                        read(X );                                                     lock(Y );\n                  X := X − 1;                                                  read(X );\n                          write(X );                                                 unlock(X );\n                        unlock(X );                                      X := X + 1;\n                          lock(Y );                                                    lock(X );\n                         read(Y );                                                     write(X );\n                     Y := Y + 1;                                                  unlock(Y );\n                           write(Y );                                                 unlock(X );\n                        unlock(Y );\n\nT1 : l1(X ), r1(X ), w1(X ), u1(X ), l1(Y ), r1(Y ), w1(Y ), u1(Y ): Ok!\nT2 : l2(X ), l2(Y ), r2(X ), u2(X ), l2(X ), w2(X ), u2(Y ), u2(Y ): Ok!\nNote: T2 locks and unlocks X twice and locks Y without a need", "char_count": 1204, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 22, "text_raw": "Ex2: Transactions with binary locks\n\n\n                         T1                                            T2\n                          lock(X );\n                                                     lock(X );\n                          read(X\n                                                      lock(Y );                                                          );X := X − 1;\n                                                   read(X );\n                           write(X );\n                                                  unlock(X );\n                         unlock(X );\n                                      X := X + 1;\n                          read(Y );\n                                                     lock(X );\n                           lock(Y );\n                                                      write(X );\n                      Y := Y + 1;\n                            write(Y );\n                                                  unlock(X );\n                         unlock(Y );\n\n    T1 : l1(X ), r1(X ), w1(X ), u1(X ), r1(Y ), l1(Y ), w1(Y ), u1(Y ): Not ok\n   T2 : l2(X ), l2(Y ), r2(X ), u2(X ), l2(X ), w2(X ), u2(Y ): Not ok\n    Note: T1 reads Y without locking, and T2 does not unlock Y", "char_count": 1214, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 23, "text_raw": "    Ex: Schedules with binary locks\n\nS1 : l1(X ), r1(X ), u1(X ), l2(X ), r2(X ), u2(X ), l1(X ), w1(X ), u1(X )\n Ok!\nS2 : l1(X ), r1(X ), l2(X ), u1(X ), r2(X ), u2(X ), l1(X ), w1(X ), u1(X )\n Ok!\n\nS3 : l1(X ), r1(X ), l2(X ), r2(X ), u1(X ), u2(X ), l1(X ), w1(X ), u1(X )\n  Not ok\n\n     (implementation of l2(X ) is ‘broken’: should not allow to continue T2\n       with r2(X ) before u1(X ))\n Note: locks (i.e., the rules and implementations as above)\n   do not guarantee serializability by themselves;", "char_count": 510, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 24, "text_raw": "             Lock table\n\nConcurrency control subsystem has a lock manager\nmodule that relies on a lock table:\n  has schema [Data_item_name, Locking_transaction]\n   keeps only locked items (others are unlocked)\nLock manager keeps track of and controls access\n   to locks by checking the rules for transactions\n  and enforcing allowed schedules (waiting, etc.)\nBinary locking is too restrictive anyway", "char_count": 391, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 25, "text_raw": "       Shared/exclusive locks\n\n\nAllow sharing for several reading transactions (but exclusive writes)\nfor each item X, Lock(X) is\n  read-locked (or share-locked) means that X is read by a\n    transaction\n     variable #READS(X) keeps the number of reading transactions\n  write-locked (or exclusive-locked) means that X is exclusively\n    locked for writing by some transaction and cannot be accessed by\n    others\n  unlocked means that X is available for access (with locking)\nschedules start with all Lock(X) = unlocked and #READS(X) = 0", "char_count": 538, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 26, "text_raw": " Transaction with shared/exclusive locks\n\nuse three operations, read_lock(X), write_lock(X) and unlock(X) with\nrules:\n    each read(X) is after read_lock(X) or write_lock(X) (with no\n       unlock(X) in between)\n    each write(X) is after write_lock(X) (with no unlock(X) in\n       between)\n    each read_lock(X) and write_lock(X) has unlock(X) at some\n        point after\n    no changing of lock type before unlocking;\n      that is, no read_lock(X) after write_lock(X) without unlock(X)\n         between", "char_count": 510, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 27, "text_raw": "Implementation of read_lock", "char_count": 27, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 28, "text_raw": "Implementation of write_lock", "char_count": 28, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 29, "text_raw": "Implementation of unlock", "char_count": 24, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 30, "text_raw": "            Examples\n\nS1 : rl1(X ), r1(X ), u1(X ), rl2(X ), r2(X ), u2(X ), wl1(X ), w1(X ), u1(X )\n  Ok!\nS1′: rl1(X ), r1(X ), u1(X ), rl2(X ), r2(X ), u2(X ), rl1(X ), w1(X ), u1(X )\n  Not ok (write with read lock)\nS1′′: wl1(X ), r1(X ), u1(X ), rl2(X ), r2(X ), u2(X ), wl1(X ), w1(X ), u1(X )\n  Ok!\nS3 : rl1(X ), r1(X ), rl2(X ), r2(X ), u1(X ), u2(X ), wl1(X ), w1(X ), u1(X )\n  Ok!\nS3′: rl1(X ), r1(X ), wl2(X ), w2(X ), u1(X ), u2(X ), wl1(X ), w1(X ), u1(X )\n  Not ok (implementation of wl2(X ) is ‘broken’: should be exclusive)\nS3′′: rl1(X ), r1(X ), rl2(X ), r2(X ), u2(X ), wl1(X ), w1(X ), u1(X )\n  Not ok (T1 is not following the rules: a second lock without unlocking)", "char_count": 683, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 31, "text_raw": "Two-phase locking", "char_count": 17, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 32, "text_raw": "        Two-phase locking\n\nA transaction (binary or shared/exclusive)\n follows two-phase locking protocol if:\n  all locking operations are before all unlocking\n   operations\nTwo phases:\n  locking (first, expanding, or growing) phase\n  unlocking (second or shrinking) phase", "char_count": 269, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 33, "text_raw": "Two-phase locking: negative example\n\n\n\n\n\n  Transactions T1 and T2 (left) do not follow the two-phase locking\n  protocol, so they allow for a non-serializable schedule (right)", "char_count": 174, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 34, "text_raw": "Two-phase locking: positive example\n\n\n\n\n\nVersions T1′and T2′(left) follow the two-phase locking protocol, so no\nnon-serializable schedule complies the rules\n\n\n                                                                                                                                                         35", "char_count": 314, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 35, "text_raw": " serializability by two-phase locking\n\nTwo-phase locking guarantees serializability\n  (i.e., every allowed schedule of transactions\n   following the rules of the two-phase locking\n   protocol is (conflict-serializable)\n As the result, we can create a serializable\n  schedule operation by operation, without\n     knowing the transactions in full", "char_count": 346, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 36, "text_raw": "           Drawback\n\nwe may end up in a deadlock", "char_count": 38, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 37, "text_raw": "Deadlocks", "char_count": 9, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 38, "text_raw": "         Deadlock problem\n\nTwo (or more) transactions may be stuck in a\ndeadlock, where each transaction is waiting for\nanother transaction, making a ‘waiting cycle’\n\n\n\n\nThis may happen for all types of locks,", "char_count": 202, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 39, "text_raw": "    Deadlock avoidance: Overview\n\nprotocols that deal with deadlocks:\n   (naive)\n   deadlock prevention\n   deadlock detection\n   timeouts\nMost of protocols may roll back (i.e., abort and restart) some transactions\n   cascadeless (i.e., recoverable) due to two-phase locking (all deadlocked\n     transactions in the growing phase, so no one have read what they have\n     written)\n  may face and have to deal with starvation:\n     a transaction rolls back over and over again indefinitely", "char_count": 491, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 40, "text_raw": "         naive approaches\n\nconservative two-phase locking (not practical)\nOR\nlocking according to a predefined order of all items\n   all items are ordered in advance (e.g., by address)\n   all locking of a transaction is in the increasing order\n  no deadlocks by construction\n   not practical due to\n      limited concurrency\n      unreasonable restrictions on transactions", "char_count": 372, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 41, "text_raw": "   Deadlock prevention protocols\n\nTimestamp-based (wait-die and wound-wait)\nWaiting-based (no-waiting and cautious-waiting)\n  All four avoid deadlocks, but often force transaction\n   aborts without a real deadlock\nDeadlock prevention\n  is not a popular approach in practice due to high\n   overhead,\n  but may be useful when transactions are long and\n   use many items", "char_count": 370, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 42, "text_raw": " Timestamp-based deadlock prevention\n\n\n\nTransaction timestamp:\n a unique number TS (T) assigned to each\n   transaction T so that\n TS (T′) < TS (T) for each T′ started before (for the\n    first time)", "char_count": 200, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 43, "text_raw": "            Wait-die rule\nlet transaction T try to lock an item that is\n already locked by T′\n  if TS (T) < TS (T′) (i.e., T is older than T′), then T\n   waits for T′ to release\n  otherwise (i.e., T is younger) T aborts (i.e., ‘dies’)\n  and restarts with the same timestamp\nThe older proceeds (maybe, after waiting)\n and the younger restarts, so the wait-die rule\n guarantees no deadlocks, no starvation", "char_count": 395, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 44, "text_raw": "         Wound-wait rule\nlet transaction T try to lock an item that is\n already locked by T′\n  if TS (T) < TS (T′) (i.e., T is older than T′), then T′\n   aborts (i.e., is ‘wounded’) and restarts with the\n  same timestamp\n  otherwise (i.e., T is younger) T waits for T′ to\n   release\nThe older proceeds and the younger restarts\n (maybe, after waiting), so the wound-wait rule\n guarantees no deadlocks, no starvation", "char_count": 409, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 45, "text_raw": "            Examples\nWhen T1 tries to lock X that is already locked by T2\n\nif T1 is older\n   wait-die: T1 waits\nb1, . . . , b2, . . . , l2(X ), . . . , l1(X ), [T1 waits] . . . , u2(X ), . . .\n   wound-wait: T2 dies\nb1, . . . , b2, . . . , l2(X ), . . . , l1(X ), a2, . . .\n\nif T1 is younger\n   wait-die: T1 dies\nb2, . . . , b1, . . . , l2(X ), . . . , l1(X ), a1, . . .\n   wound-wait: T1 waits\nb2, . . . , b1, . . . , l2(X ), . . . , l1(X ), [T1 waits] . . . , u2(X ), . . .", "char_count": 474, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 46, "text_raw": " Waiting-based deadlock prevention\n(No timestamps in these protocols)\nLet transaction T try to lock an item that is already locked\n by T′\n  no-waiting rule:\n    T aborts and restarts\n  cautious-waiting rule:\n     if T′ is not waiting for anyone, then T waits (regularly checked)\n     otherwise, T aborts and restarts\nAny of these rules guarantees no deadlocks (no cyclic\n waiting is possible)\nSpecial care should be taken to avoid starvation.\nEasier, but even more unnecessary aborts", "char_count": 492, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 47, "text_raw": "         Deadlock detection\n\nDeadlock happens when there is a cycle of transactions waiting\nfor each other\nWe can detect a cycle and break the cycle by aborting one\ntransaction (the victim)\nCan be done by maintaining the wait-for graph:\n     nodes: active transactions\n     (directed) edges: transactions waiting for transactions\nA cycle in the wait-for graph means a deadlock\nMay be resource-consuming to maintain\nVictim selection should be done cautiously to avoid starvation", "char_count": 476, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 48, "text_raw": "             Timeouts\n\nTimeout-based deadlock avoidance:\n fix a waiting timeout period in advance\n a transaction waits for the timeout period\n  (at most) after this abort and restart\nSimple and easy to maintain\nNo guarantees\n (unknown overhead, possible starvation)", "char_count": 258, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 49, "text_raw": "Timestamps", "char_count": 10, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 50, "text_raw": "  Timestamp-based concurrency control\nWe can use timestamps for concurrency\ncontrol without locking:\n Run transactions until something goes\n  wrong (i.e., a conflict is detected)\n Roll back one of the conflict transactions\n  based on their timestamps\n   roll back is abort and restart with a new\n    timestamp", "char_count": 311, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 51, "text_raw": "  Timestamp-based concurrency control\n\nTimestamp-based concurrency control protocols:\n    all ensure serializability\n       transactions arranged by their timestamps\n   may not guarantee recoverability\n   may not guarantee no starvation\nSeveral timestamp-based protocols\n    basic: ensures serializability, but not recoverability\n     strict: ensures serializability and strictness (so recoverability)\n    basic/strict with Thomas write rule: less roll-backs", "char_count": 465, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 52, "text_raw": "      Item timestamp variables\n\nBesides the timestamp of a transaction , the concurrency\ncontrol subsystem maintains two variables for each item X :\n read timestamp ReadTS(X):\n    the timestamp of the youngest transaction that has read X\n write timestamp WriteTS(X):\n    the timestamp of the youngest transaction that has written X\nMaintained in appropriate timestamp tables\n (similar to the lock table in lock-based protocols)\n(All initialised by 0)", "char_count": 452, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 53, "text_raw": " Basic timestamp-ordering protocol\n\n\nIf there is a conflict that violates the\norder (of the serial schedule imposed by\nthe timestamps),\nthen roll back the transaction of the\nsecond operation of the conflict", "char_count": 207, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 54, "text_raw": "        Read-write conflict 1\n\na transaction may try to read data item X too\n late\n\n\n\n\n\nShould abort and restart T1", "char_count": 109, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 55, "text_raw": "        Read-write conflict 2\n\na transaction may try to write data item X too\n late\n\n\n\n\n\nShould abort and restart T1", "char_count": 110, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 56, "text_raw": "        Write-write conflict\n\na transaction may try to write data item X too\n late\n\n\n\n\n\nShould abort and restart T1", "char_count": 109, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 57, "text_raw": "   Basic timestamp-ordering Rules\n\nRule 1. When transaction T issues read(X ):\n if WriteTS (X) > TS (T) (i.e., someone younger written X ),\n then roll-back T (i.e., abort and restart T with a new timestamp)\n otherwise, execute the rest of read(X ) and set ReadTS (X) to\n  max(ReadTS (X), TS (T))\nRule 2. When transaction T issues write(X ):\n if ReadTS (X) > TS (T) or WriteTS (X) > TS (T) (i.e., someone younger\n   accessed X ),\n then roll-back T (i.e., abort and restart T with a new timestamp)\n otherwise, execute the rest of write(X ) and set WriteTS (X ) to TS (T )", "char_count": 574, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 58, "text_raw": "Basic timestamp-ordering properties\n\n\nEnsures serializable schedules, but they\n may be not recoverable,\n    (ensured by strict version)\n may have cascading roll-backs,\n    (avoided by strict version)\n may have starving transactions", "char_count": 237, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 59, "text_raw": " Strict timestamp-ordering protocol\n\n\nIdea\n In the rules the execution is postponed\n  (using e.g., locking) until the pervious write\n   is committed (so ensuring strict schedules)", "char_count": 180, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 60, "text_raw": "               Rule 1\n\nWhen transaction T issues read(X ):\n  if WriteTS (X ) > TS (T ) then roll-back T\n  otherwise\n    wait until the transaction T′such that\n     WriteTS (X ) = TS (T′) is committed (if there is\n        such)\n    execute the rest of read(X ) and\n     set ReadTS (X ) to max(ReadTS (X ), TS (T ))", "char_count": 305, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 61, "text_raw": "               Rule 2\n\nWhen transaction T issues write(X ):\n  if ReadTS (X ) > TS (T ) or WriteTS (X ) > TS (T ) then\n    roll-back T\n  otherwise\n    wait until the transaction T′such that\n       WriteTS (X ) = TS (T′) is committed (if there is\n           such)\n    execute the rest of write(X ) and set WriteTS (X ) to\n     TS (T )", "char_count": 323, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 62, "text_raw": "       Thomas writing rule\n\nImprovement (less roll-backs) for both basic and strict protocols in case of write-\nwrite conflict\n\n\n\n\n\nRule 1. When transaction T issues read(X ):                    . . .    (same)\n\nRule 2. When transaction T issues write(X ):\n\n  if ReadTS (X ) > TS (T ) then roll-back T\n\n  if WriteTS (X ) > TS (T ) ignore the operation and proceed\n\n  otherwise              . . .    (same, i.e., possibly wait, execute, update)\n\n       Same guarantees as the versions without the improvement", "char_count": 507, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 63, "text_raw": "Multi-versioning", "char_count": 16, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 64, "text_raw": " Multiversioning concurrency control\nMulti-versioning idea:\n  several versions of the (value of the) same item are\n   kept by the system\n  transactions are the same as usual (in particular, they\n   request reads/writes for items, not versions)\n  the versions of items are managed by the\n   concurrency control subsystem\nPros: increase concurrency\nCons: more storage is needed to maintain\n multiple versions", "char_count": 411, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 65, "text_raw": "   Concurrency\n       with\nMultiple granularity", "char_count": 44, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 66, "text_raw": "       Data item granularity\n\nGranularity: the size of data items\n   field value of a record (fine)\n   record\n   disk block\n   table file\n  whole database (coarse)\nThe tradeoff:\n  more coarse allows for lower degree of concurrency\n  more fine leads to more overhead (lock management, etc.)\nBest item size depends on transaction type:\n   if a transaction accesses few records, a record as item is good\n   if a transaction accesses many records, a block as item is good\nIt may be nice to have different granularity for different transactions", "char_count": 545, "is_empty": false}
{"lecture_id": "ADB_Lec08", "source_file": "ADB_Lec08.pdf", "page_num": 67, "text_raw": "", "char_count": 0, "is_empty": true}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 1, "text_raw": "       CSAI 302\n\nAdvanced Database\n\n     Systems\n\n           Lec 09\nDatabase recovery techniques", "char_count": 89, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 2, "text_raw": "     ACID principles: Reminder\n\n Atomicity       •• TransactionEnsured by theperformedrecoveryinsubsystemits entirety or not at all\n\nConsistency    • The database should always remain consistent                                 • Ensured by the transaction program\n\n  Isolation         •• TransactionEnsured by theshouldconcurrencynot interferecontrolwith subsystemothers\n\n Durability       •• ChangesEnsured byof committedthe recoverytransactionssubsystemmust persist", "char_count": 462, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 3, "text_raw": "     Recoverable Transactions\n\nTo ensure durability in ACID, a schedule may be\n\n\n   Recoverable         Cascadeless              Strict\n\n• T does not              • T does not read        • T is cascadeless\n  commit before       from               and does not\n  each T’ from         uncommitted         overwrite any\n  which T read          transactions           values written by\n  have committed                         uncommitted\n                                                transactions", "char_count": 492, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 4, "text_raw": "Recovery", "char_count": 8, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 5, "text_raw": "           Lecture content\n\nRecovery concepts           Recovery protocols\n\n\nIntro              Shadowing\nCache              Deferred-update\nLog                Immediate-update\nCheckpoint        ARIES", "char_count": 197, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 6, "text_raw": "          Recovery intro\n\n                               Computer failure    Transaction\n                                    (system crash)        failure\n                                                                • hardware, software,         • division by zero,Recovery:                                            network errors             constraint violation,\n                                                                                             etc.\n  restores database to\n                                     Local transaction    Concurrency  most recent                                       errors               control enforced\n                                                                • no data found,                • serializability   consistent state                                        programmed                violation, deadlock\n   before failure                   exception, etc.              break, etc.\nTypes of failures ➔    Disk crash           Physical problems                                                                • persistent errors with       • power cut, fire,\n                                                   disk reads or writes         catastrophe, etc.", "char_count": 1210, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 7, "text_raw": "        Groups of failures\n Disk is (significantly)                           Disk is not damageddamaged (catastrophe,                              (everything else)    disk crash, etc.)\n\n                                              recover consistency by undoing\n                                         and redoing some operations\n                                                  following a recovery protocol\n\n\n   restore the whole database from             use the database on the disk and\n          back-up storage.                           a log of operations\n\n\n                                          need to take into account the\n                                           cache in the main memory", "char_count": 702, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 8, "text_raw": "Cache", "char_count": 5, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 9, "text_raw": "              Cache\n\nDBMSs use (dedicated) cache:\n\n   Collection of buffers (pages in main memory) blocks on disk\n\nSome information (data itself, indexes, logs, etc.)\n\n  from the disk are kept in main-memory cache for quick access\n\nto perform an operation with data, the cache is first checked:\n\n   if the needed block is in cache, it is used\n\n   otherwise, an existing cache buffer is replaced by the needed block\n   from disk using buffer replacement policies\n\n   if the operation is write, then the buffer becomes dirty", "char_count": 518, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 10, "text_raw": "         Flushing approaches\n\nEach buffer in the cache has a dirty bit (flag) attached:\n  was the buffer modified or not\nFlushing approaches:\n  in-place flushing:\n    new (cache) version replaces the old (disk) one if dirty bit is 1\n           • used in most cases\n  shadowing:\n    new version is written in another place and the old version\n        is kept\n           • overhead", "char_count": 377, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 11, "text_raw": "    Buffer\n  replacement\n    policies\n\nmethods to decide which cache\n   buffers should be flushed", "char_count": 93, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 12, "text_raw": "              LRU\n\nBasic standard replacement policy is LRU:\n\n  the least recently used buffer is flushed\n   (replaced)\n\n  not specialized for DBs and not effective, because\n   different domains (types of information) may\n   benefit from different treatment", "char_count": 246, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 13, "text_raw": "    Domain separation technique\n\n\nEach domain (data, indexes, logs, or relations) has\n its own dedicated cache\nLRU (least recently used) policy is used in each\n individually\n  better results than common LRU\nCan be improved in several ways:\n   Hot set, clock sweep", "char_count": 264, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 14, "text_raw": "       Clock sweep with hot set\n\nHot set:\n   blocks that should always be in cache until a certain point\n   decided externally (e.g., smaller relation in nested-loop join)\nClock sweep over other buffers (for each domain separately):\n  each (non-hot) cache buffer has an integer count value\n  cache buffers are checked in a round-robin ‘cycle’ with some\n     regularity, maintaining individual counts\n   if a buffer has started to be used since the last time visited, increment its\n    count\n   otherwise, decrement its count\n   if we need to replace a buffer with a new block from the disk, the buffer with\n    the least count is replaced", "char_count": 640, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 15, "text_raw": "System Log", "char_count": 10, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 16, "text_raw": "           System log\n\nSystem log keeps track of executed operations of\n transactions:\n  sequential, append-only file (i.e., a table of entries)\n  reading and writing the log are not affected by failure\n   except disk or catastrophic failures\n      (i.e., logging is done by stand-alone system operations\n     which is not a part of any transaction operations)\n  backed up periodically to guard against these failures", "char_count": 411, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 17, "text_raw": "      System log: Properties\n\nSystem log keeps track of relevant executed operations of\n transactions:\n  in particular, we do not need to log computations\n  log keeps the effects of data writes and maybe reads (not write\n   and read operations)\nlog also keeps the beginnings and the ends (commit or\n abort) of transactions\n   (e.g., entries of the form [commit, T])\nlog keeps other information\n   e.g., about checkpoints and dirty buffer table", "char_count": 444, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 18, "text_raw": "  System log: Read and Write entries\n\nSystem log table can have read and write entries of several\n types:\n  UNDO- (OLD-) WRITE entry\n     keeps the before-image (i.e., old value) of a written item used to\n     undo the write if the transaction is aborted\n  REDO- (NEW-) WRITE entry\n     keeps the after-image (i.e., new value) of a written item used for\n      redo the write if the transaction is committed,\n             • but the effect is not on the disk (only in a dirty cache buffer)\n  UNDO&REDO-WRITE entry\n     keeps both above", "char_count": 538, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 19, "text_raw": "         Log cache buffer\nSystem log cache buffer:\n  main memory buffer (cache)\n   keeps the last part of the log\n  when full, appended (i.e., flushed) to the log file on\n      the disk\nLog cache buffer may also be flushed to ensure\nwrite-ahead logging:\n\n  log information about a transaction operation is\n   flushed before the effect of the operation is\n   flushed itself", "char_count": 369, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 20, "text_raw": "Write-Ahead Logging (WAL)", "char_count": 25, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 21, "text_raw": "  Write-ahead logging: More detail\nA recovery protocol follows write-ahead logging if\n\n before-image (the old version) of each item on the\n   disk cannot be overwritten (by the flushing buffer)\n  by its after-image (the new version) until all UNDO\n  (OLD) log entries have been flushed to disk\n a transaction cannot commit\n  until all UNDO (OLD) and REDO (NEW) log\n     entries for that transaction have been flushed\n     to disk\n(Most of) recovery protocols are write-ahead logging", "char_count": 485, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 22, "text_raw": "          WAL steps\n\nLog First\n  DBMS writes the intended changes as WAL records to an append-only log file before\n     modifying any database files.\nFlush to Disk\n   Before DBMS marks the transaction as committed, it flushes the WAL to disk.\n\n      This guarantees durability: even if the system crashes before applying the changes to the\n        main database files, the WAL ensures the transaction can be recovered.\nApply Changes Later\n  DBMS applies the changes to the data files asynchronously during a process\n      called checkpointing.\n   At each checkpoint, the dirty pages in memory (modified data) are written back to the\n     storage to reduce reliance on WAL during recovery.\nIf a crash happens between the WAL flush and the data file update, DBMS can use\n  the WAL to \"redo\" the operations that occurred after the last checkpoint.", "char_count": 843, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 23, "text_raw": "Checkpoints", "char_count": 11, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 24, "text_raw": "          Checkpoint idea\n\na recovery operation that makes it possible to safely return to a\n consistent state, in case of failure\n    (i.e., all committed transactions at a point of the failure are logically\n    redone, all aborted undone) by\n      flushing all relevant buffers and\n      logging currently active transactions\nEnsures that everything committed so far is on the disk and does\n not need any action in case of a failure\nRepeated regularly (e.g., every 5 minutes) by recovery subsystem\n  more frequent—less recovery work\n   less frequent—more overhead", "char_count": 563, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 25, "text_raw": "       checkpoint operation\n\n              Suspend execution of all transactions\n\n\n\n          Flush all main non-pinned dirty memory buffers\n\n\n\nWrite checkpoint entry [checkpoint, list of active transactions] to log and\n                         flush the log to the disk\n\n\n\n               Resume executing transactions", "char_count": 311, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 26, "text_raw": "Recovery protocols", "char_count": 18, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 27, "text_raw": "   Recovery & Concurrency control\n\n\nRecovery subsystem ensures atomicity and durability:\n  restores database to most recent consistent state before failure\n    one or several transactions abort and all their changes need to be\n       rolled back\nNeeds coordination with concurrency control:\n  Assume a system crash event that aborts all transactions as a\n   model type failure\n  Assume strict two-phase locking as a model concurrency\n    control protocol", "char_count": 457, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 28, "text_raw": "   Shadowing\nrecovery protocol", "char_count": 27, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 29, "text_raw": " Shadowing recovery protocol: Idea\nflush each modified buffer immediately to a\n new place on disk, the old (shadow) version is\n kept on disk (and never modified)\n  if a transaction commits, the current\n   version is used\n  if a transaction aborts, the shadow version\n   is used\n A directory: a table with pointers to\n              disk blocks", "char_count": 345, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 30, "text_raw": "    Shadowing recovery protocol\n\nShadowing (shadow paging) recovery protocol\n (for a single transaction):\n  at the beginning of a transaction,\n   a current directory with pointers to all blocks is created,\n     and it is copied to shadow directory\n  after each write,\n    affected buffers are immediately flushed to a new disk\n      block, and the current directory is updated\n  if a transaction commits, the current version is taken\n  if a transaction aborts, the shadow version is restored", "char_count": 494, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 31, "text_raw": "Example of shadowing", "char_count": 20, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 32, "text_raw": "       Shadowing properties\n\nno log required in strict (or single-user)\n environment\n  so, sometimes called NO-UNDO/NO-REDO\nno checkpoints either\n  essentially, a copy of cache on disk\nresults in a lot of overhead and random-\n ordered blocks on disk\nrequires complicated garbage collection", "char_count": 288, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 33, "text_raw": "Deferred-update\n    protocol", "char_count": 28, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 34, "text_raw": "Transaction picture", "char_count": 19, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 35, "text_raw": "       Deferred update: Idea\nDeferred update recovery protocol idea:\n   no-steal approach:\n       postpone all flushes of (dirty buffers) to disk\n             until the transaction commits\n  REDO- (NEW-) log entries are needed:\n       to recover committed transactions after a system\n           crash\n  UNDO- (OLD-) log entries are not needed:\n      no changes of aborted transactions are on the disk\n   thus, NO-UNDO/REDO", "char_count": 423, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 36, "text_raw": "    Properties and Assumptions\n\nDeferred update recovery protocol properties:\n\n   effective only for short transactions with few changes\n   cache size is an issue with longer transactions\nSimplifying assumptions, some already mentioned\n      (can be relaxed but rules and procedures may need adjustments):\n\n   strict two-phase locking with blocks as items\n   system crash as a fail (i.e., all active transactions\n       abort)\n   all blocks changed by a transaction fit into cache", "char_count": 484, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 37, "text_raw": "       Deferred update rules\nuse log with REDO entries and regular\n checkpoints\nall buffers changed by a transaction are pinned\n until commit\n   (i.e., no-steal approach)\ntransaction does not commit until all its REDO-\n type log entries are recorded in log and log buffer\n is flushed to disk\n   (i.e., the relevant REDO-part of the write-ahead\n   approach)", "char_count": 354, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 38, "text_raw": "  Deferred update: Recovery procedure\n\n(evaluated by the recovery subsystem after a system crash):\nfind the active (i.e., latest) checkpoint in the log on the disk\n   all effects of committed transactions are on the disk by the\n    checkpoint\nusing the checkpoint’s active transactions and the log after\n the checkpoint, construct the set of all committed\n transactions between the checkpoint and the crash\n   their commit log entries are on the disk\nredo all operations of the committed transactions from the\n set\n   all their log entries are on the disk", "char_count": 560, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 39, "text_raw": " Deferred update protocol: Example\n\n\n\n\n\nT1: already committed and flushed, no action required\nT2: may have non-flushed buffers,\n  but the log (including begin_transaction) is flushed, so all changes\n  can be recovered from the log (considered from from the checkpoint)\nT3: may have non-flushed buffers,\n  but the log is flushed and the checkpoint remembers that it is active, so\n   all the changes can be recovered from the log\nT4, T5: aborted and no buffers are flushed, no action required", "char_count": 497, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 40, "text_raw": "Immediate-update\n    recovery", "char_count": 29, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 41, "text_raw": "         Immediate update\nImmediate update recovery protocol idea:\n  possible steal approach:\n     allow to flush of dirty buffers\n     both before and after the transaction commits\n  REDO- (NEW-) log entries log entries are needed:\n     to redo committed transactions after a system crash\n  UNDO- (OLD-) log entries log entries are needed: to undo\n    aborted transactions\n     thus, UNDO/REDO (generalises deferred-update)\nImmediate update recovery protocol properties:\n  more general than deferred-update\n  more difficult", "char_count": 526, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 42, "text_raw": "       assumptions and rules\nSimplifying assumptions, less than above\n   strict two-phase locking with blocks as items (not essential\n    here)\n  system crash as a fail (i.e., all active transactions abort)\nImmediate update protocol rules (just write-ahead logging\n in full):\n  use log with REDO/UNDO entries and regular checkpoints\n  a dirty buffer does not flush until all relevant log entries are\n   recorded in log and log buffer is flushed to disk\n       (i.e., the first part of the write-ahead approach)\n  transaction does not commit until all its log entries are\n   recorded in log and log buffer is flushed to disk\n       (i.e., the second part of the write-ahead approach)", "char_count": 684, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 43, "text_raw": " Immediate update: Recovery procedure\n\n\n(evaluated by the recovery subsystem in case of a crash):\nfind the active (i.e., latest) checkpoint in the log on the disk\n   all effects of committed transactions are on the disk by the checkpoint\nconstruct the sets of all committed and non-committed (i.e.,\n aborted) transactions between the checkpoint and the crash\n   their commit log entries are on the disk\nredo all operations of the committed transactions\n   all their log entries are on the disk\nundo all known operations of the non-committed transactions\n  some of their log entries may not be on the disk, but their\n    corresponding changes were not flushed", "char_count": 666, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 44, "text_raw": " Immediate update protocol: Example\n\n\n\n\n\nT1, T2, T3: same as before\nT4, T5: aborted, so should be undone;\n some changes may be already flushed by t2 and\n  some may not, but the log entries of all flushed\n   changes are also flushed", "char_count": 233, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 45, "text_raw": "ARIES recovery\n   protocol", "char_count": 26, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 46, "text_raw": "           ARIES: Overview\n\nARIES protocol main properties:\n  Algorithm for Recovery and Isolation Exploiting Semantics\n  an improved version of immediate-update protocol\n     (possible steals, REDO/UNDO log entries, write-ahead logging)\n  used in practice\n  again, we concentrate on strict schedules\nARIES update recovery protocol improvement ideas:\n  different checkpoints (main improvement): instead of flushing\n    everything,\n    remember the table of currently dirty buffers\n  other improvements (e.g., logging of recovery): not discussed\n   here", "char_count": 551, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 47, "text_raw": "         ARIES Checkpoints\n\nDuring execution, ARIES maintains (in main memory):\n  Transaction table of currently active and committed\n    transactions\n     (ID, pointer to the most recent relevant log entry, status)\n  Dirty buffer table of currently dirty buffers in the cache (ID,\n    pointer to the earliest update log entry)\nARIES checkpoint (fuzzy in general)\n  the begin_checkpoint entry identifies the start point for the\n    recovery, and the state of the transaction table and dirty buffer\n    table to store\n  the end_checkpoint entry has the tables (at the begin-point\n    state) appended in the log\n     the log must be flushed at the end of checkpoint", "char_count": 662, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 48, "text_raw": "  ARIES recovery protocol: Example\n\n\n\n\n\n(a) The log\n(b) Possible transaction and dirty block table at the begin\n    checkpoint (appended to end_checkpoint)\n(c)  Possible tables at the moment of the end of\n    the log (observe that 7 in dirty buffer table\n      implies that C was flushed between Lsn 5 and 7)", "char_count": 306, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 49, "text_raw": "     ARIES recovery main steps\n\nARIES recovery procedure (evaluates at the crash event):\nAnalysis step:\n   identifies the earliest update log entry of a dirty buffer\n   at the checkpoint (and collects other relevant information)\nRedo step:\n  go through the log from the identified point to the end and redo the\n    necessary operations (i.e., the writes of dirty blocks in the table before the\n    begin checkpoint and all writes after it)\nUndo step:\n  go through the log from the end to the beginning of all uncommitted (by the\n     log end) transactions and undo necessary operations\n    (i.e., all writes that are not overwritten by a redo)\nEvaluated undo’s and redo’s are also logged,\nso that a crash during update does not cause a need to re-evaluate", "char_count": 761, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 50, "text_raw": "ARIES recovery protocol: Example\n\n\n\n\n\nLet the log above be in on the disk after a crash. ARIES steps:\n\n   1. Analysis step: identifies the earliest log entry: Lsn 1\n   2. Redo step: redo the writes with Lsn 1, 6, 7 (no 2)\n    Undo step (only T3): undo update with Lsn 6  3.\n\n(Lsn 6 is redone and undone;\n\n     think of advantages and disadvanatages of such strategy)", "char_count": 366, "is_empty": false}
{"lecture_id": "ADB_Lec09", "source_file": "ADB_Lec09.pdf", "page_num": 51, "text_raw": "", "char_count": 0, "is_empty": true}
